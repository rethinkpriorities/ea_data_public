[{"path":"index.html","id":"index-skip","chapter":"1 INDEX (skip)","heading":"1 INDEX (skip)","text":"","code":"\n#From https://stackoverflow.com/questions/62028925/how-do-i-catch-errors-in-inline-code-chunk-in-r-markdown\n\nknitr::knit_hooks$set(\n  evaluate.inline = function (code, envir = knit_global()) {\n    v = try(eval(xfun::parse_only(code), envir = envir))\n    knitr::knit_print(v, inline = TRUE, options = knitr::opts_chunk$get())\n  },\n  inline = function(x) {\n  if (any(class(x) == \"try-error\")) {\n    as.vector(x)\n  } else x\n})\n#TODO: Some of this repeats content in 'main' --- delete from one or the other?\n\n#Define objects for 2020 survey\n\nyear_s <- \"2020\"\nyear_n <- 2020\n#formatting functions\nop <- function(x, d=3) format(x, format=\"f\", big.mark=\",\", digits=d, scientific=FALSE)\nops <- function(x, d=3, ns=2) format(x, format=\"f\", big.mark=\",\", digits=d, nsmall=ns, scientific = FALSE)\noptions(scipen=999)\nscatter_theme <- theme_minimal()\n#TODO (high-priority) - is there an option to say:\n# - \"any CI's or other things that go outside of the limits should just be extended to the edge and not dropped)\"?\n# @Oska -- what about 'extending to the edge'? -- oob?"},{"path":"outline_disc.html","id":"outline_disc","chapter":"2 Notes on this ‘bookdown’ relating to the EA Survey","heading":"2 Notes on this ‘bookdown’ relating to the EA Survey","text":"material meant supplement EA Survey series posts EA forum, may linked posts. /put together David Reinstein Rethink Priorities, collaboration input others RP.","code":""},{"path":"eas_donations.html","id":"eas_donations","chapter":"3 Donation","heading":"3 Donation","text":"Linked forum post Link EA Survey 2020 Series: Donation DataNote feedback (unfold)’d love get feedback report. ’s ‘bookdown’ format produced Rmd, (folded code well folding supplemental bits case curious, ignored)Written heavy input Oska Fentem guidance David Moss others (including Peter Wildeford Nik Vetr).Much/input EA Forum post, post may leave technical detailed content, refer/link hosted report (embedded reports).() margin notes become footnotes forum post. Folding boxes mainly dropped forum version.Ideally, leave feedback right web site using Hypothes.tool (private group; see thread, public OK ).difficulties , part format, please let know. course also appreciate feedback form, including Slack, document, Github repo, etc.hope work may relevant even beyond specific context, thus love loads feedback becauseI think represents somewhat change ’re addressing EA survey (e.g., cross-year analysis)/hope apply methods formats projects data movement building, EA messaging, fundraising space!Thanks much!!","code":"<!-- removed chunk options and 'ignore errors' thing here ... because that should be in the index.Rmd file -->\n#eval=FALSE because this is already done in Main\n\nsource(here(\"code\", \"modeling_functions.R\"))\neas_20 <- readRDS(here(\"data\", \"edited_data\", \"eas_20.Rdata\"))\neas_all <- readRDS(here(\"data\", \"edited_data\", \"eas_all_private.Rdata\"))\n\neas_20_cy <- readRDS(here(\"data\", \"edited_data\", \"eas_20_cy.Rdata\"))\n\nsource(here::here(\"build\",\"labelling_eas.R\")) # needs to have been run also -- some of these objects are used below\n# Folder to save plots in\nplots_folder <- here(\"analysis\", \"plots\", \"donations_20\")"},{"path":"eas_donations.html","id":"introduction","chapter":"3 Donation","heading":"3.1 Introduction and summary","text":"Charitable donation (earning--give) , continues prominent, prevalent, impactful component Effective Altruism movement. EA Survey distributed 2014 2020, roughly 15 month intervals. result, surveys released various points year, ranging April August, survey released 2016. survey asked EAs charitable donations previous year, predicted donations year survey. work post/section reports 2020 survey (2019 giving), analysis extends years EA survey.post (accompanying ‘bookdown’ supplement chapter), consider donation responses, presenting raw numbers, descriptive, predictive, causally-suggestive analysis. present simple numbers, statistical comparisons, vizualisations, descriptive ‘predictive’ (machine learning) models. cover range topics concerns, including:total magnitude EA giving relationship non-EA giving,career paths ‘earning give’,broad relationship EA giving individual characteristics (employment status country, income),donations versus income trends across recent years,causes EAs donating , andEA’s donation plans versus realized donations (future plans).modeling work work considers donations (total, share--income, ‘donated 1000 USD’) jointly relates range characteristics. first present ‘descriptive’ results focusing key set observable features interest, particularly demographics, employment careers, ‘continuous features’ age, time--EA, income, year survey. next fit ‘predictive’, allowing ‘machine learning’ models choose features seem important predicting donations.narrative , simply refer “donations” rather “reported donations” brevity. Unless otherwise mentioned, figures simply add, average, otherwise summarize individual responses EA Survey years mentioned.1","code":"\nrequire(scales)\n\n#can also move stuff to plotting_functions.R\n\n# Define breaks and limits\nbreaks <- c(0, 10^(1:10))\nmax_lim <- max(filter(eas_all, !year %in% c(2014, 2015))[c(\"donation_usd\", \"donation_plan_usd\")], na.rm=TRUE)\ndensity_breaks <- seq(0, 1, 0.2)[-1]\n\n# Define same parameters for x and y axis\nscales <- list(limits = c(0, max_lim), trans = scales::pseudo_log_trans(base=10),\n               breaks = breaks,\n               labels = scales::label_number_si(prefix = \"$\"),\n               expand=c(0,0))\n\n\nscatter_theme <- theme_minimal()\ndonate_charity_names <- eas_20 %>%  dplyr::select(matches(\"donate_\")) %>%  dplyr::select(-matches(\"action_|_later\")) %>% names()\n\n\ndon_tot_freq <- eas_20 %>%\n  summarise(across(c(all_of(donate_charity_names)), ~sum(as.numeric(.x) > 0, na.rm = TRUE)))  %>% slice(1) %>%\n           unlist(., use.names=TRUE)\n\ndev_health_chars <- c(\"donate_deworm_the_world_c\", \"donate_givewell_c\", \"donate_schistosomiasis_control_c\", \"donate_give_directly_c\", \"donate_against_malaria_found_c\", \"donate_global_health_develop_c\")\n\nanimal_chars <- c(\"donate_mercy_for_animals_c\", \"donate_humane_league_c\", \"donate_ea_animal_welfare_fund_c\", \"donate_good_food_institute_c\", \"donate_ace_c\")\n\nea_meta_chars <- c(\"donate_rethink_charity_c\", \"donate_80k_c\", \"donate_cea_c\", \"donate_ea_foundation_c\", \"donate_ea_meta_fund_c\")\n\nlt_ai_chars <- c(\"donate_machine_intelligence_c\", \"donate_long_term_future_fund_c\")\n\nother_chars <- c(\"donate_center_applied_rational_c\", \"donate_global_health_develop_c\", \"donate_other1_c\",  \"donate_other2_c\", \"donate_other3_c\", \"donate_other4_c\",  \"donate_other5_c\")\n\nall_chars <- c(dev_health_chars, animal_chars, ea_meta_chars, lt_ai_chars, other_chars)\n\n#all_char_labels <- list(animal_don = \"Animal welfare\", dev_don = \"Global health + development\", ea_meta_don = \"EA meta and organization\", lt_ai_don=\"Long term & AI\", other_don = \"Other\" ) -- moved to\n\n#all_char_labels2 <- list(dev_don = \"Global health + development\", animal_don = \"Animal welfare\", ea_meta_don = \"EA meta and organization\", lt_ai_don=\"Long term & AI\", other_don = \"Other\" ) -- moved to\n#here::here(\"build\",\"labelling_eas.R\")\n\n# moved to build side:\n# eas_20 <- eas_20 %>% sjlabelled::var_labels(all_char_labels)\n\ncount_notna <- function(x) sum(!is.na(x))\n\nwhere_don_dummies <- c(\"d_dev_don\",  \"d_animal_don\",  \"d_ea_meta_don\",  \"d_lt_ai_don\",  \"d_other_don\")\n# Construct charity-specific aggregations (?move to build side)\n\nwhere_don_vars <- c(\"dev_don\", \"animal_don\", \"ea_meta_don\", \"lt_ai_don\", \"other_don\")\n\neas_20 <- eas_20 %>%\n  mutate(\n    num_named_dons  = rowSums(!is.na(select(., one_of(all_chars)))),\n    dev_don = rowSums(across(all_of(dev_health_chars)), na.rm = TRUE),\n    d_dev_don = dev_don > 0,\n    animal_don = rowSums(across(all_of(animal_chars)), na.rm = TRUE),\n    d_animal_don = animal_don>0,\n    ea_meta_don = rowSums(across(all_of(ea_meta_chars)), na.rm = TRUE),\n    d_ea_meta_don = ea_meta_don>0,\n    lt_ai_don = rowSums(across(all_of(lt_ai_chars)), na.rm = TRUE),\n    d_lt_ai_don = lt_ai_don>0,\n    other_don = rowSums(across(all_of(other_chars)), na.rm = TRUE),\n    d_other_don = other_don>0\n    ) %>%\n  mutate_at(.vars =where_don_vars,\n            funs(ifelse(num_named_dons==0, NA, .))\n         )\n\neas_20 %<>% labelled::set_variable_labels(.labels = as.list(all_char_labels), .strict=FALSE)\npct_tot <- function(x) {\n  x/NROW(eas_20)*100\n}\n\nnum_don <- sum(eas_20$donation_2019_c>0, na.rm=TRUE)\nnum_na_don <- sum(is.na(eas_20$donation_2019_c))\nzero_don <- sum(eas_20$donation_2019_c==0, na.rm=TRUE)\n\ntot_don <- sum(eas_20$donation_2019_c, na.rm=TRUE)\n\n#for all years, for USA nonstudents only\ntot_don_all_usa <- sum(eas_all$donation_usd[eas_all$d_live_usa==1 & eas_all$d_student==0], na.rm=TRUE)\n\ntot_inc_all_usa <- sum(eas_all$income_c_imp_bc5k[eas_all$d_live_usa==1 & eas_all$d_student==0], na.rm=TRUE)\n\ntot_share_don_us_nonstudent <- tot_don_all_usa/tot_inc_all_usa\n\ntot_don_dev <- sum(eas_20$dev_don, na.rm=TRUE)\ntot_don_animal <- sum(eas_20$animal_don, na.rm=TRUE)\ntot_don_ea_meta <- sum(eas_20$ea_meta_don, na.rm=TRUE)\ntot_don_lt_ai <- sum(eas_20$lt_ai_don, na.rm=TRUE)\n\nmed_don <- median(eas_20$donation_2019_c, na.rm=TRUE)\nmean_don <- mean(eas_20$donation_2019_c, na.rm=TRUE)\nmean_don_not_new <- mean(eas_20$donation_2019_c[eas_20$year_involved_n!=year_s], na.rm=TRUE)\n\nmean_don_18 <- mean(eas_all$donation_usd[eas_all$year==2019], na.rm=TRUE)\nmean_don_18_not_new <- mean(eas_all$donation_usd[eas_all$year==2019 & eas_all$year_involved!=\"2019\"], na.rm=TRUE)\n\n\nplan_donate_2019_c <- filter(eas_all, year == 2019) %>% pull(donation_plan_usd)\n\nmean_plan_18_19 <- mean(plan_donate_2019_c, na.rm=TRUE)\nmed_plan_18_19 <- median(plan_donate_2019_c, na.rm=TRUE)\n\nmed_not_new <- median(eas_20$donation_2019_c[eas_20$year_involved_n!=year_s], na.rm=TRUE)\n\ntop_1p3don <- eas_20 %>% select(donation_2019_c) %>% slice_max(donation_2019_c, prop =.013) %>% sum()\ntop_1p3share <- top_1p3don/tot_don"},{"path":"eas_donations.html","id":"sum-results","chapter":"3 Donation","heading":"3.1.1 Summary (some key results and numbers)","text":"55.5% EAs 2020 survey reported making charitable donation 2019, 13.7% reported making zero donations, 30.8% respond question. (Thus, responded, 80.3% reported making donation prior year.)55.5% EAs 2020 survey reported making charitable donation 2019, 13.7% reported making zero donations, 30.8% respond question. (Thus, responded, 80.3% reported making donation prior year.)Participants reported total donations 10,695,926 USD 2019 (cf 16.1M USD 2018).Participants reported total donations 10,695,926 USD 2019 (cf 16.1M USD 2018).However, number survey participants declined somewhat, 2509 2019 (1704 answered donation question) 2056 (1423 answering donation question) 2020.*\npast years, see strong trend median mean donation amounts reported.2\nHowever, number survey participants declined somewhat, 2509 2019 (1704 answered donation question) 2056 (1423 answering donation question) 2020.*past years, see strong trend median mean donation amounts reported.2The median annual donation 2019 528 USD (cf 683.92 USD 2018).median annual donation 2019 528 USD (cf 683.92 USD 2018).mean (reported) annual donation 2019 7,516 USD (cf 9,370 2018) 8,607 USD excluding joined 2020 (cf 10,246 USD 2018 excluding joined 2019).mean (reported) annual donation 2019 7,516 USD (cf 9,370 2018) 8,607 USD excluding joined 2020 (cf 10,246 USD 2018 excluding joined 2019).median annual donation 2019 excluding joined EA 2020 761 USD (cf. 990 USD comparable median 2018/2019 832 USD 2017/2018). (See ’donation income trends EA’ details).median annual donation 2019 excluding joined EA 2020 761 USD (cf. 990 USD comparable median 2018/2019 832 USD 2017/2018). (See ’donation income trends EA’ details).2019 1.3% donors accounted $6,437,404 donations 60% survey total. (Cf 2018 1.3% donors accounted 57% donations.)2019 1.3% donors accounted $6,437,404 donations 60% survey total. (Cf 2018 1.3% donors accounted 57% donations.)median percentage income donated 2019 2.96% (cf 3.23% 2018).median percentage income donated 2019 2.96% (cf 3.23% 2018).However, impute “0 missing incomes” “group medians student-status country”,* median percentage income donated 2% 2019.3However, impute “0 missing incomes” “group medians student-status country”,* median percentage income donated 2% 2019.3Mean share total (imputed) income donated 9.44% (imputing income 5k missing) 12.5% without imputation.Mean share total (imputed) income donated 9.44% (imputing income 5k missing) 12.5% without imputation.20% EAs answered donation question reported donating 10% income 2019 (impute income; otherwise 25.6% without imputation; compares 20% 2018, without imputation).20% EAs answered donation question reported donating 10% income 2019 (impute income; otherwise 25.6% without imputation; compares 20% 2018, without imputation).median percent income donated full-time-employed non-students earned $10,000 2.92%, group 23.9% donated 10% income 2019 (cf 3.38% 24% 2018).median percent income donated full-time-employed non-students earned $10,000 2.92%, group 23.9% donated 10% income 2019 (cf 3.38% 24% 2018).Overall, taking EA survey tend report donating substantially greater share income general US population – (web link).Overall, taking EA survey tend report donating substantially greater share income general US population – (web link).69.2% respondents answered donation question, 20.9% answered least one question donated.Among , charity EAs stated donated Malaria Foundation (AMF), 122 reported donations (total 1462 reported donations).Global Poverty charities continue attract largest counts amounts donations. 62% answered relevant question reported donating category. 26.9% total ‘donated’ reports global poverty charities. sum 1,703,870 USD total donations reported specifically going global poverty charities.\ncompares 27.3% reporting donating, 10.5% donations \\(\\$\\) 645,086 total donated animal charities,\n17.2%, 5.81% \\(\\$\\) 330,910 EA movement/meta charities,\n18.2%, 5.61% \\(\\$\\) 418,403 long term AI charities, respectively.\n\nGlobal Poverty charities continue attract largest counts amounts donations. 62% answered relevant question reported donating category. 26.9% total ‘donated’ reports global poverty charities. sum 1,703,870 USD total donations reported specifically going global poverty charities.compares 27.3% reporting donating, 10.5% donations \\(\\$\\) 645,086 total donated animal charities,\n17.2%, 5.81% \\(\\$\\) 330,910 EA movement/meta charities,\n18.2%, 5.61% \\(\\$\\) 418,403 long term AI charities, respectively.\ncompares 27.3% reporting donating, 10.5% donations \\(\\$\\) 645,086 total donated animal charities,17.2%, 5.81% \\(\\$\\) 330,910 EA movement/meta charities,18.2%, 5.61% \\(\\$\\) 418,403 long term AI charities, respectively.Evidence mixed whether EAs’ donations year tend exceed fall short amount planned donate (reported previous surveys). small share can tracked across years, donations tend exceed plans (around 60 USD median, 1000 USD mean). However, overall distribution donations particular year (including respondents) tends fall short distribution planned donations (450 USD median 2000 mean).Evidence mixed whether EAs’ donations year tend exceed fall short amount planned donate (reported previous surveys). small share can tracked across years, donations tend exceed plans (around 60 USD median, 1000 USD mean). However, overall distribution donations particular year (including respondents) tends fall short distribution planned donations (450 USD median 2000 mean).median EAs tend report planning donate amount next year donate particular year, average (mean) plan next year significantly larger.median EAs tend report planning donate amount next year donate particular year, average (mean) plan next year significantly larger.descriptive models basically find :\nage, named ‘top EA’ big city, taken GWWC pledge, Earning--Give career positively associated donations,\n‘employed’ (lesser extent non-male gender student status negatively associated ;\ndonation roughly proportionally associated income (approximately ‘unit elastic’),\nwell age ‘time EA’ (elasticities around 0.54 0.63, respectively).\ndescriptive models basically find :age, named ‘top EA’ big city, taken GWWC pledge, Earning--Give career positively associated donations,‘employed’ (lesser extent non-male gender student status negatively associated ;donation roughly proportionally associated income (approximately ‘unit elastic’),well age ‘time EA’ (elasticities around 0.54 0.63, respectively).predictive (ML) models highlight importance income (lesser extent) age (positively related donation incidence amounts).\n\nmodels perform moderately well, particularly predicting ‘whether donated 1k USD ’ (attains 74% accuracy compared 54% accuracy simply ‘guessing common outcome’).4\npredictive (ML) models highlight importance income (lesser extent) age (positively related donation incidence amounts).\nmodels perform moderately well, particularly predicting ‘whether donated 1k USD ’ (attains 74% accuracy compared 54% accuracy simply ‘guessing common outcome’).4","code":"\nmed_don_share <-  median(eas_20$don_share_inc_19, na.rm = TRUE)\nmed_don_share_imp_bc <- median(eas_20$don_share_inc_19_imp_bc5k, na.rm = TRUE)\n\nearn_filter <- quos(d_student==0, income_c>10000)\n\nmed_don_share_imp_ns_10k <- eas_20 %>%\n  filter(!!!earn_filter) %>%\n    summarise(med=median(don_share_inc_19, na.rm = TRUE))\n\ntot_inc <- sum(eas_20$income_c, na.rm=TRUE)\n\ntot_inc_imp_bc <- sum(eas_20$income_c_imp_bc5k, na.rm=TRUE)\n\nshare_don_gt_10pct <- sum(eas_20$don_share_inc_19>=.1, na.rm = TRUE)/sum(!is.na(eas_20$don_share_inc_19))\n\nshare_don_gt_10pct_imp <- sum(eas_20$don_share_inc_19_imp_bc5k>=.1, na.rm = TRUE)/sum(!is.na(eas_20$don_share_inc_19_imp_bc5k))\n\nshare_don_gt_5pct_imp <- sum(eas_20$don_share_inc_19_imp_bc5k>=.05, na.rm = TRUE)/sum(!is.na(eas_20$don_share_inc_19_imp_bc5k))\n\nshare_don_gt_10pct_earn <- eas_20 %>%\n  filter(!!!earn_filter) %>%\n      transmute(share_don_gt_10pct =  sum(don_share_inc_19>=.1, na.rm = TRUE)/sum(!is.na(don_share_inc_19)) ) %>%\n    unlist %>%  .[1]\n\n#don gt 10pct ... by gender\n\n#eas_20 %>%\n#     mutate(d_don_gte10_imp = don_share_inc_19_imp>=.1) %>%\n#     tabyl(gender_manual, d_don_gte10_imp) %>% tabylstuff()\npct_don <- function(x) {\n  sum(don_tot_freq[x])/sum(don_tot_freq)*100\n}\n\npct_ddon <- function(x) {\n  op(\n    sum(x != 0, na.rm=TRUE)/sum(notNA(x), na.rm=TRUE)*100\n  )\n}\ndon_stats <- eas_20 %>%\n        filter(num_named_dons>0) %>%\n  select(all_of(where_don_vars)) %>%\n  vtable::sumtable(\n                summ=c('notNA(x)', 'sum(x != 0)', 'sum(x != 0)/notNA(x)', 'mean(x)', 'sd(x)', 'pctile(x)[50]', 'pctile(x)[90]'),\n                summ.names = c('Number of Responses', 'Number reporting donation to cause', 'Share of reporters donating to cause', \"Mean donation of reporters (including 0's)\", 'Sd', \"Median\", \"90th pct\"),\n                digits=c(0,0,2,0,0,0,0),\n                simple.kable = TRUE,\n                labels = all_char_labels2,  #it's a horrible workaround but we need to have the order of these the same as the table order ... I think it's a flaw of sumtable\n                title = \"Donations by category (where indicated)\",\n                out=\"kable\") %>%\n  kable_styling()\n\n\n\n#todo (low-priority) -- replace with .summ hijacked command\n\nn_rep_char <- sum(eas_20$num_named_dons>0, na.rm=TRUE)\ndon_stats_by_gwwc <- eas_20 %>%\n        mutate(`GWWC Pledge` = case_when(\n          action_gwwc==1 ~ \"Yes\",\n          action_gwwc==0 ~ \"No\"\n        )) %>%\n        filter(num_named_dons>0) %>%\n  select(all_of(where_don_vars),\n         `GWWC Pledge`) %>%\n  vtable::sumtable(group = \"GWWC Pledge\",\n                   group.test=TRUE,\n                 summ=c('notNA(x)','sum(x != 0)/notNA(x)', 'mean(x)', 'sqrt(var(x)/length(x))',\n                        'pctile(x)[50]'),\n                summ.names = c('N Responses', 'Share positive', 'Mean', \"Median\"),\n                digits=c(0,2, 0,0,0),\n                simple.kable = TRUE,\n                labels = all_char_labels2,  #it's a horrible workaround but we need to have the order of these the same as the table order ... I think it's a flaw of sumtable\n                title = \"Donations by category (where indicated), by GWWC\", out=\"kable\")  %>%\n      row_spec(1:1, bold = TRUE) %>%\n  kable_styling()\nddon_stats_by_gwwc <- eas_20 %>%\n        mutate(`GWWC Pledge` = case_when(\n          action_gwwc==1 ~ \"Yes\",\n          action_gwwc==0 ~ \"No\"\n        )) %>%\n        filter(num_named_dons>0) %>%\n  select(all_of(where_don_dummies),\n         `GWWC Pledge`) %>%\n  vtable::sumtable(group = \"GWWC Pledge\",\n                   group.test=TRUE,\n                 summ=c('notNA(x)','sum(x != 0)/notNA(x)'),\n                summ.names = c('N Responses', 'Donated to... ?'),\n                digits=c(0,2),\n                simple.kable = TRUE,\n                labels = all_char_labels2,  #it's a horrible workaround but we need to have the order of these the same as the table order ... I think it's a flaw of sumtable\n                title = \"Binary: Indicated donating to category, by GWWC\",\n                out=\"kable\") %>%\n        row_spec(1:1, bold = TRUE) %>%\n  kable_styling()\n\n\n#  .kable() %>%\n # .kable_styling(\"striped\")\n\n#todo (low-priority) -- replace with .summ hijacked command"},{"path":"eas_donations.html","id":"toc","chapter":"3 Donation","heading":"Why does the EA Survey ask about donations?","text":"tell us?“theory change” learning donation behavior improve outcomes?present reasons may useful:5The magnitude EAs’ donations informs ‘much weight can throw around’ asking charities etc appeal us community? measures (discussed ) overall amounts largest donations, EA Survey conveys additional information donations ‘large groups moderate-income people explicitly identify EA.’may offer insight ‘motivates impedes donation behavior’.may offer insight ‘motivates impedes donation behavior’.Donation behavior may seen one measure EA engagement; evidence may thus offer insight ‘motivates engagement’.Donation behavior may seen one measure EA engagement; evidence may thus offer insight ‘motivates engagement’.Observing changes donation patterns across time may alert us potential problems important changes priorities, values, nature EA movement. able predict future donation behavior may also help EA organizations better anticipate, budget, plan (conjunction existing data models).Observing changes donation patterns across time may alert us potential problems important changes priorities, values, nature EA movement. able predict future donation behavior may also help EA organizations better anticipate, budget, plan (conjunction existing data models).Predicting describing typical donation rates can inform decisions like “EAs seem likely impact choose go direct work versus earning--give”.6Predicting describing typical donation rates can inform decisions like “EAs seem likely impact choose go direct work versus earning--give”.6Perhaps controversially (raising idea promoting ), EAs’ donation amounts might seen incentive-compatible ‘votes’ telling us people movement want EA movement focus ? However, note people need truthfully reporting , allow mis-statement, far incentive compatible.Perhaps controversially (raising idea promoting ), EAs’ donation amounts might seen incentive-compatible ‘votes’ telling us people movement want EA movement focus ? However, note people need truthfully reporting , allow mis-statement, far incentive compatible.","code":""},{"path":"eas_donations.html","id":"total_mag","chapter":"3 Donation","heading":"Total EA donations, magnitudes in context","text":"Considering magnitude donations…$10,695,926 USD donations reported seems likely small share total EA-affiliated giving, perhaps less 1/4 total (excluding super-rich institutional givers), perhaps even far smaller share (see extrapolations ).Previous estimates suggest , even among highly-engaged EAs, 40% complete EA survey. might assume people lower ‘cost time’ (, equal, lower incomes) likely -represented EA survey, donate might likely respond particular questions. estimates suggest 20% GWWC members complete survey. noted , 69.2% survey respondents answered ‘past year donation’ question 2020. present extrapolations , others.Even within survey, largest mass donations heavily concentrated among givers. expect distribution donations EA overall even heavily skewed, large donors foundations (Tuna Moskowitz Open Philanthropy accounting lion’s share. table uses data Open Phil’s Grants database, divided year cause area).7\nTable 3.1: Open Philanthropy grants year area, $1000 USD\nExtrapolations benchmarks:Ben Todd’s recent post estimates EA community donating $420 million per year, “grown maybe 21% per year since 2015”, “around 60% Open Philanthropy, 20% GiveWell donors, 20% everyone else.”Ben Todd’s recent post estimates EA community donating $420 million per year, “grown maybe 21% per year since 2015”, “around 60% Open Philanthropy, 20% GiveWell donors, 20% everyone else.”recent post tylermaule estimates $263 million ‘funding ’global funding EA causes’.8A recent post tylermaule estimates $263 million ‘funding ’global funding EA causes’.8Giving Can reports roughly $70 million donations per year, recent years.9Giving Can reports roughly $70 million donations per year, recent years.9GiveWell reported “GiveWell donors contributed $150 million recommended charities 2019”.GiveWell reported “GiveWell donors contributed $150 million recommended charities 2019”.course, large donations/grant totals may coming donors aligned EA, may entirely go towards effective charities. donations also may well-described donations recorded EA survey.fold/footnote, consider importance EA-aligned donations comparison non-EA donations similar causes. return supplemental appendix section (web link), specifically focusing US nonstudents, comparing results national survey.question whether hundreds millions dollars EA-aligned donations substantial comparison non-EA donations similar causes (e.g., developmentaid “Top trends private philanthropic donations development”\nreports OECD figure $7.8 Billion private philanthropic donations development 2018, 200-300 billion total charitable donations per year USA alone.)quick responses:Naturally, anticipate EA donations tend much effective per dollar, perhaps orders magnitude . (basic case, references, given . However, Tomasik others present credible arguments skeptical claims vast differences effectiveness within given domain.)Naturally, anticipate EA donations tend much effective per dollar, perhaps orders magnitude . (basic case, references, given . However, Tomasik others present credible arguments skeptical claims vast differences effectiveness within given domain.)Even EA donations small relation global giving, still important impact, domain can control. (Relatedly, fall victim ‘drop bucket’ ‘proportion dominance’ biases considering .)Even EA donations small relation global giving, still important impact, domain can control. (Relatedly, fall victim ‘drop bucket’ ‘proportion dominance’ biases considering .)“, , much EAs giving” may important informative measure beliefs priorities (discussed ).“, , much EAs giving” may important informative measure beliefs priorities (discussed ).rough extrapolations suggest, perhaps conservatively, $43.6 million USD reasonable central guess total amount annual donations coming non-billionaire EAs, .e., sort EAs respond EAS.10","code":"\nlibrary(scales)\n\nresearch_terms <- \"research|univ|study|UC|trial|scholar|fellow|macreoeconomic|rethink|study|feasibility|analysis|evaluation\"\n\nfocus_area_names <- c(\n`Criminal Justice Reform` = \"Crime/Justice\",\n`Farm Animal Welfare` = \"Farm Animal\",\n`Global Health & Development` = \"Glob. Health/Dev.\",\n`Scientific Research` = \"Scient. Res.\",\n`Potential Risks from Advanced Artificial Intelligence` = \"AI risk\",\n`Biosecurity and Pandemic Preparedness` = \"Biosec.\",\n`Other areas` = \"Other\",\n`Macroeconomic Stabilization Policy` = \"Macro-econ\",\n`Global Catastrophic Risks` = \"Glob. Catastr. Risk\",\n`Immigration Policy` = \"Immig. Policy\",\n`Land Use Reform` = \"Land Ref.\",\n`U.S. Policy` = \"US policy\",\n`History of Philanthropy` = \"Hist. of Phil.\"\n  )\n\n\nopen_phil_grants <- read.csv(\"https://www.openphilanthropy.org/giving/grants/spreadsheet\") %>%\n  as_tibble() %>%\n  mutate(\n    amount = as.numeric(gsub('[$,]', '', Amount)),\n    amount_usd_k = amount/1000,\n    date = lubridate::my(Date),\n    year = lubridate::year(date),\n    focus_area = dplyr::recode(Focus.Area, !!!focus_area_names),\n    focus_area = as.factor(focus_area))  %>%\n  select(-Amount, -Date)\n(\n  op_res_grants_tab_yr_area <-\nopen_phil_grants %>%\n    dplyr::group_by(year, focus_area) %>% # drop_na(!!yvar, !!treatvar) %>%\n    summarise(total = sum(amount_usd_k,  na.rm = TRUE)) %>%\n    spread(year, total, fill=0) %>%\n    adorn_totals(\"row\") %>%\n      adorn_rounding(digits = 0) %>%\n    arrange(-`2020`) %>%\n    rename_with(~snakecase::to_sentence_case(.)) %>% # Change focus_area to Focus Area\n    .kable(caption = \"Open Philanthropy grants by year and area, in $1000 USD\",\n          col.names = NA) %>%\n    row_spec(1:1, bold = TRUE) %>%\n    .kable_styling(\"striped\")\n)\nextrap_tot_ea_don <- (tot_don +\n                        tot_don*0.5 *\n                        (num_na_don/(num_don+zero_don))) / 0.3"},{"path":"eas_donations.html","id":"career-etg","chapter":"3 Donation","heading":"3.2 Career paths: Earning-to-give","text":"Although may recent decline earning--give (ETG), continues popular career path. (discuss career paths EA Survey 2020: Demographics post ‘Careers education’*)11“requested change question 2018/2019 2020… looking non-students (largely already careers), responses across years may still comparable appear show slight decline E2G”tables graphs , apparent steep drop number indicating ETG 2019 2020 survey seems likely overstated (result requested change question language options provided).12Still, responses non-students might less sensitive changes survey question likely career path ‘current career’. responses also suggest decline EtG.\nTable 3.2: Rates ‘Earning--give’ year student status (see caveats)\ndecline ETG less dramatic among non-students (23% non-student respondents still report ETG ‘current career’), nonetheless appears fairly strong consistent 2017-present.13","code":"\netg_rates_all <- eas_all %>%\n  filter(year>2014) %>%\n  group_by(year) %>%\n  summarise( \"Count\" = n(),\n             \"Share ETG\" = mean(as.numeric(d_career_etg))\n             )\n\netg_rates_ns <- eas_all %>%\n    filter(year>2014) %>%\n  filter(d_student==0) %>%\n  group_by(year) %>%\n   summarise( \"Count\" = n(),\n             \"Share ETG\" = mean(as.numeric(d_career_etg))\n             )\n\n(\netg_rates_tab <- bind_cols(etg_rates_all, etg_rates_ns[-1]) %>%\n  magrittr::set_names(c(\"Year\", \"All responses\", \"Share EtG\", \"Nonstudents\", \"Nonstudents: Share EtG\")) %>%\n  kable(caption = \"Rates of 'Earning-to-give' by year and student status (see caveats)\", digits=3) %>%\n  .kable_styling()\n)\n  #     tabyl(year, d_career_etg) %>%\n#     tabylstuff_nocol(cap = \"Non-students only; Rates of 'Earning-to-give' (see caveat)\")\n#\n\n\n# (\n# etg_rates_ns <- eas_all %>%\n#     filter(d_student==0) %>%\n#     tabyl(year, d_career_etg) %>%\n#     tabylstuff_nocol(cap = \"Non-students only; Rates of 'Earning-to-give' (see caveat)\")\n# )\n\n\n# (\n#   etg_rates_tab <- eas_all %>%\n#   group_by(year, d_student) %>%\n#   filter(!is.na(d_student)) %>%\n#   summarise( \"Count\" = n(),\n#              \"Share ETG\" = mean(as.numeric(d_career_etg))\n#              ) %>%\n#   pivot_wider(names_from =d_student,\n#               values_from=c(Count, \"Share ETG\")\n#               ) %>%\n#   set_names(c(\"Year\", \"Nonstudents\", \"Students\", \"Nonstudents: Share EtG\", \"Students: Share EtG\")) %>%\n#   kable() %>%\n#     .kable_styling()\n#)\n\n#todo - medium priority: combine the above tables into a single table: overall, just for students  with just n,\n(etg_rates_plot <- eas_all %>%\n  group_by(year, d_student) %>%\n      filter(year>2014) %>%\n  filter(!is.na(d_student)) %>%\n\n        #@oska (low-med priority todo): we should functionalize these mutations for computing se and CIs (or find someone who has done). We do it again and again, and the code is bulky\n        #maybe incorporate my se_bin function\n        #@oska todo ... also functionalize or otherwise preserve a good version of this graph\n\n  # Calculate standard error, confidence bands and change student factor levels\n  summarise(\n         m_etg = mean(as.numeric(d_career_etg)),\n         se = se_bin(d_career_etg)) %>%\n    mutate(\n         etg_low = m_etg - 1.96*se,\n         etg_high = m_etg + 1.96*se,\n         d_student = as.factor(if_else(d_student == 0, \"Non-student\", \"Student\")),\n         year = as.factor(year)) %>%\n\nggplot(aes(x=year, y=m_etg, colour = d_student, group = d_student))  +\n  geom_pointrange(aes(ymin = etg_low,\n                      ymax = etg_high),\n                  position = position_dodge(width=0.5)) + # Ensure that bars don't overlap\n  geom_line(position = position_dodge(width=0.5)) +\n  xlab(\"Mean (and 95% CI) response share in 'Earning-to-give'\") +\n  ylab(\"Share of sample\") +\n  scale_color_discrete(\"\") + # Remove legend title\n   scale_y_continuous(labels = scales::percent_format(accuracy = 1L), limits=c(0,NA), oob = scales::squish) + # Change y-axis to percentages\n  theme(legend.position = c(0.9, 0.95),\n        #legend.background = element_rect(fill=alpha('blue', 0.001)),\n        legend.key = element_blank())\n)"},{"path":"eas_donations.html","id":"descriptives","chapter":"3 Donation","heading":"3.3 Donation totals: descriptives","text":"14","code":""},{"path":"eas_donations.html","id":"overall-donations-totals-by-groups","chapter":"3 Donation","heading":"Overall donations, totals by groups","text":", present histogram positive reported 2019 donations respondents. Note :horizontal axis logarithmic scale,13.7% 2,056 total respondents reported donating zero, and30.8% total respondents report donation amount.noted , often simply refer ‘donations’ rather ‘reported donations’, brevity.2019 reported:donation 1000 USD per year … place one top half EA donors (specifically, 55th percentile), whereas top 10% donors require donating 11,000 USD top 1% 110,000 USD.results 2020 (2019 donations) comparable; median donation (reporting) 528 USD, donation $1000 puts 59.5th percentile. top 10% requires donating 9,972 top 1% means donating 89,560 USD.previous years, mean far exceeds median, (falls close 90th percentile!); small number large donations dwarf size others. illustrate ‘treemap’ plot , divides total reported contributions groups size--contribution.third total reported contributions reported 2019 come contributions 500,000 USD, another 20% coming contributions 25k 100k. Contributions 2500 USD represent less 5% total.Next consider ‘career paths driving total donation totals?’; mapping share total 2019 donations similarly, accompanied table overall shares respondents, comparison.15\nreporting ‘profit-earning give’ career paths represent largest share, nearly half total donations, despite making  15% sample (answering question). ‘profit’ careers say earning give donate 15% total, roughly proportion 12% share sample. However differences may reflect differences income wealth levels, well differences underlying characteristics people choose different career paths.Direct work seem obviously coming expense donations. pursuing careers working EA-affiliated non-profits account somewhat higher share donations (12%) (8%) share sample. (However, know much particular EAs given chosen different career.)Obviously, income levels different career paths. put perspective plot .plot depicts mean income mean donations ‘career group’, 95% CI’s latter. superimpose ‘line best fit’ (blue, smoothed 95% intervals rough fit) ‘10% income donation’ line (red). Unsurprisingly, -profit ‘-EtG’ fitted line, ‘-profit EtG’ line, although 95% CIs fairly wide. also note among people non-profit careers, similar average incomes whether non-profit EA-aligned, non-profit EA people seem donate somewhat (although CI’s overlap).Next, present reported donation amounts income groupings (imputing income missing 5000 USD).16Compare graph ‘donations donations size’ graph.largest earners (6 people earning 1 million USD ) represent 35% donations (cf largest donors represent 36% donations). However, second-highest earners, 8 people earning 500k 1 million USD represent 6% donations (cf 20% second-highest donation group). fact, second largest share total 2020 donations come second-largest (population) income-group sample, 395 people earning 50K 100K USD.Finally, report donation totals country. First 2019 donations alone:Next, pooling across years EA survey (without weighting adjustment):, ‘Winsorizing’ donations 100K USD (setting larger donations value), reduce impact outliers:report shares (0-1) total survey population coming country :\nTable 3.3: Shares (0-1) survey population country; larger countries \ngive year--year animation shares donations country:2019, largest summed donation amount came fromthe UK (11% sample 41% donations)UK (11% sample 41% donations)USA (30% sample 37% donations).USA (30% sample 37% donations).Across years:USA represents largest amount donations,USA represents largest amount donations,UK close second,UK close second,, UK ‘punches far weight.’ Note UK share may understated, UK donors claim matching ‘Gift Aid’ report part donation.17Again, raw difference may reflect differences income life circumstances among survey respondents different countries. outsized UK share also seems driven large outlying donations – Winsorise donations 100K USD, UK longer overperforms.shown ‘donations 2019’ (across years). However, suggesting provides direct evidence differences EA generosity country. return presenting ‘controlled descriptive picture’ modeling work.","code":"\neas_20$don_19_p1 <- as.numeric(eas_20$donation_2019_c+1)\n#adapting from EA survey 2019 Rscript_analysis.md\n\ndonation_2019_c <- eas_20$donation_2019_c\n\nrequire(scales)\n\ndon_breaks <- c(50, 100, 200, 300, 500,  1000, 2500, 5000, 10000, 25000, 50000, 100000, 250000, 500000, 1000000, 2500000)\n\neas_20 %<>%\n  rowwise() %>%\n      mutate(donation_2019_c_50 = max(donation_2019_c, 50)) %>%\n  ungroup\n\n(\n  donhist_19 <- eas_20 %>%\n    hist_plot_lscale(eas_20$donation_2019_c_50, breaks = don_breaks) +\n    geom_vline_mean(donation_2019_c) +\n    geom_vline_med(donation_2019_c) +\n    geom_vline_90(donation_2019_c) +\n    labs(title=\"Histogram of 2019 Donations\", x=\"2019 $ Donations (bottom-coded at 50)\", y = \"Number of respondents\")\n)\n# Todo (medium importance): Overlay a display of 'overall percentage shares' ... so we know where the 80th and 90th percentile are, etc.\nrequire(treemapify)\n\ngeom_treemap_opts <- list(treemapify::geom_treemap(alpha = 0.7),\n  geom_treemap_text(fontface = \"italic\", colour = \"white\", place = \"centre\",\n                    grow = TRUE, min.size = 1 ),\n  theme(legend.position = \"none\",\n        plot.title = element_text(hjust = 0.5))\n  )\n\n(\n  don_share_by_size <- eas_20 %>% select(donation_2019_c, donation_2019_c_split) %>%\n  group_by(donation_2019_c_split) %>%\n  summarise(total_don = sum(donation_2019_c, na.rm=TRUE)) %>%\n  mutate(don_share = round(total_don/sum(total_don)*100)) %>%\n  filter(!is.na(donation_2019_c_split)) %>%\n  ggplot(aes(area = total_don, fill= donation_2019_c_split,\n             # Include percentage of total donation\n             label = paste(donation_2019_c_split, paste0(don_share, \"%\"), sep = \"\\n\"))) +\n    geom_treemap_opts +\n  ggtitle(\"Share of total 2019 donation amount, by donation size\")\n)\n#library(treemapify)\n\n(\n  don_by_career <- eas_20 %>% select(career_, donation_2019_c) %>%\n  group_by(career_) %>%\n      filter(!is.na(career_)) %>%\n  summarise(total_don = sum(donation_2019_c, na.rm=TRUE),\n            n = n()) %>%\n  mutate(don_share = round(total_don/sum(total_don)*100),\n         freq = n/sum(!is.na(eas_20$career_))\n         ) %>%\n\n  ggplot(aes(area = total_don , fill=freq,\n             # Include percentage of total donation\n             label = paste(career_,\n                           paste0(don_share, \"%\"),\n                           paste0(\"(Pop:\", round(freq*100) , \"%)\"),\n                                  sep = \"\\n\"))) +\n  geom_treemap_opts +\n   # theme(legend.position = \"bottom\") + #todo -- add title to legend explaining that it's the survey pop; get better colors for this\n  scale_fill_continuous(name = \"Frequency\",\n                        label = scales::percent, trans = \"reverse\") +\nlabs(title= \"Share of 2019 donations by career path\",  subtitle = \"(Share of survey population in parentheses; darker = larger share)\")\n)\ncareer_tab <- eas_20 %>%\n    mutate(Career = na_if(career_, \"na\")) %>%\n      filter(!is.na(Career)) %>%\ntabyl_ow_plus(Career, caption=\"Shares in each career path\",\n              title_case = TRUE)\n #Todo: the right column needs to be x100 or say 'share' instead of 'percent'\ngrp_sum <- function(df, xvar, yvar, groupvar) {\n  df %>%\n      dplyr::select({{xvar}}, {{yvar}}, {{groupvar}}) %>%\n      group_by({{groupvar}}) %>%\n      drop_na({{xvar}}, {{yvar}}, {{groupvar}}) %>%\n      summarise(\n                      mn_y = mean({{yvar}}),\n                      mn_x = mean({{xvar}}),\n                      med_y = median({{yvar}}),\n                      med_x = median({{xvar}}),\n                      se_y = sd({{yvar}}, na.rm=TRUE)/sqrt(length({{yvar}})),\n                      se_x = sd({{xvar}}, na.rm=TRUE)/sqrt(length({{xvar}}))\n                      ) %>%\n      group_by({{groupvar}}) %>%\n    # Calculate confidence intervals\n      mutate(\n              lower = max(0, mn_y - 1.96*se_y),\n              upper = mn_y + 1.96*se_y\n              )\n}\n\nplot_grp <- function(df, groupvar, labsize=4, labangle=90, force = 1, fp = 1, mo=10, bp=1, arrow=NULL) {\n  df %>%\n    ggplot(aes(x=mn_x, y=mn_y, label = {{groupvar}})) +\n  geom_point() +\n  geom_abline(intercept = 0, slope = 0.1, colour=\"violetred1\") +\n  geom_smooth(method=lm, alpha=0.7) +\n  geom_errorbar(aes(ymin = lower,\n                      ymax = upper), alpha=0.7) +\n  scale_y_continuous( oob = scales::squish) +\n    scale_x_continuous( oob = scales::squish) +\n  ggrepel::geom_text_repel(\n    size = labsize, angle = labangle, max.overlaps=mo, force=1, force_pull = fp,\n                           box.padding = bp,\n                           arrow = arrow,\n    color=\"brown\", alpha=0.75)\n    }\n(\n  don_inc_career_plot <- eas_20 %>%\n     mutate(Career = na_if(career_, \"na\")) %>%\n      filter(!is.na(Career)) %>%\n  grp_sum(income_c_imp_bc5k, donation_2019_c, Career) %>%\n  plot_grp(Career, labsize=3) +\n  xlab(\"Mean income in USD (imputed if <5k/missing)\") +\n  ylab(\"Mean donations, CIs\") +\n      scale_y_continuous(limits=c(-10000, 30000),  oob = scales::squish)\n)\n#p_load(treemapify)\n\n(\n  don_share_by_income <- eas_20 %>%\n    select(donation_2019_c, income_c_imp_bc_k, income_c_imp_split) %>%\n    filter(!is.na(income_c_imp_bc_k)) %>%\n  group_by(income_c_imp_split) %>%\n\n    summarise(total_don = sum(donation_2019_c, na.rm=TRUE),\n            n = n()) %>%\n\n  mutate(don_share = round(total_don/sum(total_don)*100),\n         freq = n/sum(!is.na(eas_20$income_c_imp_split))) %>%\n\n  ggplot(aes(area = total_don, fill= freq,\n             # Include percentage of total donation\n             label = paste(income_c_imp_split,\n                           paste0(don_share, \"%\"),\n                           paste0(\"(Pop:\", (round(freq*100, 1)) , \"%)\"),\n                           sep = \"\\n\"))) +\n  geom_treemap_opts +\n    scale_fill_continuous(name = \"Frequency\",\n                        label = scales::percent, trans = \"reverse\") +\nlabs(title= \"Share of 2019 donations by income groups\",  subtitle = \"(Share of survey population in parentheses; darker = larger share)\")\n)\nearn_tab <- eas_20 %>%\ntabyl_ow_plus(income_c_imp_split)\n#p_load(treemapify)\n\n(\n  don_share_country <- eas_20 %>% select(donation_2019_c, country_big) %>%\n  group_by(country_big) %>%\n    summarise(total_don = sum(donation_2019_c, na.rm=TRUE),\n            n = n()) %>%\n  mutate(don_share = round(total_don/sum(total_don)*100),\n         freq = n/sum(!is.na(eas_20$country))) %>%\n    ungroup() %>%\n  filter(don_share != 0 & !is.na(country_big)) %>%\n  ggplot(aes(area = total_don, fill= freq,\n             # Include percentage of total donation\n            label = paste(country_big,\n                           paste0(don_share, \"%\"),\n                           paste0(\"(Pop:\", op(round(freq*100, 0)) , \"%)\"),\n                           sep = \"\\n\"))) +\n    geom_treemap_opts +\n     #scale_fill_continuous(name = \"Frequency\", label = scales::percent, trans = \"reverse\") +\n     scale_fill_continuous(name = \"Frequency\",\n                        label = scales::percent, trans = \"reverse\") +\nlabs(title= \"Share of 2019 donations by country\",   subtitle = \"(Share of survey population in parentheses; darker = larger share)\")\n)\n#; darker = larger share\n(\n  don_share_country_all_years <- eas_all %>% select(donation_usd, country, year) %>%\n     filter(!is.na(country)) %>%\n  group_by(country) %>%\n\n    summarise(total_don = sum(donation_usd, na.rm=TRUE),\n            n = n()) %>%\n    ungroup() %>%\n  mutate(don_share = round(total_don/sum(total_don)*100),\n         freq = n/sum(!is.na(eas_all$country))) %>%\n\n  filter(don_share > 0.1) %>%\n  mutate(country = snakecase::to_title_case(country)) %>%\n  ggplot(aes(area = total_don, fill= freq,\n             # Include percentage of total donation\nlabel = paste(country,\n                           paste0(don_share, \"%\"),\n                           paste0(\"(Pop:\", op(round(freq*100, 0)) , \"%)\"),\n                           sep = \"\\n\"))) +\n  geom_treemap_opts +\n       scale_fill_continuous(name = \"Frequency\",\n                        label = scales::percent, trans = \"reverse\") +\n  theme(legend.position = \"none\",\n        plot.title = element_text(hjust = 0.5)) +\n  labs(title= \"Share of total (all years) donation amounts by country\", subtitle = \"(Share of survey population in parentheses; darker = larger share)\")\n)\n(\n  don_share_country_all_years_w <- eas_all %>% select(donation_usd, country, year) %>%\n     filter(!is.na(country)) %>%\n    rowwise() %>%\n    mutate(donation_usd_w = min(donation_usd, 100000)) %>%\n    ungroup() %>%\n  group_by(country) %>%\n\n    summarise(total_don_w = sum(donation_usd_w, na.rm=TRUE),\n            n = n()) %>%\n    ungroup() %>%\n  mutate(don_share = round(total_don_w/sum(total_don_w)*100),\n         freq = n/sum(!is.na(eas_all$country))) %>%\n\n  filter(don_share > 0.1) %>%\n  mutate(country = snakecase::to_title_case(country)) %>%\n  ggplot(aes(area = total_don_w, fill= freq,\n             # Include percentage of total donation\nlabel = paste(country,\n                           paste0(don_share, \"%\"),\n                           paste0(\"(Pop:\", op(round(freq*100, 0)) , \"%)\"),\n                           sep = \"\\n\"))) +\n  geom_treemap_opts +\n       scale_fill_continuous(name = \"Frequency\",\n                        label = scales::percent, trans = \"reverse\") +\n  theme(legend.position = \"none\",\n        plot.title = element_text(hjust = 0.5)) +\n  labs(title= \"Share of 100k-Winsorised donations by country; all years\", subtitle = \"(Share of survey population in parentheses; darker = larger share)\")\n)\n#TODO - @oska -- UK and USA in all-caps above\n#TODO - @oska -- capitalization below\n#TODO - @oska -- sort by shares below\n\n(\n  country_tab <- eas_all %>%\n    group_by(country_big) %>%\n    filter(year>2014) %>%\n   mutate(\n          year_2020 = case_when(\n            year==2020 ~ \"2019 share.\",\n            TRUE ~ \"pre-2019 share.\"\n          ),\n          `Country` = str_to_title(country_big),\n          ) %>%\ntabyl(`Country`, year_2020) %>%\n adorn_percentages(\"col\")  %>%\n  .kable(digits=2, caption=\"Shares (0-1) of survey population by country; larger countries only\", label=TRUE) %>%\n    .kable_styling()\n)\n#d_anim <- \"Y\"\n\n#library(gganimate)\n\nanim_filename <- here(plots_folder, \"animated_tree_plot.gif\")\n\nif (exists(\"d_anim\")) {\nif (d_anim == \"Y\") {\n\nanimated_dons_country <- eas_all %>% select(year, donation_usd, country_big) %>%\n  group_by(year, country_big) %>%\n  filter(year>2014) %>%\n  summarise(total_don = sum(donation_usd, na.rm=TRUE)) %>%\n  mutate(don_share = round(total_don/sum(total_don)*100)) %>%\n  ggplot(aes(area = total_don, fill= country_big,\n           # Include percentage of total donation\n           label = paste(country_big, paste0(don_share, \"%\"), sep = \"\\n\"))) +\n  geom_treemap_opts +\n  ggtitle(\"Share of total 2019 reported donation amounts by country\")\n\n\nanim <- animated_dons_country + transition_states(year,\n                                      state_length = 3) +\n  ggtitle(\"Share of total {closest_state} reported donation amounts by country\")\n\ngganimate::anim_save(anim_filename, anim)\n\nanim\n\n}\nelse{\n  knitr::include_graphics(anim_filename)\n}\n}## Error: The animation object does not specify a save_animation method\nif (!exists(\"d_anim\")){\n  knitr::include_graphics(anim_filename)\n}\n#Todo (medium importance): slo"},{"path":"eas_donations.html","id":"donshares","chapter":"3 Donation","heading":"3.3.1 Donation (shares) versus income and GWWC pledge","text":"2018 post:also looked percentages pre-tax income EAs donating, based 1,563 EAs disclosed income donation data. previous years, EAs donating significantly less 10% Giving Can Pledge… However, graph shows, marked ‘bump’ donors giving around 10% figure, perhaps due Giving Can Pledge target around amount, due figure’s wider popularity target (e.g. tithing)., depict donations share income. histograms first positive reported incomes, next previously discussed income imputation. blue vertical line depicts share total (imputed) income donated respondents, green line depicting median red line 90th percentile. plots show similar patterns 2018.noticeable spike 10% likely reflects GWWC pledge (return ). noted , 20% EAs reported donation 10% (imputed) income 2019. 36% reported amount 5%.donations relate income, relationship differ mention took Giving Can (10%) pledge?first simply plot reported donations income, simply dividing individuals (points) whether mention taken GWWC pledge.give scatterplot reported donations income, faceted GWWC pledge, separate locally-smoothed conditional means (95% confidence intervals conditional means). (figure 2019 donations .)Unsurprisingly, higher incomes, took GWWC pledge tend report donating . average, GWWC pledgers report giving throughout whole range income, 95% confidence intervals distinct range.*, [ agrees reported 2019:][ Note smaller group respond GWWC pledge prompt provide donation response seems resemble non-pledgers. thus lump groups together subsequent analysis.]Next plot donations shares income income non-GWWC pledgers (combined non-responders) GWWC pledgers. median group given dashed blue line, dashed red line represents 10 percent income.relationship income ‘share income donated’ dips lowest incomes, mass ‘substantial donors’ curve fairly flat, seems increase higher incomes. expected, GWWC pledgers tend donate closer 10% income rest.year substantially larger shares report made GWWC pledge report donating 10% . , tabulate donation year ’whether report ever made GWWC pledge, individuals report income 5000 USD report zero positive donations:\nTable 3.3: GWWC pledgers: Don. 10%+ income survey year (exclusions: see text)\nAmong report ever taken GWWC pledge (report donations, excluding reporting incomes 5000 USD), less half report donating 10% past year. However, may underestimate, people reporting pledged /next year, donation reports previous year.18Our 2018 post report found rate slightly higher 50%.** closer figure ‘plan donate current year’, hovers around 50%.[ rates report may also lower reported 2018 post exclude earning less 5000 USD.][ online appendix (web link also plot donations income self-reported level engagement (1-3 versus 4-5). Unsurprisingly, report greater engagement tend donate .]","code":"\nscale_x_set <- list(scale_x_continuous(limits=c(0,0.35), n.breaks=20))\n\n(\n  don_share_inc_19_hist <- eas_20 %>%\n    hist_plot(don_share_inc_19) +\n    geom_vline_med(eas_20$don_share_inc_19, tgap=0.01) +\n    geom_vline_mean(tot_don/tot_inc, tgap=0.01, label = \"Overall share\") +\n        geom_vline_90(eas_20$don_share_inc_19, tgap=0.005) +\n    scale_x_set +\n    labs(title=\"2019 Donations/Income (no imputing)\", x=\"2019 Donations/income\", y=\"Number of respondents\") +\n     ylim(0, 300)\n)\n##Todo -- Medium priority: mean is missing\n# todo -- low priority: make the above histogram bigger, it's smaller than the rest\n\ndon_share_inc_19_hist_imp <- eas_20 %>%\n    hist_plot(don_share_inc_19_imp_bc5k) +\n    geom_vline_mean(tot_don/tot_inc_imp_bc, tgap=0.01, label = \"Overall share\") +\n    geom_vline_med(eas_20$don_share_inc_19_imp_bc5k, tgap=0.005) +\n        geom_vline_90(eas_20$don_share_inc_19_imp_bc5k, tgap=0.005) +\n    scale_x_set +\n    labs(title=\"2019 Donations/Income (with imputing)\", x=\"2019 Donations/income (with imputing)\", y = \"Number of respondents\") +\n  ylim(0, 300)\n\ndon_share_inc_19_hist_imp\n#Todo -- Medium priority(@oska): convert to 'share of respondents', add cumulative plot\ndon_share_inc_19_hist_imp %>% ggplotly()\n#Donations and donation shares -- scatterplots by income and GWWC 'action'\n\np_load(ggpubr)\n\nop_ax <- function(x) round(as.numeric(x), digits=2)\n\nscale_y_don <- scale_y_log10(\n    name = \"Donation amount (bottom-coded at $50)\",\n    # labels = scales::dollar,\n    labels = scales::label_number_si(prefix = \"$\"),\n    n.breaks = 10,\n    limits = c(50, NA)\n  )\n\ndon_income_gwwc_sp <- eas_all %>%\n  filter(year==2020) %>%\n    ggpubr::ggscatter(\n      x = \"income_c_imp_bc_k\", y = \"donation_usd_min50\", color = \"d_gwwc_ever\", size = 0.8, xlab = \"Income in $1k USD (imputed where missing or lt 5k)\", repel = TRUE, palette = \"jco\", yscale = \"log10\", xscale = \"log10\", add = \"loess\", add.params = list(color = \"black\", fill = \"lightgray\"), conf.int = TRUE\n    ) +\n    labs(title = \"Donations by income (log scales)\") +\n    scale_x_log10(name=\"Income in $1K USD (imputed if <5k/missing)\", labels = op_ax, n.breaks=5, limits=(c(5,5000)))  +\n    labs(colour = \"Mentioned taking GWWC pledge\") +\n    scale_y_don  +\n    theme(axis.text.x = element_text( angle = 90, vjust = 0.5, hjust = 1 ))\n\n\ndon_income_gwwc_sp_gwwc <- eas_all %>%\n  filter(year==2020) %>%\n  ggplot(aes(x = income_c_imp_bc_k, y = donation_usd_min50, color = d_gwwc_ever)) +\n  geom_point(size = 1, alpha = 0.7) + # draw the points\n  geom_smooth(aes(method = 'loess',\n                  fill = d_gwwc_ever)) + # @Oska -- note I am using  local smoothing here.\n  scale_x_log10(name = \"Income in $1K USD (imputed if below 5k/missing)\", n.breaks = 5, limits = c(5, 5000)) +\n  scale_y_log10(\n    name = \"Donation amount (bottom-coded at $50)\",\n    # labels = scales::dollar,\n    labels = scales::label_number_si(prefix = \"$\"),\n    n.breaks = 10,\n    limits = c(50, NA)\n  ) +\n  scale_color_discrete(name = \"GWWC pledge\") +\n  scale_fill_discrete(guide = \"none\") +\n  theme(axis.text.x = element_text( angle = 90, vjust = 0.5, hjust = 1 ),\n        legend.position = c(.87,.15),\n        legend.background = element_rect(fill=alpha('blue', 0.01)))\n\n##Todo -- Medium priority - clean up the above a bit more...  get the axes better so that we can really see the 'large mass in the middle a bit better. Maybe slightly smaller dots and bolder smoothed lines, perhaps different colors for the CI shading for each\n# - perhaps use geom_pointdensity with different shapes to indicate regions of \"larger mass\"\n\n# #TODO -- Add some layer to better capture the masses *exactly at* 10pct\n\n# REVIEW\n# We should note that this doesn't include those who donate nothing due to the log scale (pseudo log scale is a bit weird here as well)\nrequire(ggpointdensity)\n\ndon_share_income_by_X  <- eas_all %>%\n  filter(year==2020) %>%\n  mutate(income_c_imp_bc5k_k = income_c_imp_bc5k/1000) %>%\n  rowwise() %>%\n  mutate(don_share_inc_19_imp_bc5k = min(don_share_inc_19_imp_bc5k, 0.4)) %>%\n  ungroup() %>%\n   group_by(d_gwwc_ever_0) %>%\n  mutate(med_gwwc = median(don_share_inc_19_imp_bc5k, na.rm=TRUE)) %>%\n   ungroup() %>%\n   group_by(engage_high_n) %>%\n    mutate(med_eng = median(don_share_inc_19_imp_bc5k, na.rm=TRUE)) %>%\n  ggplot(aes(x = income_c_imp_bc5k_k, y = don_share_inc_19_imp_bc5k)) +\n  ggpointdensity::geom_pointdensity(adjust=0.25) +\n  geom_smooth(method = \"loess\") +\n #geom_hline_med(y) +\n  geom_hline(yintercept=0.1, linetype=\"dashed\", size=0.5, color = \"red\") +\n  scale_y_continuous(labels = scales::label_percent(accuracy = 1L)) +\n  scale_x_log10(breaks = scales::log_breaks(n=7)) +\n  scale_color_viridis_c(\"density of respondents\") +\n  xlab(\"Income in $1K USD (imputed if missing, bottom-code at 5k)\") +\n  theme(axis.title.x = element_text(size = 10)) +\n  ylab(\"Donations/Income (top-code at 40%)\")\n\n\ndon_share_income_by_engage_sp <- don_share_income_by_X +\n       geom_hline(aes(yintercept=med_eng), linetype=\"dashed\", size=0.5, color = \"blue\") +\n   facet_wrap(~engage_high_n, nrow=3)  +\n    ylab(\"Donations/Income (top-coded at 50%)\") +\n  labs(title=\"By 'High-engagement': 2019 'Don. shares of income' by income (w. imputing)\")\n\n\ndon_share_income_by_gwwc_sp <- don_share_income_by_X +\n       geom_hline(aes(yintercept=med_gwwc), linetype=\"dashed\", size=0.5, color = \"blue\") +\n   facet_wrap(~d_gwwc_ever_0)  +\n  labs(title=\"By GWWC: 2019 'Don. share of income' by income (w/ imputing)\")\ndon_income_gwwc_sp\ndon_income_gwwc_sp_gwwc\ndon_share_income_by_gwwc_sp\n(\n  tab_don_by_year_pledge <- eas_all %>%\n  filter(!is.na(d_don_10pct_bc5k) & year>=2015) %>%\n  mutate(`Survey year` = year,\n         d_don_plan_10pct = as.numeric(donation_plan_usd/income_c_imp_bc5k >=0.1),\n         d_don_plan_10pct = if_else(year<2018, NaN, d_don_plan_10pct)) %>%\n  group_by(d_gwwc_ever_0, `Survey year`) %>%\n  summarise(n = n(), \"Donated 10% of income\" = mean(d_don_10pct_bc5k),\n            \"Donated 10% of income (plan)\" = mean(d_don_plan_10pct, na.rm=TRUE)\n            ) %>%\n  rename(\"Ever GWWC pledge\" = d_gwwc_ever_0) %>%\n  adorn_rounding(digits = 2) %>%\n  kable(caption = \"GWWC pledgers: Don.  10%+ of income by survey year (exclusions: see text)\", label=TRUE) %>%\n  .kable_styling()\n)"},{"path":"eas_donations.html","id":"emp-student","chapter":"3 Donation","heading":"3.3.2 Employment and student status","text":"present income donation statistics “statuses” 50 respondents forest plot (full table statistics group can found bookdown appendix).* forest plots subsection, blue line presents simple linear best-fit points, red line represents 10% donation rate.19Donations generally track income aggregation, groups possibly ‘-performing’ ‘-performing’; return descriptive modeling.20","code":"\nse <- function(x) sqrt(var(x)/length(x))\n\n\nsumstatvec <- c(\"{median}\", \"{p10}-{p90}\", \"{mean} [{se}] ({sd})\")\ndoninclabs <- list(income_k_c ~ \"Income in $1000 USD\",\n                   donation_2019_c ~ \"2019 donation (in USD)\",\n                   donation_2020_c ~ \"2020 planned donation\")\ndon_inc_by_student <-\neas_20 %>%\n  group_by(status_) %>%\n  mutate(\n    status_ = as.character(status_),\n    large_group = case_when(\n                          n()<50 ~ \"Other\",\n                           TRUE ~ status_)\n    ) %>%\n  ungroup() %>%\n  dplyr::select(income_k_c, donation_2019_c, donation_2020_c, large_group) %>%\n  tbl_summary(by = large_group,\n              type = c(all_continuous()) ~ \"continuous2\",\n      statistic = list(all_continuous() ~ sumstatvec),\n        label = doninclabs,\n                  missing = c(\"no\") ) %>%\n      bold_labels() %>%\n    add_n() %>%\n    add_overall()\n\n\n#TODO: High -- fix the column labels\n#todo (low) -- we use this several times and it's a good format; let's functionalise it\n#Todo (medium): Bootstrapping the SE of the median would be nice, see, e.g., https://clayford.github.io/dwir/dwr_12_generating_data.html\nlibrary(ggrepel)\n#\n# 1.summarize donation and income (mean and 95pct CI for each) by status_\n# 2. plot median (and mean) donation by income for each group (income lowest to highest)\n# 3. fit a line/curve of donation by income for each group (do for ) -- replace with the regression line based on the population not the groups\n# 4. Add error bars (for donations, not income) -- hard to do for median, though\n\n#TODO -- High Priority: Make this nice in the ways discussed (@oska it seems you have already started this)\n\n# why are the error bars not surrounding the point?\n# make it pretty (use your judgment), fix labels, add median colored dot,\n\n\n(\n  don_inc_status_plot <- eas_20 %>%\n     mutate(\n  status_ = str_replace_all(\n    status_, c(\"_\" = \" \")\n    )\n  ) %>%\n  grp_sum(income_c_imp_bc5k, donation_2019_c, status_) %>%\n  plot_grp(status_, labsize=3, fp=0.3, force=5, mo=20, bp=1.5,\n           arrow = arrow(length = unit(0.02, \"npc\"))\n           ) +\n  xlab(\"Mean income in USD (imputed if < 5k/missing)\") +\n  ylab(\"Mean donations, 95% CIs\") +\n      scale_y_continuous(limits=c(-10000, 30000),  oob = scales::squish)\n)\n# Todo (low): Plot regression line for full pop\n# Todo: HIGH -- get this to look nicer, label it better, add better axis breaks (every 5k for donation, every 20k for income)\n#Todo (Medium) -- add plots for the medians\n#Todo"},{"path":"eas_donations.html","id":"don-by-country","chapter":"3 Donation","heading":"3.3.3 Donations by country","text":"Donations income countryWe report similar income donation statistics countries 50 respondents:\n          1\n          \n           \n          c(\"Median\", \"10%-90%\", \"Mean [se] (SD)\")\n          , plot donations income country residence countries largest number EA respondents. fit simple best-fit (least-squares) line blue, add red line depicting 10% donation rate. , donations generally track income, -performers (see later modeling). UK clearly contains notable donation outliers, leading large confidence intervals UK mean (truncated 30000 USD).","code":"\n(\n  don_income_by_ctry <-\n    eas_20 %>%\n        dplyr::select(income_k_c, donation_2019_c, donation_2020_c, country_big) %>%\n        tbl_summary( by = country_big,\n                     sort = all_categorical() ~ \"frequency\", #reverse this ordering or maybe reverse sort by average income\n                      type = c(all_continuous()) ~ \"continuous2\",\n      statistic = list(all_continuous() ~ sumstatvec),\n        label = doninclabs,\n            missing = c(\"no\")\n        ) %>%\n    bold_labels() %>%\n    add_n() %>%\n    add_overall()\n)\n#todo (medium?): make a stem-leaf thing here\n\n#todo  (High): add *medians* to the above\n  # don_inc_status_plot <- eas_20 %>%\n  # dplyr::select(status_, donation_2019_c, income_k_c) %>%\n  # group_by(status_) %>%\n  #     drop_na(status_, donation_2019_c, income_k_c) %>%\n  #     summarise(across(c(donation_2019_c, income_k_c),\n  #                     list(mean=mean,\n  #                          median=median,\n  #                          se = ~sd(.x)/sqrt(length(.x))))) %>%\n  #   group_by(status_) %>%\np_load(ggimage)\n\ncountry_codes <- tibble(country = c(\"Australia\", \"Canada\", \"France\", \"Germany\", \"Netherlands\", \"Other\", \"United Kingdom\", \"USA\"),\n                        code = c(\"ac\", \"ca\", \"fr\", \"de\", \"nl\", \"yt\", \"gb\", \"us\"))\n\n(\n  don_inc_country_plot <-  eas_20 %>%\n  grp_sum(income_c_imp_bc5k, donation_2019_c, country_big) %>%\n  left_join(., country_codes, by = c(\"country_big\" = \"country\")) %>%\n  plot_grp(country_big) +\n  xlab(\"Mean income in USD (imputed if <5k/missing)\") +\n  ylab(\"Mean donations, CIs\") +\n     scale_y_continuous(limits=c(-3000, 30000),  oob = scales::squish)\n)\n  #+ggimage::geom_flag()\nplot_box_pt_viol <- function(df, yvar, groupvar, notch=TRUE) {\n  df %>%\n   dplyr::select({{yvar}}, {{groupvar}}) %>%\n      ggplot() +\n      aes({{groupvar}}, {{yvar}}) +\n    geom_point(size = 0.30, colour = \"grey\", position = position_jitter(seed = 42,  width = 0.3, height = 0.01)) +\n      geom_boxplot(alpha=0.7, notch=notch,  color=\"black\") +\n      geom_violin(alpha=0.4, color = \"pink\") +\nscatter_theme +\n  scale_y_log10()\n}\n\n(\n  don_by_country_viol_20 <-  eas_20 %>%\n       plot_box_pt_viol(donation_2019_c, country_big, notch=TRUE) +\n  labs(title = \"Donation amounts by country (2019)\")\n)\n\n(\n  don_by_country_viol_all <-  eas_all %>%\n           plot_box_pt_viol(donation_usd, where_live_cat, notch=TRUE) +\n  labs(title = \"Donation amounts by country grouping (2013-2019)\")\n)\n\n\n(\n  don_by_yr_viol_all <-  eas_all %>%\n    mutate(year=as.factor(year)) %>%\n    plot_box_pt_viol(donation_usd, where_live_cat, year) +\n      ggplot() +\n  labs(title = \"Donation amounts by year\")\n)"},{"path":"eas_donations.html","id":"donations-age-and-years-in-ea","chapter":"3 Donation","heading":"Donations, age and years in EA","text":"Next, consider donations may increase decrease ‘time--EA’ (.e., ‘tenure’). discussed posts bookdown chapters, may reflecting differences stays EA (continues responding survey) much reflects people change year year., plot donations tenure, breaking age groups.Donations appear positively associated tenure nearly age groups, perhaps flattening 5 years, age groups. Donations also appear positively associated age level tenure. return descriptive (causally-suggestive) models.next report comparable chart donation share income:share income, see donations positively associated time EA, least older age groups.21","code":"\ndon_by_tenure_facet_age <-\n  eas_all %>%\n  filter(year==2020) %>%\n  filter(!is.na(age_ranges)) %>%\n  ggplot() +\n  aes(x = tenure, y = donation_usd_min50) +\n geom_point(size = 0.15, colour = \"#0c4c8a\", position = position_jitter(seed = 42,  width = 0.1, height = 0.001)) +\n  geom_smooth(span = 0.75) +\n  scatter_theme +\n  facet_grid(vars(), vars(age_ranges), scales = \"free\") +\nlabs(title = \"2019 donation by time in EA\",\n     subtitle = \"Faceted by Age ranges\") +\n    labs(x = get_label(eas_20$tenure)) +\n  scale_y_don\n\ndon_by_tenure_facet_age\ndon_by_tenure_facet_age %>% ggplotly()\ndonshare_by_tenure_facet_age <- eas_20 %>%\n  filter(!is.na(age_approx_ranges)) %>%\n  ggplot() +\n  aes(x = tenure, y = don_share_inc_19_imp_bc5k) +\n geom_point(size = 0.15, colour = \"#0c4c8a\", position = position_jitter(seed = 42,  width = 0.1, height = 0.001)) +\n  geom_smooth(span = 0.75) +\n  scatter_theme +\n  facet_grid(vars(), vars(age_approx_ranges), scales = \"free\") +\nlabs(title = \"2019 donation as share of (imputed) income by time in EA\",\n     subtitle = \"Faceted by Age ranges\") +\n    labs(x = get_label(eas_20$tenure)) +\n    ylab(element_blank()) +\n  ylim(0, 0.3)\n\ndonshare_by_tenure_facet_age\ndonshare_by_tenure_facet_age %>% ggplotly"},{"path":"eas_donations.html","id":"by-referrer","chapter":"3 Donation","heading":"By referrer","text":"Next, consider donations vary ‘referrer’ (.e., link) took individual EA survey., blue line gives linear fit (group means), red line slope donating 10% income.referrer level see strong association income donation, however, confidence intervals wide. 80000 Hours social media appear ‘-performers’, groups referrers confidence intervals wide make strong inferences. (Furthermore, always, differences may reflect underlying differences samples collected referrers, differences ‘time--EA’.)","code":"\n(\n  don_inc_referrer_plot <-  eas_20 %>%\n  grp_sum(income_c_imp_bc5k, donation_2019_c, referrer_cat) %>%\n  plot_grp(referrer_cat) +\n    scale_y_continuous(limits=c(0, 15000), oob = scales::squish) +\n  xlab(\"Mean income by group in USD (imputed if <5k/missing)\") +\n    ylab(\"Mean donations by group, CIs\") +\n    ggtitle(\"Donation by income and referrer\")\n)\n# (Todo?) I wonder if we should get rid of the blue line and gray line for this … or replace it with one from an individual-based regression"},{"path":"eas_donations.html","id":"donation-and-income-trends-in-ea","chapter":"3 Donation","heading":"3.4 Donation and income for recent years","text":"can consider reported amounts donated year EA survey (EAS), well average reported. However, neither can easily interpreted tell us whether EAs (individual total) donating less recent years; neither individuals total. year--year change survey responses, differential representativeness makes challenging.22(discussion can found Bookdown point).EAS response rates (response rates donation question particular) vary year--year proportion total size EA population representative, may want simply focus totals, move proportion true totals.*EAS response rates (response rates donation question particular) vary year--year proportion total size EA population representative, may want simply focus totals, move proportion true totals.*hand, suppose number responses EAS fluctuates year year proportion size EA, composition representative EA movement whole. case may reliable report mean median donations EAS respondents, combine extrapolations ‘guesstimates’ based separate estimates changes size EA (informed data including EA survey).hand, suppose number responses EAS fluctuates year year proportion size EA, composition representative EA movement whole. case may reliable report mean median donations EAS respondents, combine extrapolations ‘guesstimates’ based separate estimates changes size EA (informed data including EA survey).extent EAS response total fluctuating (independently size EA) nonrepresentative, may able make statements changes donations among particular subgroups, even within-subgroup composition may change.extent EAS response total fluctuating (independently size EA) nonrepresentative, may able make statements changes donations among particular subgroups, even within-subgroup composition may change.limitations:report totals averages ,advise caution interpreting amounts changeswe return controlled model, also subject similar limitations,defer detailed analysis question future work.plot tests depict consider year--year changes donations reported EA surveys year.23We first consider donation rates year answer donation question (reporting 0 positive amounts). give share positive responses, mean, median, 80th percentile donation, standard deviation year:\nTable 3.3: Donations year\nconsiders people answer donation questions. extreme consider non-responses reflecting people made (little ) donations, lower bound donation rates. compromise measure, probably tighter lower bound, might assume people willing report incomes generally willing answer financial questions. Thus report donations seems reasonable suspect donate big way. thus consider subset reported income, considering similar statistics modified donation variable, coded ‘0’ donation reported.\nTable 3.3: Donations year reporting income (missings coded 0)\nNext, present combined scatterplot, violin plot, stem leaf plot, depicting densities donation amounts year. present first level outcomes (log scales) ‘log (donation+1)’ outcome.linear plots tests donation amounts suggest substantial significant differences overall donations years, log specification suggest year--year differences, (log) 2019 donations significantly lower 2017 donations, even accounting multiple comparisons. return , extent, descriptive modeling.24","code":"\nlibrary(ggstatsplot)\nlibrary(pairwiseComparisons)## Error in library(pairwiseComparisons): there is no package called 'pairwiseComparisons'\n(\n  don_by_year_tab <- eas_all %>%\n    filter (year>=2015) %>%\n    sumtab(donation_usd, year, caption=\"Donations by year\", digits=c(0, 0, 2, 0, 0, 0,0)) %>%\n    kable_styling() #redundant but helps with parsing\n\n)\n(\ndon0_by_year_tab <- eas_all %>%\n  filter(!is.na(income_c) & year>2014) %>%\n  #rowwise() %>%\n  #mutate(donation_usd_0 = if_else(is.na(donation_usd), 0, donation_usd)) %>%\n  #ungroup() %>%\n  sumtab(donation_usd_0, year, caption=\"Donations by year for those reporting income (missings coded as 0)\", digits=c(0, 0, 2, 0, 0, 0, -1, 0)) %>%\n    kable_styling()\n)\n#todo  same for GWWC people (member_gwwc needs reconciling)\n\n#todo -- include a 'total donations row'. maybe plot/graph this stuff;\n(\ndon_by_year_viol_test <- eas_all %>%\n  #select(donation_usd_min50, year) %>%\n  #select(donation_usd, year) %>%\n  mutate(year = year-1) %>%\n  filter(year>2014) %>%\n  ggbetweenstats(y = donation_usd,\n                           x = year,\n                          ylab = \"Donations (USD)\",\n                 # plot.type = \"violin\", # type of plot\n                  type=\"parametric\",\n                  conf.level = 0.95,\n                # pairwise.display = \"significant\",\n                 #p.adjust.method = \"hol\",\n                 #results.subtitle = \"false\",\n    title = \"Donations by year, 2016-2020\"\n                    ) +\n    theme(legend.position=\"none\") +\n                     ylim(50, NA) +\n  scale_y_continuous(trans = \"pseudo_log\",\n                     breaks = breaks,\n                     labels = scales::dollar_format())\n)\n(\ndon_by_year_viol_test_ldon <- eas_all %>%\n  #select(donation_usd_min50, year) %>%\n  #select(donation_usd, year) %>%\n  mutate(year = year-1,\n         ldon1 = log(donation_usd+1)) %>%\n  filter(year>2014) %>%\n  ggbetweenstats(y = ldon1,\n                           x = year,\n                          ylab = \"Log (Donations +1)\",\n                 # plot.type = \"violin\", # type of plot\n                  type=\"parametric\",\n                  conf.level = 0.95,\n                # pairwise.display = \"significant\",\n                 #p.adjust.method = \"hol\",\n                 #results.subtitle = \"false\",\n    title = \"(Log) donations by donation year, 2016-2019\"\n                    ) +\n    theme(legend.position=\"none\")\n)\n#  +  geom_signif(comparisons = list(c(\"2018\", \"2019\"),  c(\"2014\", \"2019\")),   step_increase = 0.05, test = \"wilcox.test\")\n\n#%>%  ggplotly()\n\n#Below: replaced this with 'wilcox, the nonparametric test' ... but note that is on top of the tests given by the ggbetweenstats command\n#+ geom_signif(comparisons = list(c(\"2018\", \"2019\"), c(\"2017\", \"2019\"), c(\"2013\", \"2019\")),   step_increase = 0.1, test = \"wilcox.test\")"},{"path":"eas_donations.html","id":"which-charities","chapter":"3 Donation","heading":"3.5 Which charities (causes and categories) are EAs donating to?","text":"noted introduction, small share respondents report donating. group several categories summarized , reporting 429 respondents indicated least one category donations.\n(#tab:don_stats)Donations category (indicated)\nprevious years, ‘Global health development’ largest category, terms number reported donations, terms mean (median, 90th percentile) donations (give mean including zeroes, reported specific category donation)., depict amounts density donations category, vertical axis logarithmic scale. width violin plot depicts smoothed density. box, horizontal lines represent medians , lower upper margins box 25th 75th percentiles, “whisker” lines extends box largest (smallest) value 1.5 \\(\\times\\) inter-quartile range, large dots represent outlying points beyond edge whiskers.can also check whether donations cause (incidence amounts) vary whether person (ever) took GWWC pledge. , present scatterplots + violin + box plots donation (USD amounts) category, split GWWC pledge status.details plots similar previous plot (“Donation amounts category…”, see description ). However, lower upper margins (now ‘notched’) box present estimate 95% confidence interval medians (reporting least one category donations reporting GWWC status). see mainly overlap, perhaps less “EA meta organization”, GWWC pledgers seem give ., tabulate donations cause, groups. final column table presents statistical test significant differences means donation category GWWC status. (Note ‘significance stars’ implies lack statistical significance \\(p<0.10\\) level two-tailed tests).\nTable 3.4: Donations category (indicated), GWWC\nNext, , donation incidence (.e., ‘whether someone reports donation particular cause category’):\nTable 3.5: Binary: Indicated donating category, GWWC\n, differences substantial, cases, statistically significant (three stars indicates statistical significance \\(p<0.01\\)) level two-tailed test).suggested first two tables , among report charity category, took GWWC pledge tend give much average category (perhaps Long Term & AI), although none individual differences meet conventional statistical significance simple F-tests (note tests fairly low-powered due small sample sizes). second table illustrates, GWWC pledgers likely donated categories, difference statistically significant standard chi-sq tests categories except ‘Global Health Development’. can seen seen \\(\\chi^2\\) tests “Donated category” table, well uncorrected Fisher’s exact tests: \\(p=\\) 0.103 ‘Global Health Development’, \\(p<0.01\\) categories.","code":"\n#TODO - HIGH: add better cause labels to this, visualise it in a way that conveys the aggregate shares of donations counts and amounts\n #created near the top of this file\n\ndon_stats\n##TODO --\n#sort by reverse frequency of donations to a cause\n\n#TODO: bottom code and change the scale on this, time permitted\n\n(\n  don_by_cause_viol <-  eas_20 %>%\n      filter(num_named_dons>0) %>%\n      select(where_don_vars, action_gwwc_f) %>%\n      gather(cause, don, -action_gwwc_f) %>%\n      ggplot() +\n      aes(cause, don) +\n      geom_violin() +\n      geom_boxplot() +\n    ylab(\"Donation amount\") +\n    geom_point(size = 0.30, colour = \"#0c4c8a\", position = position_jitter(seed = 42,  width = 0.3, height = 0.01)) +\nscatter_theme +\n  scale_y_log10(labels = scales::label_number_si(prefix = \"$\"),\n    n.breaks = 10) +\n      scale_x_discrete(labels = function(x) str_wrap(all_char_labels, width = 10)) +\n  labs(title = \"Donation amounts by category: see description above\")\n)\n#Todo (Low to medium) ... @oska: if it's easy-ish, maybe gganimate this one across years?\n#@David: Kinda difficult to do this as the variables in where_don_vars don't seem to align with eas_all\n\n#@oska -- it is there, in variables like `donate_[charity]_year` but it would require considerable data cleaning work. Will ask/see if it's worth it.\n#TODO -- High Priority (@oska): clean up the below to be more readable, add the mean and a CI for the mean\n\n(\n  don_by_cause_viol_gwwc <-  eas_20 %>%\n      filter(num_named_dons>0 & !is.na(action_gwwc_f)) %>%\n      select(where_don_vars, action_gwwc_f) %>%\n      gather(cause, don, -action_gwwc_f) %>%\n      ggplot() +\n      aes(cause, don, color=action_gwwc_f) +\n      scale_color_discrete(name=\"GWWC pledge\",\n                         labels=c(\"No\", \"Yes\")) +\n      geom_violin() +\n      geom_boxplot(notch=TRUE) +\n    geom_point(size = 0.30, colour = \"#0c4c8a\", position = position_jitter(seed = 42,  width = 0.3, height = 0.01)) +\nscatter_theme +\n  scale_y_log10() +\n      scale_x_discrete(labels = function(x) str_wrap(all_char_labels, width = 10))\n)\ndon_stats_by_gwwc\nddon_stats_by_gwwc\n# #TODO -- High Priority (@oska): -- the below is a mess... we want both the frequency table and test for each of these ... but how to do it. I feel like I've done this before. maybe the function in rstuff `fisherme` would help?\n\n# TODO (high-medium):  Once we get it to work, do similar plots and tests for different 'which cause' comparisons ...\n\nfisher_cats <- eas_20 %>% filter(num_named_dons>0) %>%\n  dplyr::select(all_of(where_don_vars)) %>%\n  lapply(janitor::fisher.test, y = eas_20$action_gwwc_f[eas_20$num_named_dons>0], simulate.p.value=TRUE)"},{"path":"eas_donations.html","id":"plan-actual","chapter":"3 Donation","heading":"3.6 Donations: plans and aspirations versus actual (reported) donations","text":"people meet exceed amount intended planned donate next year? factors relate ? surveys provide evidence.recent surveys, asked “[current year] much currently plan donate?”. also ask “[previous year], roughly much money donate?”.EA surveys released various points year:2017, survey released April; thus ‘plan’ reported 1/3 way year (slightly later, depending response time).2017, survey released April; thus ‘plan’ reported 1/3 way year (slightly later, depending response time).2018, survey released May.2018, survey released May.2019, released August, 3/4 way throughout year.2019, released August, 3/4 way throughout year.Thus, years, year--year comparison may tell us something whether people lived plans. particularly relevant 2017 2018 surveys, also relevant 2019-20, particularly donations tend clustered years’ end (e.g., Christmas giving, Giving Tuesday November).** clustering seems hold true giving USA overall. E.g., Charity Navigator (citing ‘Digital giving index’) states 31% annual giving occurred month December.2019 post wrote:also asked respondents much planned donate 2019. … median planned donation 2019 1,074.98 USD among EAs, 3,000 USD among full-time employed non-student EAs., compare 2019 report planned-2019 donation reports 2020 EAS actual 2019 donations. report several different groupings , well pairings surveys.","code":"\n#filtering and shaping functions\n\nf_don_plan_by_year <- function(df=eas_all) {\n  #adjusting for comparing planned and actual donation for same year in question (but not always for 'same individuals')\n  {df} %>%\n  select(year, donation_usd, donation_plan_usd) %>%\n  gather(donation_type, value, -year) %>%\n  mutate(year = if_else(donation_type == \"donation_plan_usd\", year, year-1)) %>%\n  mutate(year = fct_rev(as.factor(year)),\n         donation_type = fct_recode(donation_type,\n                                    \"Planned Donation\" = \"donation_plan_usd\",\n                                    \"Donation\" = \"donation_usd\")) %>%\n  filter(year %in% c(2016, 2017, 2018, 2019, 2020))\n}\n\nf_don_18_20 <- function(df=eas_all) {\n  #this is for comparing to 'planned donation' (next year)\n  df %>%\n dplyr::filter(year %in% c(\"2018\", \"2019\",\"2020\")) %>%\n  group_by(year) %>%\n  select(year, donation_usd, donation_plan_usd) %>%\n  gather(donation_type, value, -year)\n}\n\nf_next_d_don <- function(df=eas_all) {\n  #same as f_don_18_20, but instead of gather it constructs a differenced variable `next_d_don`\n  df %>%\n dplyr::filter(year %in% c(\"2018\", \"2019\",\"2020\")) %>%\n  select(year, donation_usd, donation_plan_usd) %>%\n  transmute(next_d_don = donation_plan_usd - donation_usd)\n}\n#Construct key tibbles to use in comparing planned and actual for 2019\n\ndemographics <- c('age', 'gender', 'country', 'employ_status')\n\n# Filtering for those present in both datasets\nplanned_actual_2019 <- eas_all %>%\n  filter(year %in% c(2019, 2020) & !is.na(ea_id)) %>%\n  select(ea_id, donation_usd, donation_plan_usd, year) %>%\n  distinct() %>%\n  group_by(ea_id) %>% filter(n() == 2) %>% # Filter for those appearing in both years\n  pivot_wider(names_from = \"year\",\n              values_from = c(\"donation_usd\", \"donation_plan_usd\")) %>%\n  # Remove unnecessary columns\n  select(-donation_plan_usd_2020, -donation_usd_2019) %>%\n#  drop_na() %>% # Ensure that each participant had planned donation from 2019 and actual donation from 2020 # TODO - fix, this is dropping everything\n  rename(donation_2019 = donation_usd_2020,\n         planned_donation_2019 = donation_plan_usd_2019) %>%\n  # Add demographic information\n  left_join(., select(eas_20_cy, all_of(demographics), ea_id, action_gwwc, start_date, end_date, income_c), by = \"ea_id\")\n\n#Convert to long format for ggplot\nplanned_actual_2019_l <- planned_actual_2019 %>%\n  group_by(ea_id) %>%\n  gather(donation_type, value, donation_2019, planned_donation_2019)\n## helper functions\n\nf_19_hyp <- function(df) { #2019 data for donation difference\n  df %>%\n     filter(donation_2019>0 & planned_donation_2019>0) %>% #positive don in each year\n  transmute(don_diff = donation_2019 - planned_donation_2019) #only the difference is used; this adds an 'attribute' to this object\n}\n#test_rep_don_diff_mn_19\n#point hypothesis of 0 mean (+attribute)\n  #1000 replications of the relevant 'data'\n#test_rep_don_diff_med_19: as above but for median\n\n#test_rep_next_d_don_mn_18_20\n#for actual vs *next* year's plan (means)\n#test_rep_next_d_don_med_18_20 ... (medians)\n\n#### Linked tests: New Purr testing framework #####\n# ...Alternate between testing mean and median = 0 ####\nmean_zero_hyp <- list(null = \"point\", mu = 0)\nmed_zero_hyp <- list(null = \"point\", med = 0)\nhyps <- list(mean_zero_hyp, med_zero_hyp)\n\n# ...Stats to calculate #####\nstat_mean <- list(list(stat = \"mean\"))\nstat_median <- list(list(stat = \"median\"))\n\nbs_1000 <- list(reps = 1000, type = \"bootstrap\")\n\n#dataframes for testing 'current less next donation' and 'actual less planned donation'\ndf_next_don <- eas_all %>% f_next_d_don\ndf_don_diff <- planned_actual_2019 %>% f_19_hyp\n\nn <- 4 # Total number of tests ... mean and median for each dataframe (better to softcode this?)\n\nresponses <- c( rep(\"don_diff\", n/2), rep(\"next_d_don\", n/2))\np_value_directions <- rep(\"two_sided\", n)\n\n# ...  Functionalize ####\ndfs <- list( rep(list(df_don_diff), n/2),\n             rep(list(df_next_don), n/2))\n\nlinked_df_labels <- c(rep(\"2019-20 linked responses\", 2),\n                      rep(\"2018-2020 all responses\", 2))\nlinked_test_var_type <- c(rep(\"Actual vs Planned\", 2), rep(\"'Next year' vs Current\", 2))\nlinked_tests_df <- tibble(df = do.call(c, dfs), # Dataframes (needs tidying)\n\n                          # Stats to calculate\n                          stat = rep(c(stat_mean, stat_median), n/2),\n\n                          # Hypotheses to test\n                          hypothesis = rep(hyps, n/2),\n\n                          # Samples to generate\n                          gen = rep(list(bs_1000), n),\n\n                          # Outcome variables\n                          response = responses,\n\n                          # Direction for p-value calculation\n                          p_val_dir = rep(\"two_sided\", n))\n\n# .... actually run tests and collect pvalues etc ####\nlinked_tests_df <- linked_tests_df %>%\n  mutate(results = pmap(., test_hypothesis))\n  #test_hypothesis was defined in `hypothesis_test.R`; it runs the steps in the Infer testing package with options selected based on the content of the arguments.\n\nlinked_tests_results <- extract_hyp_results(linked_tests_df) %>% #extract and label key results for reporting and plotting\n  mutate(data_label = linked_df_labels,\n         data_type = linked_test_var_type)\n# ... make a tibble of the relevant dataframes and 'test formula elements'  ####\nunlinked_tests_df <- tibble(df = do.call(c, unlinked_data),\n\n                            formula = rep(list(unlinked_formula), n),\n\n                            hypothesis = rep(hyp_unlinked, n),\n\n                            gen = rep(list(perm_200), n),\n\n                            stat = c(rep(d_order_diff_means, n-1),\n                                     d_order_next_diff_means),\n\n                            p_val_dir = rep(\"two_sided\", n))\n# Column labels\nrename_test_results <- c(\"Statistic\" = \"stat\",\n                         \"Null type\" = \"null\",\n                         \"Null value\" = \"null_value\",\n                         \"Point estimate\" = \"point_estimate\",\n                         \"CI Lower\" = \"lower_ci\",\n                         \"CI Upper\" = \"upper_ci\",\n                         \"P-value\" = \"p_value\",\n                         \"Sample\" = \"data_label\")\n\n# This can be used for plotting\nfull_test_results <- dplyr::bind_rows(linked_tests_results, unlinked_diff_in_means_results, unlinked_diff_in_medians_results) %>%\n  select(-c(order)) %>%\n  mutate(across(c(stat, null, p_val_dir), ~ snakecase::to_sentence_case(.x)))\n\n# This forms the basis for tables/displaying stats\nfull_test_results_clean <- full_test_results %>%\n  select(-c(reps, type, formula, p_val_dir, response)) %>%\n  rename(!!rename_test_results) %>%\n  mutate(Statistic = str_replace_all(Statistic, c(\"means\" = \"Mean\",\n                                                  \"medians\" = \"Median\",\n                                                  \"Diff\" = \"Difference\")))\n#making tables\n\n#For linked tests:\ncurrent_next_test_results_clean <- full_test_results_clean %>%\n  filter(data_type == \"'Next year' vs Current\") %>%\n  select(-c(data_type, null_dist))\n\nplanned_v_actual_test_results_clean <- full_test_results_clean %>%\n  filter(data_type == \"Actual vs Planned\") %>%\n  select(-c(data_type, null_dist))\n\nplanned_v_actual_test_table <- planned_v_actual_test_results_clean %>%\n      select(-c(`Null value`, `Null type`, `Sample`)) %>%\n  kable(caption = \"Actual minus planned donations for 2019, linked participants (2019-20)\",\n        digits=c(0,0,0,3)) %>%\n  kable_styling()\n\ncurrent_next_test_table <- current_next_test_results_clean %>%\n      select(-c(`Null value`, `Null type`, `Sample`)) %>%\n  kable(digits=c(0,0,0,0,3), caption = \"Planned minus last year's donation, 2018-20, all participants who report donations\") %>%\n  kable_styling()\n#making tables for UNLINKED tests:\n\nplanned_actual_unlinked_results_table <- full_test_results_clean %>%\n  arrange(match(Sample,\n                c(\"Full sample (2018-19 donation years)\", \"Involved before 2019 (2018-19 don)\", \"GwwC only (2018-19 don)\", \"'Matched individuals'\"))) %>%\n  filter(`Null type` == \"Independence\" & data_type == \"Actual - Planned\"\n) %>%\n      select(-c(data_type, null_dist, `Null value`, `Null type`)) %>%\n    select(Sample, Statistic, everything()) %>%\n  kable(caption = \"Actual versus Planned donation distributions: permutation tests\",\n        digits=c(0,0,0,0,0,3)) %>%\n  kable_styling()\n\n\n\nnext_current_unlinked_results_table <- full_test_results_clean %>%\n  filter(`Null type` == \"Independence\" & data_type == \"'Next year' - 'this year'\"\n) %>%\n      select(-c(data_type, null_dist, `Null value`, `Null type`)) %>%\n    select(Sample, Statistic, everything()) %>%\n  kable(caption = \"'Next year (plan)' - 'this year' donation distributions: permutation tests\",\n        digits=c(1,1,1,3)) %>%\n  kable_styling()"},{"path":"eas_donations.html","id":"planned-vs.-actual-individuals-present-in-both-surveys","chapter":"3 Donation","heading":"2019 Planned vs. actual: Individuals present in both surveys","text":"first consider 441 respondents can matched across 2019 2020 surveys (anonymized email).plots cover respondents appear samples provide planned actual donation values. individuals make 22.9% total respondents appear 2020 sample 15% total respondents across 2019 2020.25Below, plot planned actual 2019 donations respondents.26Reassuringly, distributions largely overlap. separate graph whether individual made GWWC pledge:graphs suggest large differences distributions.27","code":"\n# Create plots for planned and actual donations matched across 2019\n\nscales_point_density_min50 <- list(limits = c(50, 500000), trans = scales::pseudo_log_trans(base=10),\n                     breaks = breaks,\n                     labels = scales::dollar_format())\n\nplanned_actual_2019_density <- planned_actual_2019_l %>%\n  rowwise() %>%\n  mutate(value = max(value, 50)) %>%\n  ungroup() %>%\n  ggplot() + geom_density(aes(x = value, fill = donation_type), alpha = 0.5) +\n  do.call(scale_x_continuous, scales_point_density_min50) +\n  scale_y_continuous(breaks = density_breaks,\n                     expand = c(0,0)) +\n  ggtitle(\"Actual vs Planned 2019 donations\", subtitle = \"Donations bottom-coded at $50; subset: those who can be matched across surveys)\") +\n  theme(legend.position = \"bottom\",\n        legend.margin=margin(t = -0.6, unit='cm')) + # Shift legend position up\n  xlab(\"\") + ylab(\"Density\") +\n  scale_fill_discrete(name = \"\",\n                      labels = to_title_case(unique(planned_actual_2019_l$donation_type)))\n\n# Define same parameters for x and y axis\nscales_point_density <- list(limits = c(0, max_lim), trans = scales::pseudo_log_trans(base=10),\n                     breaks = breaks,\n                     labels = scales::dollar_format())\n\n\nplanned_actual_2019_pointdensity <- planned_actual_2019 %>%\n  # ggplot(aes(y = donation_2019, x = planned_donation_2019)) +\n  rowwise() %>%\n  mutate(planned_donation_2019 = max(planned_donation_2019, 50),\n  donation_2019 = max(donation_2019, 50)) %>%\n  ungroup() %>%\n  ggplot(aes(y = donation_2019, x = planned_donation_2019)) +\n  ggpointdensity::geom_pointdensity(adjust = 0.25) +\n  geom_abline(slope = 1,\n              intercept=0,\n              linetype = \"dotted\") +\n   geom_smooth() +\n  do.call(scale_x_continuous, scales_point_density_min50) +\n  do.call(scale_y_continuous, scales_point_density_min50) +\n  scale_color_viridis_c(\"Neighbours\") +\n  #scale_size_continuous(\"Income\", labels = scales::label_number_si()) +\n  ylab(\"Actual 2019 Donation (bottom-coded @ $50)\") +\n  xlab(\"Planned 2019 donation (bottom-coded @ $50)\") +\n  ggtitle(\"Planned & actual donations 2019 (cross-survey matches)\")\n\n#@oska I added a geom_smooth. If you can get it to work with the income-size and legends looking good, let's put that back (TODO)\n#We can also trim the right horizontal  axis perhaps (maybe that can be set more generally above?)\nplanned_actual_2019_density\n(\n  planned_actual_gwwc <- planned_actual_2019_l %>%\n      rowwise() %>%\n  mutate(value = max(value, 50)) %>%\n  ungroup() %>%\n  filter(!is.na(action_gwwc)) %>%\n  mutate(action_gwwc = as.factor( if_else(action_gwwc == 1, \"GWWC Pledge\", \"No GWWC Pledge\") ) )%>%\n  # mutate(value = value + 1) %>%\n  ggplot() + geom_density(aes(x = value, fill = donation_type), alpha = 0.5)\n  + scale_x_log10(labels = scales::label_number_si(prefix = \"$\"))\n  + ggtitle(\"Actual vs Planned 2019 donations by 'made GWWC pledge'\", subtitle=\"Linked individuals, log scale\") +\n    xlab(\"Donation value, bottom-coded at $50\") +\n    ylab(\"Density\") + facet_grid(action_gwwc ~ . ) +\n  scale_fill_discrete(name = \"\",\n                      labels = to_title_case(unique(planned_actual_2019_l$donation_type)))\n)\n#TODO (\\@oska)  -- maybe do this specifically for a year in which there is a  large gap in timing -- perhaps 2018 is the best as it was <ay (1/2 the year) and we think it's a reliable data year\n\n#TODO: Med-high -- test for difference in planned and actual (a 'shift') and ideally test for a difference in difference between GWWC and non-GWWC"},{"path":"eas_donations.html","id":"don_v_plan","chapter":"3 Donation","heading":"Donations versus plans (same individuals, linked)","text":"graphs figures help us understand whether distribution planned actual gifts differ, tell us whether individual’s donation meets exceeds plan. considering individuals present surveys, can connect donation responses across years.graph shows distribution difference planned actual 2019 donations matched across years. negative value corresponds actual donation lower planned.Planned actual donations highly correlated (\\(\\rho =\\) 0.948).substantial shares report substantially less plan, less balances , tendency towards donating planned. fact, mean difference donation plan 1,139 USD excess plan (green line), median differences 67.9 USD.Considering zeroes might quick uncareful mis-responses, repeat plot report positive planned actual donations consecutive years, also compare GWWC pledgers versus non-pledgers:results similar – substantial shares outperformed plans, substantial shares underperformed, positives seem outweigh negatives. GWWC non-GWWC pledgers median donation exceeds plan (around 200 USD).see striking differences GWWC pledgers non-pledgers measure.28We next present scatterplot planned versus actual donations 2019, can matched across surveys. figure , brightness color indicates density respondents (number ‘neighbors’) particular combination planned actual donations.Overall, plot less centered around 45 degree line ‘plans=actual’. noticeable departures direction, seem balance . Thus, might loosely conclude ‘average 441 individuals can matched across years tend donate amount close planned’. However, may nonetheless important differences, test ., plot donations linked individuals – actual donations left, planned donations right. overlay ‘violin’ density plot (widths depicts frequencies). Medians depicted red dots, boxes depict 25th 75th percentiles. lines show individual’s donation (left) connected plan (right). plot also reports Wilcoxon signed-rank test (paired data).nonparametric tests reported find statistically significant difference: actual donations tend exceed planned donations sample, difference unlikely due chance. ‘pseudo-median’ difference estimated 281 USD 95% lower CI bound 162. “matched-pairs rank-biserial correlation” also bounded 0.17 0.41, suggesting “actual donation exceeds planned donation” likely “planned exceeds actual” (population drawn ).results similar focus subset report donation years (see bookdown robustness appendix).also present simulation-based tests whether mean median individual ‘actual minus planned’ donations exceeds falls zero. given table .\nTable 3.6: Actual minus planned donations 2019, linked participants (2019-20)\nmean ‘actual minus planned’ donations 1,587 USD, simulation-based (bootstrapped) confidence intervals [-279, 3,454], corresponding p-value 0.138. median difference point estimate 141 USD, simulation-based (bootstrapped) confidence intervals [22.5, 259], corresponding p-value 0.102. Thus, evidence points towards ‘actual donations exceeding planned donations EAs can linked across 2019-20’. However, (unlike Wilcoxon signed-rank tests) differences strongly statistically significant simulation-based tests.","code":"\n#TODO [Medium-High] -- incorporate it in so it will work for split plots, for 'same year', etc.\n\nm_dd <- planned_actual_2019 %>%\n  transmute(don_diff = donation_2019 - planned_donation_2019) %>%\n  ungroup() %>%\n  dplyr::summarize(mn_dd=mean(don_diff, na.rm=TRUE),\n                   med_dd = median(don_diff, na.rm=TRUE)\n  )\n\n(\n  actual_planned_2019 <- planned_actual_2019 %>%\n  mutate(don_diff = donation_2019 - planned_donation_2019) %>%\n  ggplot(aes(x = don_diff)) +\n  geom_density(alpha=0.5,\n               fill=\"blue\") +\n  scale_x_continuous(trans = pseudo_log_trans(base=10),\n                     breaks = c((-1)*breaks*2, breaks*2),\n                     labels = label_number_si(prefix = \"$\")) +\n  geom_vline(xintercept=m_dd$mn_dd, size=1.5, color=\"green\") + # this code is lame, we can improve it\n  geom_vline(xintercept=m_dd$med_dd, size=1.5, color=\"red\") + # this code is lame, we can improve it\n  geom_vline(xintercept=0) +\n#  coord_flip() +\n  labs(title = \"2019 donations: actual minus planned\",\n      caption = \"Red line: Median, Green line: Mean\" ) +\n  xlab(\"Actual - planned for same year\") +\n  ylab(\"\")\n)\n# TODO: keep improving this guy\n(\n  actual_planned_2019 <- planned_actual_2019 %>%\n  mutate(don_diff = donation_2019 - planned_donation_2019) %>%\n  ggplot(aes(x = don_diff)) +\n  geom_density(alpha=0.5,\n               fill=\"blue\") +\n  scale_x_continuous(trans = pseudo_log_trans(base=10),\n                     breaks = c((-1)*breaks*2, breaks*2),\n                     labels = label_number_si(prefix = \"$\")) +\n  geom_vline(xintercept=m_dd$mn_dd, size=1.5, color=\"green\") + # this code is lame, we can improve it\n  geom_vline(xintercept=m_dd$med_dd, size=1.5, color=\"red\") + # this code is lame, we can improve it\n  geom_vline(xintercept=0) +\n#  coord_flip() +\n  labs(title = \"2019 donations: actual minus planned\",\n      caption = \"Red line: Median, Green line: Mean\" ) +\n  xlab(\"Actual - planned for same year\") +\n  ylab(\"\")\n)\n(\n  actual_planned_2019_no_0_bygwwc <- planned_actual_2019 %>%\n    filter(!is.na(action_gwwc)) %>%\n     filter(donation_2019>0 & planned_donation_2019>0) %>%\n  mutate(don_diff = donation_2019 - planned_donation_2019 )\n         %>%\nggplot(aes(x = don_diff, y = as.factor(action_gwwc), fill = factor(stat(quantile)))) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE,\n    quantiles = 4, quantile_lines = TRUE\n  ) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n    scale_x_continuous(trans = pseudo_log_trans(base=10),\n                     breaks = c((-1)*breaks*2, breaks*2),\n                     labels = label_number_si(prefix = \"$\")) +\n  geom_vline(xintercept=0) +\n    ggtitle(\"2019 donations (no zeroes): actual minus planned, by GWWC-pledge\") +\n  xlab(\"\") +\n  ylab(\"\")\n)\nplanned_actual_2019_pointdensity\n(\nmatched_dons_wilcoxon <- planned_actual_2019_l %>%\n  mutate(donation_type = to_title_case(donation_type)) %>%\nggstatsplot::ggwithinstats(\n  x = donation_type,\n  y = value,\n  type = \"nonparametric\",\n  paired = TRUE,\n    point.path.args = list(alpha = 0.1,\n                           linetype = \"solid\"),\n) +\n  do.call(scale_y_continuous, scales) +\n  xlab(\"\") + ylab(\"\") +\n  scale_fill_discrete(name = \"\")\n)## Error: Package 'afex' is required for this function to work.\n##   Please install it by running install.packages('afex').\nw_signed_test_planned_actual <- wilcox.test(x = planned_actual_2019$donation_2019, y = planned_actual_2019$planned_donation_2019,\n              alternative = c(\"greater\"),\n            mu = 0, paired = TRUE, exact = NULL, correct = TRUE,\n            conf.int = TRUE, conf.level = 0.95,\n            tol.root = 1e-4, digits.rank = Inf)\n\n#a Wilcoxon signed rank test of the null that the distribution of ... x - y (in the paired two sample case) is symmetric about mu is performed.\n\n#Here the CI estimates 'the median of the difference between a sample from x and a sample from y.'\nplanned_actual_2019_no_0 <- planned_actual_2019 %>%\n  filter(donation_2019>0 & planned_donation_2019>0)\n\nw_signed_test_planned_actual_no0s <- wilcox.test(x = planned_actual_2019$donation_2019, y = planned_actual_2019$planned_donation_2019,\n              alternative = c(\"greater\"),\n            mu = 0, paired = TRUE, exact = NULL, correct = TRUE,\n            conf.int = TRUE, conf.level = 0.95,\n            tol.root = 1e-4, digits.rank = Inf)\n\n#a Wilcoxon signed rank test of the null that the distribution of ... x - y (in the paired two sample case) is symmetric about mu is performed.\n\n#Here the CI estimates 'the median of the difference between a sample from x and a sample from y.'\nplanned_v_actual_test_table\nlinked_ddmn <- linked_tests_results %>% filter(response==\"don_diff\" & stat==\"mean\")\nlinked_ddmed <- linked_tests_results %>% filter(response==\"don_diff\" & stat==\"median\")"},{"path":"eas_donations.html","id":"plan-actual-all","chapter":"3 Donation","heading":"Planned vs. actual: All respondents (across relevant years)","text":"responded 2019 2020 surveys (left emails times) might tend engaged EAs. particular, fulfilled one’s planned donation might make one likely want complete follow-survey, perhaps keen provide one’s donation data particular. suggest figures may biased towards ‘fulfilled plans’.Thus, next overlay planned actual donations respondents across surveys. compare ‘amounts planned year survey’ ‘amounts reported previous year, following year’s survey’. separately available year.offers us larger sample, may less vulnerable bias just-mentioned, brings sample selection issues, comparisons also treated caution (see fold/footnote).Indeed, ‘2019 respondents entered planned donation amount’ (call ‘2019-planners’) may precisely representative population interest. Still, might least seek ‘internally-valid’ measure ‘distribution actual 2019 donations 2019-planners’, compare actual planned 2019 donations. still imperfect: composition 2019 2020 respondents may differ, discussed elsewhere.Thus, distribution ‘reported 2019 donations completed survey 2020’ (call ‘2020-reporters’) may different distribution actual 2019 donations made 2019-planners. direction nature bias unclear; might get hints comparing reported donations 2018 2019 respectively 2019-reporters 2020-reporters. distribution donations changes little year year, might worry less bias. defer future work., also report measures joined EA 2019 (plausibly stable group).2019 (2020 survey ‘actual’ 2019 survey ‘planned’) 2018 (2019 survey ‘actual’ 2018 survey ‘planned’), histograms planned actual donations line approximately (although planned donations tend bit higher). However, 2017 (2018 survey ‘actual’ 2017 survey ‘planned’), planned donation distribution appears far lower. seems likely result different response different composition 2017 2018 responses.29(Thus include 2017 “planned versus actual” comparisons.)noted, remaining relevant donation years (2018 2019) median donation somewhat lower median planned donation, suggesting -performance relative plans. investigate .2018-19, distributions planned versus actual donations differ?*spite caveats , consider test whether distribution planned donations year exceeds falls short actual donations, pooling 2018-2019 2019-2020 data (consider donations vs plans 2018 2019).separately bothoverall, andoverall, andexcluding joined EA 2019 (plausibly stable group).excluding joined EA 2019 (plausibly stable group)., give density planned actual donations, split year-involved. Vertical lines represent medians group donation type (green=donation, pink=planned donations). Donations bottom-coded 50 USD. , groups (survey entries linked) planned donation distribution appears somewhat higher actual distribution, although difference dramatic.present results simulation-based permutation tests . \n(Explanation fold).\nuse permutation tests testing whether median (mean) planned donations exceeded/fell short mean actual donations, using data different years’ surveys (without connected individuals).null hypothesis (2019 donations) :‘difference median donation, survey sample, actual 2019 donations (reported 2020) planned 2019 donations (reported 2019).’Suppose maintain hypothesis ‘individuals appeared 2019 survey versus 2020 survey ‘randomly drawn’’,consider null hypothesis “distribution planned actual donations identical” (may stronger assumption needed).permutation procedure repeatedly simulates distribution planned actual donations consistent null, using original donation amount data randomly re-assigning observation either ‘planned’ ‘actual’. ‘simulated null distribution’ can compute targeted statistic (difference mean/median donation two groups). can plot ‘simulated nll distribution differences’ consider ‘often observe difference extreme ’point estimate’ actual data’? yields p-values reported .confidence intervals differences come simply using 95% interval range simulated distribution, shifted centered around point estimate.figure presents simulated null distribution differences medians arising procedure, full sample (2018-19 donation years).red line gives point estimate ‘differences median planned actual’ data. grey bins present ‘(simulated) distribution differences planned actual, null hypothesis planned actual drawn distribution’.‘pink areas’ depict area simulated null distribution ‘extreme’ point estimate; iis area represented ‘p-value’ two-tailed hypothesis test.Finally turquoise represent 95% CI actual median; essentially comes simulated distribution hypothesis true difference medians exactly equal point estimate.Note turquoise region just crosses 0, confirming ‘just barely reject null’, Bayesian analysis probably put lot probability mass fairly substantial differences.table summarize results test means medians, four distinct subsamples.\nTable 3.7: Actual versus Planned donation distributions: permutation tests\nfull sample, subset EA since 2019, GWWC pledgers, mean median donations fall short planned donations. Overall, difference medians bounded 300 600 USD. differences (medians) strongly statistically significant. Perhaps large outliers, differences means much widely bounded, thus comparison largely uninformative.contrasts results individuals can matched across 2019 2020 surveys, actual donations tend exceed reported plans prior year.* noted earlier, contrast might people met exceeded donation plans likely respond surveys subsequent years, report donations .30Given contrasting findings, work might warranted. donations tend underperform plans, might look patterns underperformance might suggest ways improving .","code":"\nscales_set <- list(scale_y_discrete(expand = c(0,0)),\n                   scale_x_continuous(limits = c(50, max_lim),\n                     trans = scales::pseudo_log_trans(base=10),\n                     breaks = breaks,\n                     expand = c(0,0),\n                     labels = scales::dollar_format())\n               )\n\nridge_bottom_opts <- list(\n  theme(legend.position = \"bottom\",\n  legend.margin=margin(t = -0.6, unit='cm')),\n  ylab(\"\"),\n  scale_fill_discrete(\"\"))\n\n\n(\n  dons_planned_across_all <-  eas_all %>%\n  f_don_plan_by_year %>%\n  ggplot(aes(x = value, y = as.factor(year), fill = donation_type)) +\n  geom_density_ridges(alpha=.6,\n                      color = \"black\",\n                      quantile_fun = median,\n                      quantile_lines = TRUE,\n                      rel_min_height = 0.005)  +\n  # geom_vline_med(x) +\n  scales_set +\n  ridge_bottom_opts +\n  xlab(\"\") +\n  guides(fill = guide_legend(override.aes = list(linetype = 0))) +\n    labs(title= \"Density of planned and actual donations for each year\",  subtitle = \"Vertical lines: medians for the year and donation type\",\n         caption = \"Donations bottom-coded at $50\")\n)\n #TODO -- medium-high priority: some depiction of quantiles/cutoffs within each smoothed histogram (for all the ones below, even the faceted ones). See, e.g., https://stackoverflow.com/questions/57563692/combining-facet-wrap-and-95-area-of-density-plots-using-ggplot2/57566951#57566951\n\n\ndons_plan_hist_opts <- function(df) {\n  df %>%\n      ggplot(aes(x = value, fill = donation_type)) +\n      geom_density(alpha=.35) +\n  scales_set +\n  #geom_vline_med(x) +\n  ridge_bottom_opts +\n    xlab(\"\")\n}\n\n\n#crappy workaround here:\nx <- eas_all %>%\n  filter(year %in% c(2018, 2019, 2020)) %>% f_don_plan_by_year\n\nxo <- eas_all %>% filter(year_involved<2019) %>%  filter(year %in% c(2018, 2019, 2020)) %>% f_don_plan_by_year\n\nx_med_don <- median(x$value[x$donation_type== \"Donation\"], na.rm=TRUE)\nx_med_don_plan <-  median(x$value[x$donation_type== \"Planned Donation\"], na.rm=TRUE)\nxo_med_don <- median(x$value[xo$donation_type== \"Donation\"], na.rm=TRUE)\nxo_med_don_plan <-  median(xo$value[x$donation_type== \"Planned Donation\"], na.rm=TRUE)\n\n\ndons_planned_18_20 <- eas_all %>%\n      filter(year %in% c(2018, 2019, 2020)) %>%\n    f_don_plan_by_year %>%\n  rowwise() %>%\n  mutate(value = max(value, 50)) %>%\n  ungroup() %>%\n  dons_plan_hist_opts +\n  geom_vline(xintercept=x_med_don, size=.5, color=\"green\") +\n  geom_vline(xintercept=x_med_don_plan, size=.75, color=\"pink\") +\nggtitle(\"2018-19\")\n\n\ndons_planned_18_20_no_new <- eas_all %>%\n          filter(year_involved<2019) %>%\n      filter(year %in% c(2018, 2019, 2020)) %>%\n        f_don_plan_by_year %>%\n  dons_plan_hist_opts +\n  geom_vline(xintercept=xo_med_don, size=.5, color=\"green\") +\n  geom_vline(xintercept=xo_med_don_plan, size=.75, color=\"pink\") +\n  ggtitle(\"2018-19\")\n\n(\ndons_planned_18_20_arr_new <- ggarrange(dons_planned_18_20, dons_planned_18_20_no_new,\n                                        ncol = 2, nrow=1,\n                                        labels=c(\"All\", \"Involved pre-2019\"),\n                                        label.x=0.0,\n   label.y=0.85,\n   legend=\"bottom\",\n common.legend=TRUE                                 ) +\n     labs(title= \"Density of planned and actual donations, split by year-invo\",  subtitle = \"Vertical lines: medians for the group and donation type\",\n         caption = \"Donations bottom-coded at $50\")\n)\n #todo (@oska) -- finish this; separate aligned plots for\n # - is it doing what I think? I think we want to use 2020 for the sums in  'actual' but not in 'planned'\n # - align the above, fix labels\n # - report some more stats within each as 'bars' or shading (geom lines could also be good)\n # - stat tests for each\nplanned_actual_unlinked_results_table\n# report on\n\n#test_rep_mean_don_19_20\n#test_rep_med_don_19_20\n\n#test_rep_mean_don_19_20_gwwc\n#test_rep_med_don_19_20_gwwc\n\n#test_rep_mean_don_19_20_nonew\n#test_rep_med_don_19_20_nonew"},{"path":"eas_donations.html","id":"next-year","chapter":"3 Donation","heading":"3.7 Donations versus next year’s plans","text":"noted, can match subset individuals across years. However, years asked, respondents answered retrospective donation question also answered ‘planned year’ question. can see tend relate; may particularly consider whether 2020 donations expected higher lower 2019, light pandemic (cf Giving Tuesday report suggesting growth overall US charitable giving 2020). overlay distribution ‘last year’s donations’ ‘planned current year’ donations 2018-2020 surveys.year, median planned donations exceeds actual donations. distribution appears fairly constant across years, obvious substantial drop 2020.Next plot two dimensions: individual plot planned current year’s donation reported donation year prior survey.graph’s implications obvious. large mass exactly along 45 degree line, donation amount planned current year equals amount reported last year. seems substantial mass planned donations exceed actual donations (45 degree line), smoothed curve largely positioned line, perhaps small zero entries planned donations.repeat plot report positive values ‘previous year’ ‘planned year’:previous sections, conduct simulation-based tests. can separately consider () (unpaired) differences medians means distributions (ii) medians means differences .First, considering differences distributions:\nTable 3.7: ‘Next year (plan)’ - ‘year’ donation distributions: permutation tests\nmean distribution current-years’ planned donations higher mean previousc year’s, reject equality (p value far conventional statistical threshold). However, median statistically significantly higher (438 USD point estimate).Next, considering differences individual:\nTable 3.6: Planned minus last year’s donation, 2018-20, participants report donations\nmedian difference clearly 0 – great middle mass participants report donation planned current year previous one, case resampling simulations. However, mean difference strongly significantly positive: consider magnitude differences, people tend report greater planned donation year reported last year. However, necessarily indicate -optimism underperformance: possible individuals responding individual survey period fact increase donations year year.","code":"\nnext_don_lab <- c(donation_usd = \"Don: Last year\", donation_plan_usd  = \"Don: This year (plan)\")\n\n(\n  dons_v_next_18_20 <- eas_all %>%\n    f_don_18_20 %>% ggplot(aes(x = value, y = as.factor(year), fill = donation_type)) +\n  geom_density_ridges(alpha=.6,\n                      color = \"black\",\n                      quantile_fun = median,\n                      quantile_lines = TRUE)  +\n  # geom_vline_med(x) +\n  scales_set +\n  ridge_bottom_opts +\n  guides(fill = guide_legend(override.aes = list(linetype = 0))) +\n    labs(title= \"Density of last year vs current year planned donations\",  subtitle = \"Vertical lines: medians for the year and type of report\") +\n    scale_color_brewer(labels=next_don_lab) +\n  scale_fill_brewer(labels=next_don_lab) +\n  xlab(\"\") +\n    theme(legend.title=element_blank()) +\n          guides(fill = guide_legend(reverse = TRUE))\n)\n  #dons_plan_hist_opts  +\n #   facet_wrap(~factor(year, levels=c('2018','2019','2020')), nrow=3, ncol = 1)\n#)\n\n\n  # Todo -  medium: It's still not clear what is going on from year to year... maybe try animated?\n\n  #  Todo -- medium/high: get bars or color separation for quantiles (probability mass) within each histogram\n\n\n  #p_load(\"\")\n  #devtools::install_github('thomasp85/gganimate')\n  #devtools::install_github('thomasp85/transformr')\n  #dons_v_next_18_20_anim <- dons_v_next_18_20 + transition_states(year, state_length = 3) +  ggtitle(\"Donations and plans: {closest_state}\")\ncurrent_planned_eas <- eas_all %>%\n  select(ea_id, donation_usd, donation_plan_usd, year) %>%\n  # Add demographic information -- cut because it was crap\n  #left_join(., select(eas_20_cy, all_of(demographics), ea_id, action_gwwc, start_date, end_date, income_c), by = \"ea_id\") %>% #remove likely duplicate entries (do that elsewhere too?) ; this also removes entries from years without any responses to these I guess\n  distinct()\n(\ncurrent_planned_pointdensity <- current_planned_eas %>%\n  # ggplot(aes(y = donation_2019, x = planned_donation_2019)) +\n  filter(year>=2018) %>%\n  rowwise() %>%\n  mutate(donation_usd = max(50, donation_usd),\n         donation_plan_usd = max(50, donation_plan_usd)) %>%\n  ungroup() %>%\n  ggplot(aes(x = donation_usd, y = donation_plan_usd)) +\n  ggpointdensity::geom_pointdensity(adjust = 0.25) +\n   geom_smooth() +\n  do.call(scale_x_continuous, scales_point_density_min50) +\n  do.call(scale_y_continuous, scales_point_density_min50) +\n  scale_color_viridis_c(\"Neighbours\") +\n  #scale_size_continuous(\"Income\", labels = scales::label_number_si()) +\n  ylab(\"Planned (next year's) Donation\") +\n  xlab(\"Actual (this year's) donation\") +\n   labs(title= \"Last year's donation vs this year's (planned) donation\",\n       subtitle = \"2018-2020; donations 'bottom-coded' at 50 USD\")\n)\n#TODO: --medium  importance -- facet or animate this across years'\n(\ncurrent_planned_pointdensity_no0 <- current_planned_eas %>%\n  # ggplot(aes(y = donation_2019, x = planned_donation_2019)) +\n  filter(donation_usd >0 & donation_plan_usd>0) %>%\n    filter(year>=2018) %>%\n rowwise() %>%\n  mutate(donation_usd = max(50, donation_usd),\n         donation_plan_usd = max(50, donation_plan_usd)) %>%\n  ungroup() %>%\n  ggplot(aes(x = donation_usd, y = donation_plan_usd)) +\n  ggpointdensity::geom_pointdensity(adjust = 0.25) +\n   geom_smooth() +\n  do.call(scale_x_continuous, scales_point_density_min50) +\n  do.call(scale_y_continuous, scales_point_density_min50) +\n  scale_color_viridis_c(\"Neighbours\") +\n  #scale_size_continuous(\"Income\", labels = scales::label_number_si()) +\n  ylab(\"Planned (next year's) Donation\") +\n  xlab(\"Actual (this year's) donation\") +\nlabs(title= \"Last year's vs this year's (planned) donation\",  subtitle = \"For EAs reporting a positive amount for each\",\n     caption=\"2018-20, donations 'bottom-coded' at 50 USD\" )\n)\n#TODO: --medium  importance -- facet or animate this across years'\nnext_current_unlinked_results_table\ncurrent_next_test_table"},{"path":"eas_donations.html","id":"modeling","chapter":"3 Donation","heading":"3.8 Model of EA donation behavior","text":"","code":""},{"path":"eas_donations.html","id":"modeling-questions-and-approaches","chapter":"3 Donation","heading":"Modeling ‘questions’ and approaches:","text":"discussed posts linked material, broadly imagine three categories modeling: (See discussion fold/footnote.)Descriptive (‘relates donation behavior’),Descriptive (‘relates donation behavior’),Predictive (‘people particular characteristics donate future’), andPredictive (‘people particular characteristics donate future’), andCausal (‘factors actually determine amount donated’; changed factors, donations change).Causal (‘factors actually determine amount donated’; changed factors, donations change).Descriptive modeling: Essentially, offering “dimension reduction” data, presenting ‘features relate donation behavior’?Predictive modeling: Training model produce best --sample (--time) fit current (future) donations based individual characteristics. model include ‘leaks’, .e., excluding individual characteristics outcomes occur time ‘prediction’.Causal: Consider identification ‘causal paths’, .e., ‘actually determines amounts donated’.However causal inference requires strong assumptions /exogenous random shifts potential determinants donation behavior. don’t obvious candidates current setting. best, can interpret descriptive predictive models suggestive causal relationships.may care causalitybecause see potential intervene boost variables cause greater giving, /becausebecause see potential intervene boost variables cause greater giving, /becausea better understanding actually drives donation behavior may yield additional insights, helping us understand world better.better understanding actually drives donation behavior may yield additional insights, helping us understand world better.However, see little potential credible convincing causal inference . thus first focus description (less , prediction), informally considering ‘plausible causation’. discuss (implement) next section. (Discussion bookdown/fold ).** Consider factors potential interest, including influence movement (e.g., ‘recommended career paths’) fundamental interest (perhaps income, age initial cause prioritization). Simply looking differences donation measures tell us actual impact donation; ‘controlled regression’: likely related , influenced (observable ) unobserved components may also drive donations.E.g., suppose people first went elite university tended donate . mean attending elite university causes greater donations. Individuals attend elite university may greater exposure EA charitable appeals, greater (unobserved wealth) lifetime income, may independently cause greater giving. Even age given obvious causal interpretation, given sample selection; e.g., sample look older people tend joined EA younger age, people may driven join younger age altruistic, stronger EA peer network, etc.reasons, general look sources experimental quasi-experimental variation factors interest justify causal inference. However, present data.mentioned introduction, able predict donations useful several reasons. Thus, follow descriptive models “predictive models”, different goals approaches, including elements machine learning (see discussion ).","code":""},{"path":"eas_donations.html","id":"descriptive","chapter":"3 Donation","heading":"3.8.1 Descriptive (and causally-suggestive) models","text":"2019 post:results regression analysis suggestive … higher incomes GWWC members tend donate lower incomes students. …year’s post begin set pre-specified models aimed describing providing suggestive inference causal factors driving donations. (discussion Bookdown point) .descriptive modeling remove ‘insignificant’ features model (stepwise regression), shrink coefficients towards zero (Ridge Lasso models). assumptions classical linear model simple extensions coefficients present unbiased consistent. (However, admit strong assumptions model, particularly embodying exogeneity, likely fail important ways current non-experimental setting.)retain features direct interest (‘introduced EA’) /theoretical importance (income),** ‘controls’ (especially time--EA survey-year) might allow us better interpret features interest.31As discussed posts ‘people introduced EA’ changed years. also expect involved EA longer period time engaged, perhaps donate (possibly due differential attrition). Thus, seems reasonable tracking association donation introducer, might want ‘control ’ (difference hold constant) differences ‘time--EA’ groups. Still, admit specifications based explicit causal model identification strategy.","code":""},{"path":"eas_donations.html","id":"choosing-features-and-modeling-targets","chapter":"3 Donation","heading":"Choosing features and modeling targets","text":"construct several ‘feature sets’:“Key demographics, student status, geography”, used models “Career/Economics”: (Income, employment status, top-6 university)* “Pledges/commitments:” Whether ever taken ‘Giving Can Pledge’, whether ‘Earning Give’ “Controls” age, time--EA, survey-year (used models)** [ “Top-6 university” refers whether individual lists six universities (Oxford, Stanford, Harvard, CalTech, MIT, Cambridge) appearing top-10 USNWR, QS, rankings. However, university asked 2018 survey; check whether impact coefficient year 2018.][ refer latter “controls” aid interpretation features interest, noted . However, also independent interest.]focus three key outcomes:Amount donated (converted US dollars)32Amount donated (converted US dollars)32Donation share income33Donation share income33Whether donated 1000 USDWhether donated 1000 USDIn extensive ‘bookdown’ version report summary statistics data used models. See .report summary statistics selection features target outcomes , limited subset report zero positive previous current-year donation (modeling).\nTable 3.8: Donations, income, career, 2018-2020, (subset: reporting 0+ donation)\n, report donations, income, career, GWWC pledge rates. Note ‘Don. avg.’, average current year planned donation, close, slightly ‘Donation’ variable, somewhat positive values. Note also income imputation (missing stated 5000 USD) recodes 10% values, leads fairly similar average income figure (compare ‘Income (imp.)’ ‘Income (imp. bc.)’, latter refers income imputation bottom-coding 5000 USD). Note , perhaps unsurprisingly, rates self-reported ‘earning--give’ careers ‘ever made Giving Can pledge’ higher among sample (report donation) overall EAS sample.\nTable 3.9: Demography etc., 2018-2020 (subset: reporting 0+ donation)\n\nTable 3.9: Year, years-involved, age; 2018-2020 (subset: reporting 0+ donation)\ntable suggests, modeling EA survey years 2018-2020 , roughly equal shares year (although somewhat fewer subsequent year). largest (plurality) demographic groups (sample overall, see posts) male, non-students, ‘white’ ethnicity, US. least 43% come one cities named EA survey (50% responding), 13% (data) education ‘top-6’ global university.","code":"\n# Define vector for renaming terms in regression output\n#\"new_names'\" moved to `build/labeling_eas.R'\n#TODO - medium -- try to move all this to build side\n\n#We impute variables where missing and normalizing all variables to be mean-zero and to be on the same scale.\n\ndiqr <- function(x) {\n  (x - mean(x, na.rm=TRUE))/IQR(x, na.rm=TRUE)\n}\n\ngtmed <- function(x) {\n  x*(x>med(x))\n}\n\n#TODO -- HIGH importance -- why 43 missing values for donation_usd?\n\neas_all_s <- eas_all %>%\n  filter(!is.na(don_av2_yr) & year_f %in% c(\"2018\", \"2019\", \"2020\")) %>%\n  mutate(\n    #(re) code scaling and 2-part splits for the modeling sample (2018-20, reporting donations)\n    age_d2sd = arm::rescale(age), #Todo (automate this with `mutate(across)` thing)\n    age_if_older = gtmed(age),\n\n    ln_age_if_older = gtmed(ln_age),\n    ln_years_involved_post_med = gtmed(ln_years_involved),\n    years_involved_d2sd = arm::rescale(year - as.numeric(year_involved)),\n    years_inv_d2sd_post_med = gtmed(years_involved_d2sd),\n    income_c_imp_diqr = diqr(income_c_imp_bc5k),\n    age_d2sd_post_med = arm::rescale(age_if_older),\n    income_c_imp_diqr_if_richer = gtmed(income_c_imp_diqr),\n    ln_income_c_imp_if_richer= gtmed(ln_income_c_imp_bc5k)\n  ) %>%\n  rowwise() %>%\n  mutate(don_share_inc_imp_bc5k = min(don_share_inc_imp_bc5k, 1)) %>%  #recode about 84 values so the range is between 0-1 for frac. logit to work\n  ungroup() %>%\n  dplyr::select(all_of(c(num_out, bin_out, controls, key_demog, feat_income_employ, feat_gwwc_etg, robust_controls)),\n                income_c, income_c_imp, income_c_imp_bc5k, income_c_imp_diqr, income_c_imp_diqr_if_richer, first_hear_ea_lump, years_involved, age,\n                contains(\"d2sd\"), contains(\"iqr\")) %>% #I have added first_hear_ea_lump back even though we don't use it here because we want to use it in ML; I hope it doesn't mess anything up\n  # years_involved included to put in sumstats\n  labelled::set_variable_labels(.labels = as.list(key_eas_all_labels), .strict=FALSE)\n\n#eas_all_s_rl <- eas_all_s %>%\n  #filter_all(any_vars(is.na(.), negate = TRUE)) %>% #(Alt: drop all rows with any missings)\n  #mutate(\n    #re-leveling should now be done on build side only because it removes labels\n  #Hopefully everything above preserves levels\n  #where_live_cat = relevel(where_live_cat, ref=\"USA\"),\n      #city_cat = relevel(city_cat, ref=\"Other\"),\n        #year_f = relevel(as.factor(year_f), ref=\"2017\"),\n      #student_cat = relevel(student_cat, ref=\"Non-student\"),\n      #not_male_cat = relevel(not_male_cat, ref=\"Male\")\n     # race_cat = relevel(race_cat, ref=\"Just white\")\n    #) %>%\n  #gdata::drop.levels()  #drops unused factor levels\n\n  #Recode missing as 0 for all dummies, as a 'NA category' for categoricals\n  #also for normalized variables; i.e., set missings to the mean\neas_all_s_rl <- eas_all_s %>%\n    mutate(across(matches(\"d_|not_just_white\"), missing_to_zero))\n\neas_all_s_rl_imp <- eas_all_s_rl %>%\n      mutate(across(matches(\"d2sd|diqr\"), missing_to_zero)) %>%\n    labelled::set_variable_labels(.labels = as.list(key_eas_all_labels), .strict=FALSE)\n#TODO: (future) -- check for sensitivity to this imputation vs dropping these obs\n\n# Write imp dataset to csv and RDS for ML/predictive modeling in donation_pred.R etc.\n\nsaveRDS(eas_all_s_rl_imp, file = here(\"data\",\"edited_data\",\"eas_all_s_rl_imp.Rdata\"))\n\neas_all_s_rl_imp %>% write_csv(here(\"data\", \"edited_data/eas_all_s_rl_imp.csv\"))\ncount_uniq <- eas_all_s_rl %>% #counts of unique values for each feature in each year\n  grp_uniq(year_f)\n\nrecover_cols <- count_uniq %>%  #any columns *without* unique features in each year?\n  select_if(~ any(.==1))%>%\n  names()\n#don_inc_career_tab\n\n(\n  don_inc_career_tab <- eas_all_s_rl_imp %>%\n            filter(!is.na(don_av2_yr)) %>%\n      mutate(`Earn-to-give` = as.factor(d_career_etg),\n           `GwwC` = as.factor(d_gwwc_ever_0)) %>%\n  ungroup() %>%\n  filter(year_f %in% c(\"2018\", \"2019\", \"2020\")) %>%\n dplyr::select(starts_with(\"don\"), starts_with(\"d_don\"), starts_with(\"inc\"), -income_c_imp_diqr,\n               d_pt_employment, d_not_employed,\n               `Earn-to-give`, `GwwC`) %>%\n  dplyr::select(-starts_with(\"l_\"), -d_don_10pct, -ends_with(\"d2sd\"),\n                -matches(\"_if_|_post_\")) %>%\n    .summ(title = \"Donations, income, career, 2018-2020,  (subset: reporting 0+ donation)\",\n          digits = c(0,0,1,1,2,1),\n          labels=TRUE,\n          logical.labels = c(\"No\", \"Yes\"),\n          factor.counts = FALSE,\n           out=\"kable\") %>%\n  kable_styling()\n)\n#TODO for future posts/time permitting: split by 'whether reported donation', test for differences\n\n(\n  demog_etc_tab <- eas_all_s_rl_imp %>% ungroup() %>%\n    filter(year_f %in% c(\"2018\", \"2019\", \"2020\")) %>%\n    droplevels() %>%\n        filter(!is.na(don_av2_yr)) %>%\n dplyr::select(-contains(\"don\"), -starts_with(\"d_don\"), -starts_with(\"inc\"), -starts_with(\"ln_\"), -d_don_10pct, -ln_income_c_imp_bc5k,  -matches(\"d2sd|_if_|_post_\")) %>%\n    select(-d_pt_employment, -d_not_employed, -d_career_etg, -d_gwwc_ever_0, -first_hear_ea_lump, -year_f, -years_involved, -age) %>%\n  select(everything()) %>%\n     labelled::set_variable_labels(.labels = as.list(key_eas_all_labels), .strict=FALSE) %>%\n    sumtable(\n    labels = TRUE, #uses assigned in Hmisc or sjlabelled\n                simple.kable = TRUE, title = \"Demography etc., 2018-2020 (subset: reporting 0+ donation)\",\n    digits = 1,\n    factor.counts = FALSE,\n    out=\"kable\"\n) %>%\n  kable_styling()\n)\n(\n  year_etc_tab <- eas_all_s_rl_imp %>% ungroup() %>%\n    filter(year_f %in% c(\"2018\", \"2019\", \"2020\")) %>%\n    droplevels() %>%\n        filter(!is.na(don_av2_yr)) %>%\n dplyr::select(year_f, years_involved, age) %>%\n     labelled::set_variable_labels(.labels = as.list(key_eas_all_labels), .strict=FALSE) %>%\n    sumtable(\n    labels = TRUE, #uses assigned in Hmisc or sjlabelled\n                simple.kable = TRUE, title = \"Year, years-involved, age; 2018-2020 (subset: reporting 0+ donation)\",\n    digits = 1,\n    factor.counts = FALSE,\n    out=\"kable\") %>%\n  kable_styling()\n)"},{"path":"eas_donations.html","id":"constructing-models","chapter":"3 Donation","heading":"Constructing models","text":"focus following modeling specifications: 34Proportional-effects ‘Quasi-Poisson’ model ‘amount donated’ outcomes (allowing expected donation exponential function features). 35Proportional-effects ‘Quasi-Poisson’ model ‘amount donated’ outcomes (allowing expected donation exponential function features). 35Fractional logit (Papke Wooldridge (2008)) ‘donation share income’Fractional logit (Papke Wooldridge (2008)) ‘donation share income’Logit regression binary ‘donated 1000 USD’ outcomeLogit regression binary ‘donated 1000 USD’ outcome","code":"\n# Define models (For LINEAR models ... used only in appendix, but some of these are reused in other models)\n#-----------------------------------------------------\n\nfeat_list = list(\n  #better to make this a 'named list'? (TODO -- @oska would that improve the code?)\n  c(key_demog, feat_income_employ, controls),\n  c(key_demog, feat_income_employ, controls, robust_controls),\n # c(key_demog, feat_income_employ, feat_fh, controls, robust_controls), #robust controls here because 'first heard' is likely entangled with tenure and age\n  c(key_demog, feat_income_employ, feat_gwwc_etg, controls) )\n\nfeat_list_n = list(\n  #better to make this a 'named list'? (TODO -- @oska would that improve the code?)\n  c(key_demog_n, feat_income_employ_n, controls_n),\n  c(key_demog_n, feat_income_employ_n, controls_n, robust_controls_n),\n  c(key_demog_n, feat_income_employ_n, feat_gwwc_etg, controls_n) )\n\nfeat_names = c(\"Baseline\", \"Robust controls\",  \"Base + EtG & GWWC\")\n\nrhs_vars_list <- rep(feat_list, length(targets_short))\n#rhs_vars_list_iqr <- rep(feat_list_iqr, length(targets_short))\n\noutcome_vars_list <- rep(as.list(targets_short), each=length(feat_list))\n\ndfs <- rep(list(eas_all_s_rl_imp), length(outcome_vars_list))\n## Create dataframe for modeling\nlinear_models <- make_model_df(rhs_vars_list, outcome_vars_list, dfs)\n\n# Fit linear models\nlinear_models <- linear_models %>%\n  mutate(\n    lm_fit = fit_models(\n      linear_models, \"formulas\", \"dfs\", fun = fit_lm)\n    )\n#warning `using type = \"numeric\" with a factor response will be ignored‘-’ not meaningful for factor`\n# @DR: Why are these models being fit on binary outcomes? DR, @OM: It is fit on all the outcomes including the binary ones, no? However, we haven't reported it yet. Anyways, I think there is still a norm of considering 'linear probability models' in Economics, and arguments on its behalf, at least as a robustness check.\n\n# Extract coefficients, fitted and residuals\nmodel_feat_names <- rep(c(feat_names), times= length(targets_short))\nmodel_oc_names <- rep(c(targets_short_names), each= length(feat_names))\nmodel_names <- paste(model_oc_names, model_feat_names, sep = \": \")\nlinear_models <- linear_models %>%\nmutate(lm_coefficients = map(lm_fit,\n                             extract_coefficients,\n                             replacement_names = new_names,\n                             robust_SE = TRUE),\n#TODO -fix -- Medium importance (as linear is just for robustness checks...) error/warning: `'^’ not meaningful for factors`\n\n       lm_resids = map(lm_fit, residuals),\n       lm_fitted = map(lm_fit, fitted))\n\n#note: in modeling_df, lm_fit and qp_fit are the 'model output' objects\n# `lm_resids` are a list of vectors of residuals from each linear model\n# `lm_fitted` are a list of vectors of predicted outcomes from each linear model\n\n# Error: Problem with `mutate()` column `lm_coefficients`.\n## ℹ `lm_coefficients = map(...)`.\n## x only 0's may be mixed with negative subscripts\n#trying out some simple models just as a place to test what is going on\n\ntest_qp <- eas_all_s_rl_imp %>%\n  glm(don_av2_yr ~ ln_income_c_imp_bc5k  + ln_age + not_male_cat + student_cat + race_cat + where_live_cat + city_cat + d_pt_employment +    d_not_employed + d_top6_uni + ln_years_involved + year_f, family=quasipoisson, data =.)\n\n\n\ntest_fl <- eas_all_s_rl_imp %>%  glm(don_share_inc_imp ~ ln_income_c_imp_bc5k + ln_age + not_male_cat + student_cat + race_cat +\n    where_live_cat + city_cat  + d_pt_employment +\n    d_not_employed + d_top6_uni + ln_years_involved + year_f, family = quasibinomial('logit'), data = .)\n\n\ntest_logit <- eas_all_s_rl_imp %>%  glm(d_don_1k ~ age_d2sd + not_male_cat + student_cat + race_cat +\n    where_live_cat + city_cat + income_c_imp_diqr + d_pt_employment +\n    d_not_employed + d_top6_uni + years_involved_d2sd + year_f,\n    family = binomial, data = .)\nqp_targets_short <- c(\"don_av2_yr\")\nqp_outcome_vars <- rep(as.list(qp_targets_short), each=length(feat_list)) # List of outcome variables for quasi-poisson\nqp_rhs_vars <- rep(feat_list, length(qp_targets_short)) # List of independent variables\nqp_dfs <- rep(list(eas_all_s_rl_imp), length(qp_outcome_vars)) # List of dataframes to fit models to\n\nqp_models <- make_model_df(qp_rhs_vars, qp_outcome_vars, qp_dfs) # Create dataframe for models\n\n# Add model names\nfeat_group_names <- c(\"1. Baseline\", \"2. Robust controls\",\n                    \"3. Base + ETG + GWWC\")\n\nqp_model_names <- feat_group_names\n\nqp_models <- qp_models %>%\n  mutate(model_name = rep(qp_model_names, length(qp_targets_short)))\n\n# Fit quasi-poisson models\nqp_models <- qp_models %>%\n  mutate(\n    qp_fit = fit_models(\n      qp_models, \"formulas\", \"dfs\", fun = fit_glm)\n    )\n\n# Extract coefficients\n## Takes a little while, consider parallels package?\nqp_models_noexp <- qp_models %>%\n  mutate(qp_coefficients = map(qp_fit,\n                               extract_coefficients,\n                               replacement_names = new_names,\n                               exponentiate = FALSE,\n                               robust_SE = TRUE),\n         qp_resids = map(qp_fit, residuals),\n         qp_fitted = map(qp_fit, fitted))\n\nqp_models <- qp_models %>%\n  mutate(qp_coefficients = map(qp_fit,\n                               extract_coefficients,\n                               replacement_names = new_names,\n                               exponentiate = TRUE,\n                               robust_SE = TRUE),\n         qp_resids = map(qp_fit, residuals),\n         qp_fitted = map(qp_fit, fitted))\n#Note: redone/redoing  - fractional logit instead of Quasi-poisson with offset\n#Discussion:\n\nfl_targets_short <- c(\"don_share_inc_imp_bc5k\")\nfl_outcome_vars <- rep(as.list(fl_targets_short), each=length(feat_list)) # List of outcome variables for quasi-poisson\nfl_rhs_vars <- rep(feat_list, length(fl_targets_short)) # List of independent variables\nfl_dfs <- rep(list(eas_all_s_rl_imp), length(fl_outcome_vars)) # List of dataframes to fit models to\n\n#----------\n\n# Function to remove a particular string from a list\n#remove_str_list (moved to rstuff functions)\n\n# Create dataframe for models\nfl_models <- make_model_df(fl_rhs_vars, fl_outcome_vars, fl_dfs)\n\nfl_models <- fl_models %>% mutate(model_name = rep(feat_group_names, length(fl_targets_short)))\n# Fit fractional logit models\n\nfl_models <- fl_models %>%\n  mutate(\n    fl_fit = fit_models(\n      fl_models, \"formulas\", \"dfs\", fun = fit_glm,\n          family = quasibinomial('logit'))\n    )\n\n# Extract coefficients\n## Takes a little while, consider parallels package?\nfl_models_noexp <- fl_models %>%\n  mutate(fl_coefficients = map(fl_fit,\n                               extract_coefficients,\n                               replacement_names = new_names,\n                               exponentiate = FALSE,\n                               robust_SE = TRUE),\n         fl_resids = map(fl_fit, residuals),\n         fl_fitted = map(fl_fit, fitted))\n\nfl_models_noexp_nonrobust <- fl_models %>%\n  mutate(fl_coefficients = map(fl_fit,\n                               extract_coefficients,\n                               replacement_names = new_names,\n                               exponentiate = FALSE,\n                               robust_SE = FALSE),\n         fl_resids = map(fl_fit, residuals),\n         fl_fitted = map(fl_fit, fitted))\n\nfl_models <- fl_models %>%\n  mutate(fl_coefficients = map(fl_fit,\n                               extract_coefficients,\n                               replacement_names = new_names,\n                               exponentiate = TRUE,\n                               robust_SE = TRUE),\n         fl_resids = map(fl_fit, residuals),\n         fl_fitted = map(fl_fit, fitted))"},{"path":"eas_donations.html","id":"models-tables-and-plots-of-results-years-2018-20-combined","chapter":"3 Donation","heading":"Models (Tables and plots of results; years 2018-20 combined)","text":"put together forest plots (normalized) coefficients distinct set models outlined , can compared scales. Specifically, consider,three key outcomes (‘amount donated (averaged)’, ‘donation share income’, ‘donated 1000 USD’),models three specific sets features, yielding nine models total (plus robustness checks appendix).feature sets, refer forest plots , :1. “Base” (baseline model)Demographics: Log age, Gender, Student, Race/ethnicity, live, CityCareer-related: Employed PT, Employed, Top-6 Uni.Controls: Years EA (log), Year surveyWhere “imp” denotes income imputed missing, “log” notes natural log taken (allowing proportional ‘elasticity’ relationship).Note Logit models use standardizations instead logged continuous variables.362. “Robust controls”: Including features Base well second term “Years EA (log), Log age” takes positive value exceed respective sample medians, otherwise set zero. represent ‘adjustment terms’ allowing us see whether time--EA, age, income may different relationship donations higher values .373. “Base + ETG + GWWC”: Including features Base well binary variables “GWWC (ever), EtG”, .e., whether reported ever taken Giving Can Pledge, whether report career ‘earning--give’.Note report models three feature sets forest plots . However, forest plot reports single outcome single ‘theme’, e.g., focusing reporting just coefficients demographics across three model feature sets (repeated coefficients across plots).themes areDemographics (including age time--EA)*Employment/career, GWWC, EtG, Income**“Non-response” particular questions (appendix)***However, important remember reported estimates forest plot come models ‘control ’ features (reported).Note exclude ‘two-part’ coefficients (‘Robust controls’ models) forest plots.38We present coefficients ‘Age, Time EA, Income, nonlinear adjustments ’ separate set tables (web link).**, [ use natural log income models donation amounts ‘donation/income’ outcome. (untransformed) coefficients elasticity interpretation — percent increase donations (donation share) given percentage increase income. scale comparable coefficients, report forest plots. report tables “Age, time--EA, Income; possible nonlinearity” instead.][ avoid clutter present results nonresponse feature set bookdown appendix table .]","code":"\nlab_list_to_text <- function(df) {\n  df %>%\n    var_label %>% unname %>% unlist() %>% paste(collapse = ', ')\n}\n# Create variable groupings for displaying coefficients\n## Can't think of a tidier way to do this...\n### Check that this extracts all necessary\n\ndemog_coefs <- c(\"Age\", \"Where live:\", \"Student\", \"city\", \"Gender:\", \"white\", \"race\")\nemp_gw_etg_coefs <- c(\"top-6 uni\", \"employ\", \"etg\", \"gwwc\")\n#fh_coefs <- c(\"hear\")\nnr_coefs <- c(\"response\", \"NA\")\n\nnonlin_coefs <- c(\"income\", \"age\", \"year\") #coefficients of interest not (always) reported elsewhere, allowing us to consider nonlinearity\n\n# Filter the coefficients returned from using broom::tidy\n## Keep only those specified in character vector keep\nextract_coefs <- function(df, keep, term_col = term,\n                          ignore.case = TRUE,\n                          exclude = NULL){\n\n  # Add assertion statements in/doc string\n\n  if (ignore.case == TRUE){\n    keep <- tolower(keep)\n  }\n\n  keep <- paste(keep, collapse=\"|\")\n\n  coef_df <- df %>% filter(str_detect(tolower({{term_col}}), keep))\n\n  if (!is.null(exclude)){\n  exclude <- paste(exclude, collapse=\"|\")\n    coef_df <- coef_df %>% filter(!str_detect(tolower({{term_col}}), exclude))\n  }\n\n  return(coef_df)\n}\n# Extract coefficients for each feature set, for making forest plots (and tables)\n\n# forms <- list(\"qp\", \"fl\", \"logit\")\n#--> pmap (todo @oska)\nqp_coefs <- qp_models %>%\n  select(qp_coefficients, model_name, outcome) %>%\n  tidyr::unnest(., cols = c(qp_coefficients))\n\nqp_coefs_noexp <- qp_models_noexp %>%\n  select(qp_coefficients, model_name, outcome) %>%\n  tidyr::unnest(., cols = c(qp_coefficients))\n\nfl_coefs <- fl_models %>%\n  select(fl_coefficients, model_name, outcome) %>%\n  tidyr::unnest(., cols = c(fl_coefficients))\n\nfl_coefs_noexp <- fl_models_noexp %>%\n  select(fl_coefficients, model_name, outcome) %>%\n  tidyr::unnest(., cols = c(fl_coefficients))\n\nfl_coefs_noexp_nonrobust <- fl_models_noexp_nonrobust %>%   select(fl_coefficients, model_name, outcome) %>%\n  tidyr::unnest(., cols = c(fl_coefficients))\n\nlogit_coefs <- logit_models %>%\n  select(logit_coefficients, model_name, outcome) %>%\n  tidyr::unnest(., cols = c(logit_coefficients))\n\n# feature_sets <- list(\"demog\", \"inc_emp_gw_etg\", \"fh\", \"nr\")\n#--> pmap2 feature_sets, forms (todo @oska) .. or maybe map across forms but not feature sets here, as we need bespoke exclusions\n\nexclude_demog_coefs <- c(\"response\",\"older\", \"post_med\", \"ln_\" )\n\nexclude_inc_coefs <- c(\"response\", \"if above\", \"older\", \"na\")\n\n#exclude_fh_coefs <- c(\"response\", \"if above\", \"older\") #will prob need to add coefs for all the small fh categories if we put these all in\n\ndemog_coefs_qp <- extract_coefs(qp_coefs, demog_coefs, exclude = c(exclude_demog_coefs))\nemp_gw_etg_coefs_qp <- extract_coefs(qp_coefs, emp_gw_etg_coefs, exclude = exclude_inc_coefs)\nnr_coefs_qp <- extract_coefs(qp_coefs, nr_coefs)\nnonlin_coefs_qp <- extract_coefs(qp_coefs, nonlin_coefs)\nnonlin_coefs_qp_noexp <- extract_coefs(qp_coefs_noexp, nonlin_coefs)\n\nnonlin_coefs_qp_combo  <- bind_rows(nonlin_coefs_qp_noexp %>% filter(str_detect(term, \"Year of\")==FALSE), nonlin_coefs_qp %>% filter(str_detect(term, \"Year of\")==TRUE))\n\ndemog_coefs_fl  <- extract_coefs(fl_coefs, demog_coefs,  exclude = exclude_demog_coefs)\n\nemp_gw_etg_coefs_fl <- extract_coefs(fl_coefs, emp_gw_etg_coefs, exclude = exclude_inc_coefs)\n\n#TODO: doublecheck the income coefficients:\n\nnr_coefs_fl <- extract_coefs(fl_coefs, nr_coefs)\nnonlin_coefs_fl <- extract_coefs(fl_coefs, nonlin_coefs)\nnonlin_coefs_fl_noexp <- extract_coefs(fl_coefs_noexp, nonlin_coefs)\nnonlin_coefs_fl_noexp_nonrobust <- extract_coefs(fl_coefs_noexp_nonrobust, nonlin_coefs)\n\nnonlin_coefs_fl_combo  <- bind_rows(nonlin_coefs_fl_noexp %>% filter(str_detect(term, \"Year of\")==FALSE), nonlin_coefs_fl %>% filter(str_detect(term, \"Year of\")==TRUE))\n\n\ndemog_coefs_logit <- extract_coefs(logit_coefs, demog_coefs, exclude = exclude_demog_coefs)\nemp_gw_etg_coefs_logit <- extract_coefs(logit_coefs, c(\"income\", emp_gw_etg_coefs), exclude = exclude_inc_coefs)\nnr_coefs_logit <- extract_coefs(logit_coefs, nr_coefs)\nnonlin_coefs_logit <- extract_coefs(logit_coefs, nonlin_coefs)\ngroup_fp_do <- function(df, groups=model_name, xlims=c(NA,NA), vl=1){\n  df %>%\n    grouped_forest_plot(., groups = {{groups}}, vline = {{vl}}) +\n    coord_cartesian(xlim = {{xlims}}) +\n    scale_colour_discrete(name = \"\",\n                        labels = function(x) str_wrap(x, width = 15)) +\n  theme_bw() +\n  theme(legend.position = \"bottom\") +\n  guides(fill=guide_legend(nrow=2,byrow=TRUE))\n}\n#TODO: Add to caption at bottom, automate, specify the exact models (or at least explain the control variables)\n# Legend on top or bottom?\n# Todo -- gray line in background\n# add more grid lines\n\n\nfp_qp_subtitle <- \"Quasi-poisson: relative rates, 95% CIs (Robust SEs); colors = models\"\n\nfp_logit_subtitle <- \"Logit model, proportional effects, 95% CIs; colors = models\"\n\nfp_fl_subtitle <- \"Frac. Logit model, prop. effects, 95% CIs; colors = models\"\n\nfp_caption = str_wrap(\"Results come from three distinct models, each with different sets of features. These models and their features are fully described in the main text. All confidence intervals are heteroskedasticity-robust (White, 1980).\", 120)\n\n#todo (@oska) purr::map these too\nfp_demog_coefs_qp <- demog_coefs_qp %>%\n  group_fp_do(vl=1) +\n  labs(title= \"'Donation amount', demog. coefficients\",\n       subtitle = fp_logit_subtitle,\n       caption = fp_caption ) +\n  theme(plot.caption = element_text(size = 8, hjust = 0))\n\nfp_demog_coefs_fl <- demog_coefs_fl %>%\n  group_fp_do(vl=1) +\n  labs(title= \"'Donation/income', demog. coefficients, 2018-20\",  subtitle = fp_fl_subtitle,   caption = fp_caption) #TODO -- get me my ticks for 0.25, 0.5 etc\n\nfp_demog_coefs_logit <- demog_coefs_logit  %>%\n  group_fp_do(vl=1) +\n  labs(title= \"'Donated $1000+', demog. coef., 2018-20\",  subtitle = fp_logit_subtitle,   caption = fp_caption)\n\n\n#todo (@oska) purr::map these too\nfp_emp_gw_etg_coefs_qp <- emp_gw_etg_coefs_qp %>%\n  filter(!(str_detect(model_name, \"Robust\") & str_detect(term, \"Income\"))) %>%  #Don't show income in models with nonlinear income terms\n  group_fp_do(vl=1) +\n  labs(title= \"'Donation amount', career-related coefs, 2018-20\",  subtitle = fp_qp_subtitle,\n         caption = fp_caption)\n\n#TODO -- NA STILL HERE!\n\n\nfp_emp_gw_etg_coefs_fl <- emp_gw_etg_coefs_fl %>%\n  filter(!(str_detect(model_name, \"Robust\") & str_detect(term, \"Income\"))) %>%\n  group_fp_do(vl=1) +\n  labs(title= \"'Donation as share of income', proportional model, career-related coefs\",  subtitle = fp_qp_subtitle,   caption = fp_caption)\n\nfp_emp_gw_etg_coefs_logit <- emp_gw_etg_coefs_logit %>%\n  filter(!(str_detect(model_name, \"Robust\") & str_detect(term, \"Income\"))) %>%\n  filter(!(str_detect(term, \"NA\"))) %>%\n  group_fp_do(vl=1, xlims=c(0,NA)) +\n  labs(title= \"'Donated $1000+', Logit model, career-related coefs\",  subtitle = fp_logit_subtitle,\n         caption = c(fp_caption)\n       )\n\n###\n##TODO -- get NA out of here!"},{"path":"eas_donations.html","id":"demog_mod","chapter":"3 Donation","heading":"Model theme: Demographics","text":", plot estimates (heteroskedasticity-robust) 95% confidence intervals key demographic coefficients three models. , want emphasize models also ‘control’ wide set characteristics (e.g., income, age, time--EA), cataloged .first present results Quasi-Poisson model donation amount (expressed average current planned donation year, whichever noted). model allows effects “proportional”, described interpreted .39In figure , vertical bar “1” represents coefficient “difference donation groups, else equal”. 95% confidence intervals cross line (City, just barely), rule ‘difference’ conventional frequentist null-hypothesis testing.Still, evidence suggests (else equal), individuals big cities named EA survey donate substantially .40Point estimates imply donate 18-19% average (considering baseline model model robust controls), 25% average, also adjust earning--give GWWC status.41Ethnicity seems little relationship donation , least little evidence suggest relationship. coefficients “just white” close zero, wide 95% confidence intervals.gender coefficients weakly suggest women nonbinary people donate somewhat less, else equal. Students seem donate substantially less, perhaps 70-80% much nonstudents. Still, conventional sense (95% confidence interval), rule differences observed sample due chance, fact, differences relevant population zero, opposite direction. (Also, see caveats post potential non-representativeness, recall bias measurement error, etc.)plot estimates, features, (Fractional Logit) models ‘share income donated’ (income imputed 0 5000, explained ).42We find generally similar results models donation amounts, perhaps slightly important role gender (non-males donating lower share else equal), slightly less important role student status. However, none coefficients statistically significant conventional sense.EAs living named cities donate substantially higher share income, else equal – roughly 6.8% greater share baseline model.43Again, little evidence ethnicity related outcome. Non-males seem donating somewhat lower share income, 89.2% high share baseline model. Students also seem donate lower shares, 94.4% high baseline model.final outcome variable ‘whether individual donated $1000 ’. also present normalized age coefficient.44Age strong relationship outcome: two standard deviation increase age (19.6 years older) associated near-doubling probability donating 1000 USD model. (1.78 times high baseline model.), baseline model…EAs living named big cities likely – roughly 18.4% likely,EAs living named big cities likely – roughly 18.4% likely,Non-males 80.9% likely males,Non-males 80.9% likely males,‘-just-white’ people 82.3% likely white people,‘-just-white’ people 82.3% likely white people,students 62.9% likely nonstudents…students 62.9% likely nonstudents……donate least 1000 dollars, else equal.graph suggests results similar across three models. coefficients statistically significant conventional sense","code":"\nfp_demog_coefs_qp\nfp_demog_coefs_fl\nrpct <- function(x){ (round(x, 3) -1)*100}\nfp_demog_coefs_logit"},{"path":"eas_donations.html","id":"mod_emp","chapter":"3 Donation","heading":"Model theme: Employment/career, GwwC, EtG, (income)","text":"Next consider employment career-related features.45Unsurprisingly, report ever taken GWWC pledge, report Earning--Give career also report donating substantially , else equal. However, magnitudes strikingly large: donate nearly twice much, 50% , respectively.attended global top-6 universities (defined ) also donate substantially , 34.8% baseline model point estimate.part-time-employed seem donate somewhat , else equal, although confidence intervals wide. employed tend donate less.Similarly , report ever taken GWWC pledge, report Earning--Give career tend donate much larger share income rest, else equal. Specifically, twice large share GWWC, 50% EtG.see similar patterns top-6 university employed. However results part-time employer contrast previous plot. part-time employed tend donate somewhat overall, tend donate lower share income base group (full-time employed), else equal. (, recall already controls income factors.)see similar patterns logit models “whether donated least 1000 USD”, notable exceptions. Similarly, GWWC pledgers much likely donate least amount. EtG people show less dramatic difference, 31.5% likely base group, else equal.(models without two-part controls) also present relationship income. Unsurprisingly, income strong positive association probability donating 1k : income 56125 USD greater (25-75 ‘interquartile range’) associated 2.82 times greater probability .top-6 universities part-time employed appear slightly (‘significantly’) likely donate 1k , else equal. -employed substantially less likely donate 1k .","code":"\nfp_emp_gw_etg_coefs_qp\nfp_emp_gw_etg_coefs_fl\nfp_emp_gw_etg_coefs_logit"},{"path":"eas_donations.html","id":"nonlin","chapter":"3 Donation","heading":"Age, time-in-EA, Income, Year; possible nonlinearity","text":"next present estimates, six nine models (excluding models involving GWWC earning--give), continuous-valued features (age, income, years--EA) well survey-year categorical feature. present baseline ‘Robust control’ models; latter allow us consider distinct patterns values -median. present tables rather forest plots, interpretation subtle.first consider models amount donated, using proportional (Quasi-Poisson) specification. , coefficients reported way allows considered elasticities (discussed ). coefficient survey year dummies presented way allows ‘proportional change’ interpretation, presented previous plots.46\nTable 3.10: Don. ‘avg’\nBaseline\nRobust controls\nRobust controls\nBaseline\nRobust controls\nRobust controls\nBaseline\nRobust controls\nRobust controls\nBaseline\nRobust controls\nBaseline\nRobust controls\nBaseline model, see , unsurprisingly, donations clearly strongly increase income, else equal; parlance Economics, donation seems ‘Normal good.’ estimated income elasticity 0.948, suggesting , else equal, average, income increases data share ‘X’, donations increase slightly less share. .e. donations increase slightly less proportionally income, suggesting donation ‘luxury good’ strict Econ-1 sense. However, upper confidence interval still somewhat 1 (usual caveats sample selection, unobservable factors, causality apply).model 2 include adjustment coefficient allow nonlinearity, allowing elasticity donations income distinct income levels median. coefficient positive (loosely suggesting , -average levels income, greater income leads proportionally greater donations) small, rule zero difference. Arguably, fact even upper confidence interval adjustment rather small speaks strong nonlinearity, favor ‘proportional donations’ model starting point.Age positive relationship donation; baseline coefficient suggests age doubles, contributions increase 53.8% average, else equal. Model 2 suggests ‘age relationship’ approximately proportional way, small (statistically insignificant) positive adjustment ages median (age 28).Time--EA strongly related donations, even ‘controlling age, etc.’ (vice versa). doubling years EA associated 62.8% greater donation. nonlinear adjustment term fairly small statistically insignificant.‘survey year difference’ estimates (2019 2020, 2018 base year) fairly close 1 (representing ‘difference’). However, 95% confidence intervals rather wide, suggesting lack statistical power discern difference.47We next present corresponding coefficients fractional logit models ‘donations share income’.\nTable 3.10: Don./Income (imp, bc)\nBaseline\nRobust controls\nRobust controls\nBaseline\nRobust controls\nRobust controls\nBaseline\nRobust controls\nRobust controls\nBaseline\nRobust controls\nBaseline\nRobust controls\nbaseline models suggest donation share income roughly constant, slightly increasing income. every doubling income, share income donated seen increase 4.26%. 95% confidence intervals include small decreases increases share income doubles (-5% +13%), evidence suggests approximate proportionality. Model 2 suggests pattern continues larger incomes, little apparent nonlinearity median income (fairly tight bounds ).Age strongly positively associated ‘donation share income’, doubling age approximately relating 85.3% increase share income donated (.e., doubling share, average, observables held constant).48Years--EA also shows strong association share income donated, doubling ‘tenure’ approximately relating 61.4% increase share income donated.adjustment coefficients small fairly-tightly bounded, suggesting perhaps small differences relationships values age tenure medians.models find statistically significant associations survey year share--income donated, else equal, 2019 2020 generally lower values 2018. However, want read much , given possible differences survey response composition, discussed posts.Finally, consider models ‘donated 1k ’:\nTable 3.10: Don. > 1k USD\nBaseline\nRobust controls\nRobust controls\nBaseline\nRobust controls\nRobust controls\nBaseline\nRobust controls\nBaseline\nRobust controls\nBaseline\nRobust controls\nRobust controls\npresent exponentiated coefficients, representing relative proportional rates outcome distinct groups.Age strongly positively associated outcome (donation outcomes), 2 sd difference age (20.1) years associated near doubling probability making 1k donation. Unsurprisingly, income also strongly associated donating 1k .coefficients 2019 (especially) 2020 EA survey year dummies substantially 1, suggesting donating 1k becoming less prevalent among otherwise-similar individuals. However, noted , cautious ‘year coefficients’ potential changes EA survey promotion response may reflect actual changes EA population.‘years EA’ coefficients also extremely strong. suggest 2 sd increase tenure EA (4.89 years) associated 2.45 times greater relative chance donating 1k relative base group), else equal.","code":"\n#Making table of *raw coefficients* for logged income variables here, as these have elasticity interpretations\n\nnonlin_tables <- bind_rows(nonlin_coefs_qp_combo, nonlin_coefs_fl_combo, nonlin_coefs_logit) %>%\n    select(outcome, term, model_name, estimate, std.error, p.value, conf.low, conf.high) %>%\n  mutate(\n  term = str_replace_all(term, c(\"ln_\" = \"log \", \"EApost_med\"  = \"EA (post median)\")),\n  term =  str_replace_all(term, key_eas_all_labels),\n  term =  str_replace_all(term, c(\"Involved\" = \"in\")),\n  term =  str_replace_all(term, c(\"_bc5k\" = \"\")),\n  term =  str_replace_all(term, c(\"imp.\" = \"imp., bc\")),\n  term =  str_replace_all(term, c(\"years_inv_d2spost_med\" = \"Years in EA (2sd norm) post-median\"))\n  ) %>%\n    filter(!str_detect(model_name, \"GWWC\")) %>%\n  mutate(\n    outcome = str_replace_all(outcome,            key_eas_all_labels\n    )\n    ) %>%\n    arrange(term) %>%\n    group_by(outcome) %>%\n    group_split\n\n\nnonlin_don_avg_tab <- nonlin_tables[[1]] %>% select(-outcome) %>%\n  .kable(caption = nonlin_tables[[1]][[1,\"outcome\"]],\n          col.names = NA, digits=3) %>%\n    .kable_styling(\"striped\")\n\n\nnonlin_don_gt1k_tab <- nonlin_tables[[2]] %>% select(-outcome) %>%\n  .kable(caption = nonlin_tables[[2]][[1,\"outcome\"]],\n          col.names = NA, digits=3) %>%\n    .kable_styling(\"striped\")\n\nnonlin_donshare_tab <- nonlin_tables[[3]] %>% select(-outcome) %>%\n  .kable(caption = nonlin_tables[[3]][[1,\"outcome\"]],\n          col.names = NA, digits=3) %>%\n    .kable_styling(\"striped\")\nnonlin_don_avg_tab\nnonlin_donshare_tab\nnonlin_don_gt1k_tab"},{"path":"eas_donations.html","id":"predictive-models","chapter":"3 Donation","heading":"3.8.2 Predictive models","text":"use elastic-net random-forest modeling approaches validation (standard modern ‘machine learning’ tooklit), derive model ‘predicts well’.*discuss models may may useful bookdown (see margin note fold ).49We focus predicting individual’s donation year, focusing set outcomes used previous section. model useful actual prediction problem going forward, need rely ‘ex-ante’ characteristic already observable time career/EtG/pledge decision.50These might include immutable demographics, career plans, pledges previously taken, consider year trend effects.Although models mind, . posing specific ‘prediction problem’ per se. Instead using machine learning tools built prediction problems generate ‘data-driven insights’ factors related EA donation behavior. , directly specifying included components model (features, interaction terms, etc.). Instead provide large set possible ‘inputs’ use ML techniques train models predict well outside data trained . models good job accomplishing task: ‘gave set features EA, fairly accurate guess donate.’insights models also treated caution. , may deriving causal relationships. Furthermore, parameters derived model-fitting ML procedures general unbiased consistent, difficult derive proper confidence intervals parameters.Still, benefit exercise may considered ‘derivation robust predictive relationships data mainly driven data , rather preconcieved ideas.’ models may also useful building blocks towards future predictive work.Note: content present note part ‘Bookdown’ version EA forum post.…brief, elastic net models involve linear models (log-linear case), .e., ‘regressions’, carefully ‘penalize’ (squared) magnitude coefficients, effect shrinking towards zero. penalties specifically ‘tuned’ ‘validated’ maximize predictive power model. essentially regression approaches, can report sign magnitude coefficients used ‘optimally tuned’ predictive model. (However, careful interpreting parameters, statistical inference challenging. See e.g., Mullainathan Spiess (2017a) detailed discussion.)Decision tree models (report ) take different approach, attempting discern optimal ways split data conditional groups (e.g., ‘income 20k’) subgroups (e.g., ‘students versus nonstudents income 20k’), finally making prediction subgroup ‘bottom tree’. random forest approach extends allow sort averaging across ensemble trees derived independently, selecting random subset features.fit models/approaches, starting wide set potential features, explain three main outcomes considered . features include (nearly) considered , well ‘first heard EA’ responses.* , plot seven ‘important’ features (aka variables) predicting log donation amount (average planned actual, available) according random forest elastic net (‘regression’) models.51Above, report ‘importance scores’ ten important features (‘variables’) two distinct approaches predicting log (average) donation.52These importance scores technically defined . elastic net (“linear reg”) approach, depict coefficients’ signs “+” “-”; tree/forest-based modeling less straightforward.Income (normalized, bottom-coded 5000 USD, logged) important predictor model, wide margin. , relative importances vary. E.g., random forest model deems age student status particularly important, linear model ; turn linear model puts substantial importance non-response student status question, random forest modeling . put substantial importance years involved ‘employed’ statuses. Considering ‘one first-heard EA’, linear model finds nonresponse (lesser extent) GiveWell positively related important, 80000 hours negatively related predicted donation. also finds Earning Give somewhat important (positively related), perhaps lesser extent might expected.difficult interpret, probably useful future predictions, basically discuss non-response features .53As data exhibited large donation amount outliers, (naturally tied high income), re-trained models subset data respondents earned less $500,000, importance scores reported .results similar. income still important predictor models. ranking variables, importance scores generally similar ‘unfiltered’ model .54In extensive hosted ‘bookdown’ version present details results elastic-net regression-based models (feature sets). See .next focus specifically elastic-net regression-based model.graph presents overall ranking importance scores within elastic-net linear regression model, symbols depicting whether features take positive negative sign. addition mentioned , substantial importance assigned ‘first heard’ sources, e.g., GWWC several related sources, well Ted Talks positively predict log donation, 80000 Hours, Facebook, Educational course negatively predict log donation.","code":"\n# Need to see each of these variables for all models\ntuning_folder <- here(\"analysis\", \"intermed_results\", \"donation_prediction\", \"tuning_results\")\nfinal_models <- here(\"analysis\", \"intermed_results\", \"donation_prediction\", \"final_models\")\n\nl_don_av_2yr_best_params <- readRDS(here(final_models, \"l_don_av_2yr.Rdata\")) %>%\n  filter(!grepl(\"decision\", model, ignore.case = TRUE))\n\ndon_share_inc_imp_best_params <- readRDS(here(final_models, \"don_share_inc_imp.Rdata\")) %>%\n  filter(!grepl(\"decision\", model, ignore.case = TRUE))\n\nd_don_1k_best_params <- readRDS(here(final_models, \"d_don_1k.Rdata\")) %>%\n  filter(!grepl(\"decision\", model, ignore.case = TRUE))\n\nl_don_av_2yr_best_params_filter <- readRDS(here(final_models, \"l_don_av_2yr_filter.Rdata\"))  %>%\n  filter(!grepl(\"decision\", model, ignore.case = TRUE))\n\n# don_share_inc_imp_best_params_filter <- readRDS(here(final_models, \"don_share_inc_imp_filter.Rdata\"))\n# d_don_1k_best_params_filter <- readRDS(here(final_models, \"d_don_1k_filter.Rdata\"))\n\nl_don_av_2yr_best_params <- l_don_av_2yr_best_params %>%\n  bind_rows(l_don_av_2yr_best_params_filter)\n\n#don_share_inc_imp_best_params <- don_share_inc_imp_best_params %>% bind_rows(don_share_inc_imp_best_params_filter)\n\n#d_don_1k_best_params <- d_don_1k_best_params %>%  bind_rows(d_don_1k_best_params_filter)\nrecode_params <- function(df){\n    # Shortcut function to tidy up variable names in parameter df\n    df <- df %>% dplyr::select(model, vi) %>%\n    tidyr::unnest(vi) %>%\n    mutate(model = str_replace_all(model,\n                                   c(\"preprocess_\" = \"\", \"_\"  = \" \")),\n           Variable =  str_replace_all(Variable, key_eas_all_labels),\n           Variable =  str_replace_all(Variable,\n                                       c(\"_\"  = \" \", \"_Student\" =\"\", \"ln\" = \"log\")),\n           Sign = if_else(is.na(Sign), \"NA\", Sign))\n}\n\n\nnorm_vi <- function(df, slice_top = 7){\n  # Shortcut function for calculating normalized variable importance\n  # Not reproducible...\n  df %>% group_by(model) %>%\n    mutate(Norm = scale_var(Importance)) %>%\n    group_by(Variable) %>%\n    mutate(Total_Norm = sum(Norm)) %>%\n    group_by(model) %>%\n    slice_max(Total_Norm, n = slice_top) %>%\n    mutate(Variable = fct_reorder(Variable, Norm))\n}\n\nplot_vi <- function(df, shapes = shape_colours){\n  # Shortcut function for plotting normalized variable importance (output of norm_vi)\n  df %>% ggplot(aes(y = Variable, x = Norm, colour = model, shape = Sign)) +\n    scale_shape_manual(values = shapes) +\n    geom_point(size = 4, stroke = 5) +\n    xlab(\"Normalised feature importance\") + ylab(\"\")\n}\n\n\n#specific changing of variable  and signs for the below.\nmutate_labels_sign_snip <- function(df) {\n  df %>%\n     mutate(\n  Variable = str_replace_all(Variable,\n    c(\"First-heard EA\"=\"Heard EA:\",\n      \"response\" = \"resp.\",\n      \"Gender Gender\" = \"Gender\",\n      \"unknown\" = \"No resp.\",\n      \"Student Student\" = \"Student\",\n      \"X80000\" = \"80000\")),\n  Sign = if_else(is.na(Sign), \"NA\", Sign)\n    )\n}\n\n# Set colors for shapes as a named vector\nshape_colours <- c(\"NA\" = 120, \"NEG\" = 95, \"POS\" = 43)\n# Tidy up parameters\nl_don_av_2yr_best_params_recode <- l_don_av_2yr_best_params %>% filter(is.na(filter_name)) %>% recode_params\nl_don_av_2yr_best_params_recode_filter <- l_don_av_2yr_best_params %>% filter(!is.na(filter_name)) %>% recode_params\n\ndon_share_inc_imp_best_params_recode <- don_share_inc_imp_best_params %>% recode_params\n\nd_don_1k_best_params_recode <- d_don_1k_best_params %>% recode_params#NOT RUN\n# Starting to plot decision trees (early stages)\n\nl_don_av_2yr_tree <- l_don_av_2yr_best_params %>%\n  mutate(\n    model = str_replace_all(\n      model, c(\"preprocess_\" = \"\", \"_\"  = \" \"))\n  ) %>%\n  filter(!grepl(\"decision\", model, ignore.case = TRUE))\n) %$%\n  workflowsets::extract_fit_parsnip(fit[[1]])\n\n# l_don_av_2yr_treeX <- l_don_av_2yr_best_params %>%\n#    mutate(\n#     model = str_replace_all(\n#       model, c(\"preprocess_\" = \"\", \"_\"  = \" \"))\n#   ) %>%\n#   filter(str_det(model, \"decision tree\")) %$%\n#   workflowsets::extract_fit_parsnip(fit[[1]])\n#, fig.dim = c(10, 10)\n\n(\niplot_l_don_av_2yr_best_params <-\n  l_don_av_2yr_best_params_recode %>%\n  filter(!grepl(\"tree\", model, ignore.case = TRUE)) %>%\n    norm_vi(slice_top = 10) %>%\n    mutate_labels_sign_snip %>%\n  slice_max(Total_Norm, n = 10) %>%\n  mutate(Variable = fct_reorder(Variable, Norm)) %>%\n  ggplot(aes(y = Variable, x = Norm, colour = model, shape = Sign)) +\n    scale_shape_manual(values = c(120, 95, 43)) +\n  geom_point(\n    position = position_jitter(seed = 42,  width = 0.1, height = 0.1),\n    size = 4, stroke = 5) +\n  xlab(\"Normalised feature importance\") +\n  ylab(element_blank()) +\n  ggtitle(\"Normalized importance scores: predicting log(don.)\")\n)\n(\niplot_l_don_av_2yr_best_params_filter <-\n  l_don_av_2yr_best_params_recode_filter %>%\n      filter(!grepl(\"tree\", model, ignore.case = TRUE)) %>%\n    norm_vi(slice_top = 10) %>%\n    mutate_labels_sign_snip %>%\n  slice_max(Total_Norm, n = 10) %>%\n  mutate(Variable = fct_reorder(Variable, Norm)) %>%\n  ggplot(aes(y = Variable, x = Norm, colour = model, shape = Sign)) +\n    scale_shape_manual(values = c(120, 95, 43)) +\n  geom_point(\n    position = position_jitter(seed = 42,  width = 0.1, height = 0.1),\n    size = 4, stroke = 5) +\n  xlab(\"Normalised feature importance\") +\n  ggtitle(\"Importance: predict log(don.) (filter: income < 500k)\")\n)\n# TODO -- important -- what are the base groups here, especially for 'first-heard'? I thought in previous work we made \"don't remember\" the base group! This is important for interpreting the coefficient signs!\n\n# Plot all coefficients for elastic net model\n#TODO (DR @ OF -- plot the coefficients rather than the importance weights? (the latter are absolute value t-values anyways))\n\n#TODO/check DR @ OF -- why is 'year of survey 2015' (and 2017) in here? those years should have been removed from the dataset; I think they have been, but still it somehow reports an importance score? -- OK I am removing '0' importance scores for now\n\n(\nenet_coefs_ldon <- l_don_av_2yr_best_params_recode %>%\n      filter(\n        grepl(\"regression\", model, ignore.case = TRUE)  & Importance!=0) %>%\n  mutate_labels_sign_snip %>%\n  #mutate(Norm = scale_var(Importance)) %>%\n    mutate(Variable = fct_reorder(Variable, Importance)) %>%\n\n  ggplot(aes(y = Variable, x = Importance, shape = Sign)) +\n      scale_shape_manual(values = c(95, 43)) +\n  geom_point(size = 2, stroke = 4) +\n  xlab(\"Feature importance\") +\n  ggtitle(\"Importance scores: predicting log(don.)\")\n)"},{"path":"eas_donations.html","id":"predictive-model-shares-of-income-donated","chapter":"3 Donation","heading":"Predictive model: Shares of income donated","text":"Next consider shares income donated, income imputed bottom-coded mentioned previous sections.(Log) Income deemed highly important predictor share income donated, random forest models regression models.55Both types models assign importance age years involved; much stronger random forest (linear models positive signs middling importance). hand, also assign importance reporting one ‘remember determine first heard EA’; much stronger linear model (deemed important feature, positive sign). Overall, importance scores rather divergent. linear models assign importance (positive sign) people indicating first heard EA ‘Raising Effective Giving, EA Funds, Foundational Research Institute “Swiss group”’, GWWC related ‘pledge/charity orgs’, , much lesser extent, GiveWell Ted Talk.56Further details figures can found ‘Bookdown’ version .present remaining signed non-zero importance scores linear model figure .","code":"\n(\n  iplot_don_share_inc_imp_best_params <- don_share_inc_imp_best_params_recode %>%\n      filter(!grepl(\"tree\", model, ignore.case = TRUE)) %>%\n    mutate_labels_sign_snip %>%\n    norm_vi(slice_top = 10) %>%\n  plot_vi() +\n  ggtitle(\"Importance scores: predicting share of income donated \")\n)\n(\nplot_enet_coefs_don_share <- don_share_inc_imp_best_params_recode %>%\n      filter(\n        grepl(\"regression\", model, ignore.case = TRUE) & Importance!=0) %>%\n    mutate_labels_sign_snip %>%\n  #mutate(Norm = scale_var(Importance)) %>%\n    mutate(Variable = fct_reorder(Variable, Importance)) %>%\n\n  ggplot(aes(y = Variable, x = Importance, shape = Sign)) +\n      scale_shape_manual(values = c(95, 43)) +\n  geom_point(size = 2, stroke = 4) +\n  xlab(\"Feature importance\") +\n  ggtitle(\"Importance scores: predicting log(don.)\")\n)"},{"path":"eas_donations.html","id":"predictive-model-donated-1k-usd-or-more","chapter":"3 Donation","heading":"Predictive model: Donated 1k USD or more","text":"approaches deem (logged, imputed, bottom-coded) income important predictor donating 1k USD . also consider (log) years involved age substantially important. logistic regression elastic-net model assigns importance several sources ‘learning EA’, ‘Ted Talks’, ‘GWWC related’, (less ) Givewell (well nonresponse) deemed particularly important, positive signs . random forest (linear model) also deems student status somewhat important associated feature.details figures can found ‘Bookdown’ version .Next, plot (nonzero) importance scores coefficients elastic-net logistic model donating 1k .","code":"\n(\n  iplot_don_1k_best_params <- d_don_1k_best_params_recode %>%\n      filter(!grepl(\"tree\", model, ignore.case = TRUE)) %>%\n    mutate_labels_sign_snip %>%\n    norm_vi(slice_top = 10) %>%\n  plot_vi() +\n  ggtitle(\"Importance scores: predicting donation > 1k USD \")\n)\n(\nplot_enet_coefs_don_1k <- d_don_1k_best_params_recode %>%\n    filter(\n      grepl(\"logistic\", model, ignore.case = TRUE) & Importance!=0) %>%\n    mutate_labels_sign_snip %>%\n  #mutate(Norm = scale_var(Importance)) %>%\n    mutate(Variable = fct_reorder(Variable, Importance)) %>%\n\n  ggplot(aes(y = Variable, x = Importance, shape = Sign)) +\n      scale_shape_manual(values = c(95, 43)) +\n  geom_point(size = 2, stroke = 4) +\n  xlab(\"Feature importance\") +\n  ggtitle(\"Importance scores: predicting donation > 1000k USD\")\n)"},{"path":"eas_donations.html","id":"model-perf","chapter":"3 Donation","heading":"3.8.2.1 Model Performance","text":"Note: hosted ‘bookdown’ discuss ‘well models predict’ (see final subsection linked section). Overall, models offer predictive power. E.g., note 46% relevant sample reports 1k donations. logistic regression model can correctly predict 75% outcomes false-positive rate around 25%.57We may want consider ‘successful’ predictive models making practically useful predictions. words, ‘far ’ predictions classifications average, actual outcomes. procedure considers fit randomly-drawn set-aside ‘testing data’, data used ‘training’ (‘fitting’) model. , consider commonly-used metrics.","code":""},{"path":"eas_donations.html","id":"regression-model-performance","chapter":"3 Donation","heading":"Regression Model Performance","text":"Reminder: section (discussing performance) briefly summarized/linked EA Forum post.order assess usefulness predictive regression model consider root-mean-square-error (RMSE) mean-absolute-error (MAE). RMSE (aka RMSD) can interpreted average ‘Euclidean distance’ actual values model’s prediction. observation (set-aside ‘testing sample’), construct RMSE :Measure differences actual predicted outcome (e.g., donation)Square differencesTake average squared differences across observationsTake square root thisTo construct mean-absolute-error (MAE) simplyMeasure absolute-value differences actual predicted outcome (e.g., donation) observationTake average across observationsMAE much straightforward interpretation: simply asks ‘far , average?’RMSE used model fitting various reasons, arguably less-interpretable less-relevant MAE judging model’s fit cases like one. RMSE error negatively assesses model fit based squared deviations, thus sensitive ‘large mistakes’. may relevant ‘large errors much much worse small ones’ – , clearly case. presence data large outlying observations, prediction tend poor measure.address :Present RMSE MAERe-run models (log average) donations subset individuals incomes 500,000 USD. subset, fewer influential donation outliers.latter also allows us consider sensitive model fit outliers.Note considering models outcome transformed (e.g., log(donations)) construct RMSE MAE exponentiating generate predictions level outcomes, measure deviations level scale.58\nTable 3.11: Regression model performance\ncompare ‘naive model’ predict average donation everyone? Note comparable unfiltered data, mean absolute deviation 13305.9303138871 standard deviation 106109. predictive model reduces uncertainty substantially.","code":"\nl_don_av_2yr_best_params <- l_don_av_2yr_best_params %>% mutate(dv = \"Donation amount*\")\n\ndon_share_inc_imp_best_params <- don_share_inc_imp_best_params %>%\n  mutate(dv = \"Donation as a share of income\")\n\n\n(\n  reg_model_performance <- purrr::map(list(l_don_av_2yr_best_params, don_share_inc_imp_best_params), ~.x %>%\n      dplyr::select(dv, rmse, mae, model, matches(\"filter_name\"))\n      ) %>%\n  bind_rows() %>%\n    mutate(filter_name = if_else(is.na(filter_name), \"None\", filter_name)) %>%\n  rename(\"Dependent variable\" = dv,\n         \"RMSE\" = rmse,\n         \"MAE\" = mae,\n         \"Model\" = model,\n         \"Filter\" = filter_name) %>%\n  kable(caption = \"Regression model performance\",\n        digits = 2) %>%\n  kable_styling() %>%\n  add_footnote(\"Note: While the model was trained using logs of the dependent variable, RMSE and MAE were calculated in levels\", notation = \"symbol\")\n)\np_load(ie2misc)\n\nmad_naive <- ie2misc::madstat(eas_all_s_rl_imp$donation_usd, na.rm=TRUE)\n\nsd_naive <- round((sd(eas_all_s_rl_imp$donation_usd, na.rm=TRUE)), 0)"},{"path":"eas_donations.html","id":"classification-model-performance","chapter":"3 Donation","heading":"3.8.2.1.1 Classification Model Performance","text":"Reminder: section (discussing performance) briefly summarized/linked EA Forum post.evaluating classification model performance variety metrics can used. Firstly show ROC curve consider differences predictive power various models. can also compare uninformed classifier, simply predict positive outcome random probability \\(p\\) (maps 45 degree line).ROC curve plots true positive rate (sensitivity) function false positive rate (1-specificity). true positive rate gives rate model correctly predicts respondent donate $1000, false positive rate giving rate predictions incorrect.Better classifiers ROC curve North-West, perfect classifier L-shaped curve passing \\((0,0) \\rightarrow(0,1) \\rightarrow(1,1)\\). classifiers ROC curves cross, clear one performing better another. case . models seem performing relatively similarly, ROC curves overlapping somewhat. difficult discern model performing best, depend criterion.However, models yield curves substantially 45 degree line, thus substantially outperforming uninformed classifier. example, willing accept 25% rate false positives (falsely predicting 1k+ donation), logistic regression model correctly predicts 75% true positives (random forest model 73%).can use area curve (AUC) measure compare classifiers costs misclassification. measure quantifies close ROC curve optimal L-shaped curve.see random forest performs best terms AUC. models perform much better -skill classifier simply predicts majority class. suggest predictive power explanatory variables included models.","code":"\n# Add column for ROC curve\n\nroc_curve <- yardstick::roc_curve\nunnest <- tidyr::unnest\npr_curve <- yardstick::pr_curve\n\n# Calculate ROC curve\nd_don_1k_best_params$roc_curve <- d_don_1k_best_params %>% select(true_y, preds, pred_prob, model) %>%\n  unnest(cols = everything()) %>%\n  group_by(model) %>%\n  group_map(~ roc_curve(., true_y, .pred_FALSE))\n\n# Calculate AUC\nd_don_1k_best_params$auc <- d_don_1k_best_params %>% select(true_y, preds, pred_prob, model) %>%\n  unnest(cols = everything()) %>%\n  group_by(model) %>%\n  group_map(~ yardstick::roc_auc(., truth = true_y, estimate = .pred_FALSE))\n\n# Extract AUC\nd_don_1k_best_params <- d_don_1k_best_params %>%\n  unnest_wider(., col = auc) %>%\n  select(-c(.metric, .estimator)) %>%\n  rename(auc = .estimate)\n\n# Plot ROC curve\n(roc_curve_d_don_1k <- d_don_1k_best_params %>% select(roc_curve, model) %>%\n  unnest(cols = everything()) %>%\n  rename_with(snakecase::to_title_case) %>%\n  ggplot(aes(x = 1-Specificity, y = Sensitivity, colour = Model)) +\n  geom_line() +\n  geom_abline(slope=1, intercept = 0, linetype = \"dotted\") +\n  theme_bw()\n)\ncalculate_metrics <- function(df, metrics, preds = preds, true_y = true_y){\n  df %>% mutate(purrr::map2_dfr({{true_y}}, {{preds}}, ~ purrr::map_dfc(metrics,\n                                                                        do.call,\n                                                                        list(.x, .y))))\n}\n\nclass_metrics <- list(accuracy = yardstick::accuracy_vec,\n                      recall = yardstick::recall_vec,\n                      precision = yardstick::precision_vec,\n                      f1_score = yardstick::f_meas_vec)\n\n# Adding a no skill classifier to d_don_1k\n## Messy code\ntruth <- d_don_1k_best_params$true_y[[1]]\nmajority <- tail(names(sort(table(truth))), 1)\n\npred_majority <- as.logical(rep(majority, length(truth)))\n\n.pred_FALSE <- 1 - pred_majority\n.pred_TRUE <- 1 - .pred_FALSE\n\npred_prob <- tibble(.pred_FALSE, .pred_TRUE, truth)\n\nno_skill <- tibble(model = \"No Skill\",\n                   true_y = list(truth),\n                   pred_prob = list(pred_prob),\n                   preds = list(factor(pred_majority, levels = levels(truth)))) %>%\n  calculate_metrics(class_metrics)\n\nno_skill$auc <- yardstick::roc_auc_vec(truth, .pred_TRUE)\n\npurrr::map_df(list(no_skill, d_don_1k_best_params), ~.x %>%\n             select(model, auc, accuracy)) %>%\n  rename_with(snakecase::to_title_case) %>%\n  rename(AUC = Auc) %>%\n  kable(digits = 3) %>%\n  kable_styling()\n# Calculate precision recall curve\n# d_don_1k_best_params$pr_curve <- d_don_1k_best_params %>% select(true_y, preds, pred_prob, model) %>%\n#   unnest(cols = everything()) %>%\n#   group_by(model) %>%\n#   group_map(~ pr_curve(., true_y, .pred_FALSE))\n#\n# d_don_1k_best_params %>% select(pr_curve, model) %>%\n#   unnest(cols = everything()) %>%\n#   ggplot(aes(x = recall, y = precision, colour = model)) +\n#   geom_path() +\n#   coord_equal() +\n#   theme_bw() +\n#   geom_hline(aes(yintercept = 0.46))\nbest_d_don_1k_preds <- d_don_1k_best_params %>%\n  filter(f1_score == max(f1_score)) %$% preds[[1]]\n\nd_don_1k_true <- d_don_1k_best_params %>%\n  filter(f1_score == max(f1_score)) %$% true_y[[1]]\n#DR: @Oska, I'm just guessing this is what you wanted\n\nd_don_1k_preds_df <- tibble(preds = best_d_don_1k_preds,\n                            truth = d_don_1k_true)\n\ncm <- yardstick::conf_mat(d_don_1k_preds_df, truth, preds)\n\nautoplot(cm, type = \"heatmap\") +\n  scale_fill_gradient(low=\"#D6EAF8\",high = \"#2E86C1\") +\n  ggtitle(\"Predicting Donations over $1k\")"},{"path":"eas_donations.html","id":"summary-of-modeling-results-see-the-introduction","chapter":"3 Donation","heading":"3.8.3 Summary of modeling results – see the introduction","text":"end introduction ‘summary’ section give overall characterization modeling results bullet points; repeat .","code":""},{"path":"eas_donations.html","id":"robust-appendix","chapter":"3 Donation","heading":"3.9 Appendix: Extra analysis and robustness checks","text":"EA Forum Post: “See bookdown appendix analysis robustness checks.”appendix contains analysis robustness checks, mentioned alluded ‘main text’.section part ‘Bookdown’ version EA forum post.","code":""},{"path":"eas_donations.html","id":"save-to-don","chapter":"3 Donation","heading":"‘Saved to donate later’","text":"Sdded 30 Oct 2021A comment TylerMaule prompted us revisit question.2020, main donation questions, also askedAre presently saving money donate later, rather donate now? , roughly much money planning save 2020 purpose?report briefly . emphasize several reasons.unclear much responses reflects strong intention commitment (e.g., DAF contribution) manifested actual later donations. amount someone reports “presently saving … donate later” express vague intention donate late may subject changing mind, changes financial circumstance, value drift.unclear much responses reflects strong intention commitment (e.g., DAF contribution) manifested actual later donations. amount someone reports “presently saving … donate later” express vague intention donate late may subject changing mind, changes financial circumstance, value drift.difficult aggregate savings actual donations, lead double-counting. However, reporting results measures (saving actual donations) make report bulky.difficult aggregate savings actual donations, lead double-counting. However, reporting results measures (saving actual donations) make report bulky.However, hope look closely saving--donate behavior future. may particularly relevant patient longtermists.Key figures17.9% responses report saving donate later. (represents 24.6% answered question).17.9% responses report saving donate later. (represents 24.6% answered question).Among report saving donate, median donations 5000 USD mean donations 134,267 USDAmong report saving donate, median donations 5000 USD mean donations 134,267 USDSetting nonresponses zero mean ‘saved donate’ amount (including zeroes) 17,175Setting nonresponses zero mean ‘saved donate’ amount (including zeroes) 17,175We provide histogram , horizontal axis logarithmic scale.","code":"\neas_20 %<>%\n  rowwise() %>%\n  mutate(\n    donate_later_amount_na0 =\n      if_else(\n      is.na(donate_later_amount_c), 0, donate_later_amount_c),\n    donate_later_amount_min50 = max(50, donate_later_amount_c),\n    donate_later_amount_min50_na0 = if_else(\n      is.na(donate_later_amount_min50), 0, donate_later_amount_min50)\n    ) %>%\nungroup()\n\nnum_savdon <- sum(str_det(eas_20$donate_later, \"Yes\"))\nnum_na_savdon <- sum((eas_20$donate_later==\"\"))\ncount_eas_20 <- NROW(eas_20)\n\nmed_savdon <- med(eas_20$donate_later_amount_c)\nmean_savdon <- mean(eas_20$donate_later_amount_c, na.rm=TRUE)\n\nmean_savdon0 <- mean(eas_20$donate_later_amount_na0, na.rm=TRUE)\n\nmean_savdon0 <- mean(eas_20$donate_later_amount_na0, na.rm=TRUE)\n\nmean_savdon0_lt100k <- mean(eas_20$donate_later_amount_na0[eas_20$donate_later_amount_na0<=100000], na.rm=TRUE)\n#ddate -- adding 'saving to donate' amount here\n\n\n#eas_20 %>% tabyl(donate_later) %>% .kable() %>% .kable_styling()\n\n(\n  sav_don_20 <- eas_20 %>%\n    hist_plot_lscale(eas_20$donate_later_amount_min50, breaks = breaks) +\n    labs(title=\"Histogram of 'saved to to donate later, 2020, bottom-coded at 50'\", x = \"Amount in USD\", y = \"Number of respondents\"))"},{"path":"eas_donations.html","id":"don_eng","chapter":"3 Donation","heading":"Donations by engagement level","text":"","code":"\ndon_share_income_by_engage_sp"},{"path":"eas_donations.html","id":"don_inc_by_student","chapter":"3 Donation","heading":"Donations and income by student/employment status","text":", tabulate income donations, split student employment status.","code":"\n#this is an annoying workaround for the EA markdown ... but it shouldn't matter because this appendix is cut\n\nif(Sys.info()[[4]]==\"Yosemites-iMac.local\") {\n don_inc_by_student\n}\n\nif(Sys.info()[[4]]!=\"Yosemites-iMac.local\") {\n don_inc_by_student %>%\n      as_image(width = 8)\n}## I'm `fs` modules\n## PHANTOM ERROR: TypeError: undefined is not a constructor (evaluating 'require('fs').pathJoin(phantom.casperPath, 'modules', 'clientutils.js')')\n## TRACE:\n##  -> phantomjs://platform/casper.js: 1309 (in function injectClientUtils)\n##  -> phantomjs://platform/casper.js: 713 (in function evaluate)\n##  -> phantomjs://platform/casper.js: 1008 (in function getCurrentUrl)\n##  -> phantomjs://platform/casper.js: 1590 (in function runStep)\n##  -> phantomjs://platform/casper.js: 406 (in function checkStep)## Error in webshot::webshot(file_temp_html, file, ...): webshot.js returned failure value: 1"},{"path":"eas_donations.html","id":"don_share_by_tenure_facet_referrer","chapter":"3 Donation","heading":"Donation as share of income by tenure, ‘faceted’ by referrer to survey*","text":"several major groups referrers, () see strong positive association time--EA donations share income.","code":"\n(\ndon_share_by_tenure_facet_referrer <-\n  eas_20 %>%\n  filter(!is.na(age_approx_ranges)) %>%\n  ggplot() +\n  aes(x = tenure, y = don_share_inc_19_imp) +\n geom_point(size = 0.15, colour = \"#0c4c8a\", position = position_jitter(seed = 42,  width = 0.1, height = 0.001)) +\n  geom_smooth(span = 0.75) +\n  scatter_theme +\n  facet_grid(vars(), vars(referrer_cat2), scales = \"free\") +\nlabs(title = \"2019 donation as share of (imputed) income by time in EA faceted by referrer category\") +\n    labs(x = get_label(eas_20$referrer_cat2)) +\n  ylim(0, 0.3)\n) %>%\n  ggplotly"},{"path":"eas_donations.html","id":"additional-donations-and-income-by-whether-a-longtermist-cause-is-top-priority","chapter":"3 Donation","heading":"Additional: Donations and income by whether a Longtermist cause is top priority","text":"asked compare donations prioritize longtermist causes remainder EAs. , tabulate whether respondent gives longtermist cause high priority rating cause.presentation meant broadly descriptive. Overall, appears prioritize long-term causes tend donate bit less median mean, lot overlap two groups.","code":"\n#eas_20 %>% tabyl(lt_above_mn_priority)\n\n  #lt_4plus_priority = case_when(\n\ndon_income_by_priority <-\n    eas_20 %>%\n        dplyr::select(income_k_c, donation_2019_c, donation_2020_c, don_share_inc_19_imp,  lt_top_priority) %>%\n        tbl_summary( by = lt_top_priority,\n                      type = c(all_continuous()) ~ \"continuous2\",\n      statistic = list(all_continuous() ~ sumstatvec),\n        label = list(income_k_c ~ \"Income in $1000 USD\",\n                   donation_2019_c ~ \"2019 donation (in USD)\",\n                   donation_2020_c ~ \"2020 planned donation\",\n                  don_share_inc_19_imp ~ \"2019 donation as share of (imputed) income\"  ),\n            missing = c(\"no\")\n        ) %>%\n    bold_labels() %>%\n    add_n() %>%\n    add_overall()\n\nif(Sys.info()[[4]]==\"Yosemites-iMac.local\") {\n don_income_by_priority\n}\n\nif(Sys.info()[[4]]!=\"Yosemites-iMac.local\") {\n don_income_by_priority %>%\n      as_image(width = 8)\n}## I'm `fs` modules\n## PHANTOM ERROR: TypeError: undefined is not a constructor (evaluating 'require('fs').pathJoin(phantom.casperPath, 'modules', 'clientutils.js')')\n## TRACE:\n##  -> phantomjs://platform/casper.js: 1309 (in function injectClientUtils)\n##  -> phantomjs://platform/casper.js: 713 (in function evaluate)\n##  -> phantomjs://platform/casper.js: 1008 (in function getCurrentUrl)\n##  -> phantomjs://platform/casper.js: 1590 (in function runStep)\n##  -> phantomjs://platform/casper.js: 406 (in function checkStep)## Error in webshot::webshot(file_temp_html, file, ...): webshot.js returned failure value: 1\n# Todo (medium): fix labeling and titles above\n# Todo (High): add standard error and perhaps tests, perhaps  Bayes factors\n\n# Todo (Medium-high): visualization of donations by top-priority category (poverty, animals, LT, meta/other)\ndon_inc_priority_plot <-  eas_20 %>%\n  grp_sum(income_c_imp_bc5k, donation_2019_c, XXX) %>%\n  plot_grp(country_big) +\n  xlab(\"Mean income in USD (imputed if <5k/missing\") +\n  ylab(\"Mean donations, CIs\")"},{"path":"eas_donations.html","id":"plan-don-by-year","chapter":"3 Donation","heading":"3.9.1 Planned donation by year, comparison tests","text":"report amount people say expect donate current (survey) year . Note high share missing values 2017, substantially-larger sample 2018. noted , suggests comparing planned donations 2018 (EA survey 2018) actual donations 2018 (reported 2019 EA survey) may informative.\n(#tab:plan_don_per_year)Planned donation per year\n, results signed rank test planned versus actual donation, excluding 0 donations.","code":"\n(\nplan_don_per_year <- eas_all %>%\n filter(year>=2017) %>%\n group_by(year) %>%\n summarise(\"Number reported\" = sum(!is.na(donation_plan_usd)), N = n(),\n            \"Number missing\" = sum(is.na(donation_plan_usd)),\n           \"Proportion missing (%)\" = sum(is.na(donation_plan_usd))/n()*100,\n            \"Mean planned donation\" = mean(donation_plan_usd, na.rm=TRUE),\n           \"Median planned donation\" = median(donation_plan_usd, na.rm=TRUE)) %>%\n kable(caption = \"Planned donation per year\") %>%\n kable_styling()\n)\nw_signed_test_planned_actual_no0s## \n##  Wilcoxon signed rank test with continuity correction\n## \n## data:  planned_actual_2019$donation_2019 and planned_actual_2019$planned_donation_2019\n## V = 30124, p-value = 0.000009109\n## alternative hypothesis: true location shift is greater than 0\n## 95 percent confidence interval:\n##  162.205     Inf\n## sample estimates:\n## (pseudo)median \n##            281"},{"path":"eas_donations.html","id":"donations-by-income-earning-to-give-career-status","chapter":"3 Donation","heading":"3.9.2 Donations by income ‘earning-to-give’ career status","text":"","code":"\n(\n  don_income_etg <- eas_all %>%\n  filter(year_n>=2018) %>%\n  ggplot(aes(x = income_c_imp_bc_k, y = donation_2019, color = d_career_etg)) +\n  geom_point(size = 1, alpha = 0.7) + # draw the points\n  geom_smooth(aes(method = 'loess',\n                  fill = d_career_etg)) + # @Oska -- note I am using  local smoothing here.\n  scale_x_log10(name = \"Income in $1K USD (imputed if <5k/missing)\", n.breaks = 5, limits = c(5, 5000)) +\n  scale_y_log10(\n    name = \"Donation amount\",\n    # labels = scales::dollar,\n    labels = scales::label_number_si(prefix = \"$\"),\n    n.breaks = 10\n  ) +\n  scale_color_discrete(name = \"Earning to give\") +\n  scale_fill_discrete(guide = \"none\") +\n  theme(axis.text.x = element_text( angle = 90, vjust = 0.5, hjust = 1 ),\n        legend.position = c(.87,.15),\n        legend.background = element_rect(fill=alpha('blue', 0.01)))\n)"},{"path":"eas_donations.html","id":"usa-don","chapter":"3 Donation","heading":"3.9.3 Donation shares by income (by US-residence, 2019)","text":"request, consider median mean shares income donated, separately tallying US residents others. allows us compare donation rates reported US overall. particular, Meer Priday (2020) reports roughly 1.6-2.1% percent share income donated throughout US income quantiles (except lowest 5%). statistics suggest EAs fill donation questions survey donate greater share income, perhaps least twice much.Recall mean share total (imputed) income donated (2019) 9.44% (imputing income 5k missing).focus US-resident nonstudents across years, mean share 7.94%.also ‘average individual shares donated’; highly sensitive outliers (e.g., people lowest incomes reporting donating many times share), ‘Winsorise’, capping individual’s ‘share income donate’ percent. Following procedure capping 20%, mean share income donated, across years, US-resident non-students EA survey, 5.67%.plot donation shares log scale, US non-US residents separately (across years). , blue dash gives us median USA (vs non-USA), smoothed curve tries best fit mean. left graph ‘Winsorised’ 20%, right one 40%","code":"\nmean_don_sharenonstud_usa_w20 <-  eas_all %>%\n  filter(d_live_usa==1 & d_student==0) %>%\n  rowwise() %>%\n  mutate(don_share_inc_imp_bc5k = min(don_share_inc_imp_bc5k, 0.2)) %>%\n  ungroup() %>%\n  summarize(mean_share_nonstud_usa_w20 = mean(don_share_inc_imp_bc5k, na.rm=TRUE) )\ndon_share_income_by_usa <- function(df, share=0.2) {\n  df %>%\n    filter(!is.na(d_live_usa)) %>%\n  rowwise() %>%\n  mutate(don_share_inc_imp_bc5k = min(don_share_inc_imp_bc5k, share)) %>%\n  ungroup() %>%\n   group_by(d_live_usa) %>%\n  mutate(med_usa = median(don_share_inc_imp_bc5k, na.rm=TRUE)) %>%\n  ungroup()\n}\n\ndon_share_income_by_usa_w40  <- eas_all %>%\n  don_share_income_by_usa(0.4) %>%\n  ggplot(aes(x = income_c_imp_bc_k, y = don_share_inc_imp_bc5k)) +\n  ggpointdensity::geom_pointdensity(adjust = 0.25) +\n  geom_smooth(method = \"loess\") +\ngeom_hline(aes(yintercept=med_usa), linetype=\"dashed\", size=0.5, color = \"blue\") +\n  geom_hline(yintercept=0.1, linetype=\"dashed\", size=0.5, color = \"red\") +\n  scale_y_continuous(labels = scales::label_percent(accuracy = 1L)) +\n  scale_x_log10(breaks = scales::log_breaks(n=7)) +\n  scale_color_viridis_c(\"Neighbours\") +\n  xlab(\"Income in $1K USD (imputed if missing, bottom-code at 5k)\") +\n  theme(axis.title.x = element_text(size = 10)) +\n   ylim(NA,.21) +\n  ylab(\"Donations/Income (top-code at 40%)\") +\n  facet_wrap(~d_live_usa)  +\n  labs(title=\"By US residence: 2019 'Don. share of income' by income (w/ imputing)\")\n\n\ndon_share_income_by_usa_w20  <- eas_all %>%\n    don_share_income_by_usa(0.2) %>%\n  ggplot(aes(x = income_c_imp_bc_k, y = don_share_inc_imp_bc5k)) +\n  ggpointdensity::geom_pointdensity(adjust = 0.25) +\n  geom_smooth(method = \"loess\") +\ngeom_hline(aes(yintercept=med_usa), linetype=\"dashed\", size=0.5, color = \"blue\") +\n  geom_hline(yintercept=0.1, linetype=\"dashed\", size=0.5, color = \"red\") +\n  scale_y_continuous(labels = scales::label_percent(accuracy = 1L)) +\n  scale_x_log10(breaks = scales::log_breaks(n=7)) +\n  scale_color_viridis_c(\"Neighbours\") +\n  xlab(\"Income in $1K USD (imputed if missing, bottom-code at 5k)\") +\n  theme(axis.title.x = element_text(size = 10)) +\n    ylim(NA,.21) +\n  facet_wrap(~d_live_usa)  +\n  labs(title=\"By US residence: 2019 'Don. share of income' by income (w/ imputing)\")\n  ylab(\"Donations/Income ('Windsorised' (top-coded) at 40%)\")## $y\n## [1] \"Donations/Income ('Windsorised' (top-coded) at 40%)\"\n## \n## attr(,\"class\")\n## [1] \"labels\"\nmean_don_share_income_usa_nonstudent_w20  <- eas_all %>%\n  filter(d_live_usa==1 & d_student==0) %>%\n  rowwise() %>%\n  mutate(don_share_inc_imp_bc5k = min(don_share_inc_imp_bc5k, 0.2)) %>%\n  ungroup() %>%\n  dplyr::summarise(mean_don_share= mean(don_share_inc_imp_bc5k, na.rm=TRUE)\n  )\n\n\ndon_share_income_by_usa_w20\ndon_share_income_by_usa_w40"},{"path":"eas_donations.html","id":"nonresponse","chapter":"3 Donation","heading":"3.9.4 Models: nonresponse coefficients","text":"report ‘response’ coefficients models presented (recall ‘controls’ included specification). exponentiated, presentations . report suspect less direct interest.Baseline\nRobust controls\nBaseline\nRobust controls\nBaseline\nRobust controls\nBaseline\nRobust controls\nBaseline\nRobust controls\nBaseline\nRobust controls\nBaseline\nRobust controls\nBaseline\nRobust controls\nBaseline\nRobust controls\nBaseline\nRobust controls\nBaseline\nRobust controls\nBaseline\nRobust controls\nBaseline\nRobust controls\nBaseline\nRobust controls\nBaseline\nRobust controls\nBaseline\nRobust controls\nBaseline\nRobust controls\nBaseline\nRobust controls\n","code":"\n# make nice table (and/or forest plot?) of nonreseponses\n\n(\n  nr_coefs_table <-  bind_rows(nr_coefs_qp, nr_coefs_fl,nr_coefs_logit) %>%\n    select(outcome, term, model_name, estimate, std.error, p.value, conf.low, conf.high) %>%\n  filter(!str_detect(model_name, \"GWWC\"))  %>%\n  filter(str_detect(term, \"response|na|NA\"))  %>%\n     mutate(\n    outcome = str_replace_all(outcome,  key_eas_all_labels)\n    ) %>%\n    arrange(term) %>%\n  .kable(digits=3) %>%\n    .kable_styling()\n)"}]
