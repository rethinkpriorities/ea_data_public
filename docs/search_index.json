[["outline_disc.html", "EA survey analyses (partial) 1 Notes on this ‘bookdown’ relating to the EA Survey", " EA survey analyses (partial) Dr. David Reinstein, many others 2021-10-30 1 Notes on this ‘bookdown’ relating to the EA Survey This material is meant to supplement EA Survey series posts on the EA forum, and may be linked in those posts. It has been/is being put together by David Reinstein of Rethink Priorities, with the collaboration and input from others at RP. "],["sensitivity.html", "Methodology: Representativeness; weighting and sensitivity testing 1.1 The challenge for the EA Survey (EAS) 1.2 Sensitivity-checks 1.3 Modeling and bounding the biases 1.4 Modeling and bounding the biases 1.5 Other possible approaches (for future consideration) 1.6 References (work considered above and linked)", " Methodology: Representativeness; weighting and sensitivity testing This chapter integrates with the Demographics: considering representativeness chapter The present could be released as a ‘frozen’ EA Forum post if necessary, but it will continue to be updated in the hosted Bookdown.) Getting surveys/polls right is difficult, as recent US electoral outcomes and polling exercises suggest. It hard to produce statistics that we can be confident are representative of a population-of-interest, particularly when: there are high non-response/non-participation rates, and these rates likely vary by groups and subgroups, we are considering a hidden/rare and fluctuating population, with ‘coverage’ limitations* * We may not have have complete ‘coverage’ of relevant groups, e.g., some important parts of the EA population may not be reading the outlets that advertise the survey. there are few or no benchmarks to target and train on (such as actual voting records); nor ‘complete enumerations’ of the population of interest. 1.1 The challenge for the EA Survey (EAS) Considering representativeness of a survey with potentially substantial under-coverage, low participation rates, and a rare population In measuring the demographics, psychometrics, economic status, attitudes, behaviors, preferences, etc., of “the global population of those who identify with Effective Altruism and/or are influenced by EA ideas” we face the above trifecta. Selection issues are endemic to surveys. If the ‘propensity to complete a survey’ is related to any individual characteristic or response (and we don’t know the exact nature of this relationship), than the measured outcomes will be biased measures of the population outcomes. It is difficult or impossible to correct for such biases without a benchmark (such as an election result, a legal national census or a survey that offers an incentive so strong that it guarantees a near-100% response rate). We may not be able to ensure that we have ‘reasonable confidence that we have a reasonably representative sample.’ Without a benchmark, how would we know? If certain groups are not being reached at all (e.g., those not on the internet), there is very little we can do. However, suppose the survey merely under-represents groups with certain (observed) characteristics; e.g., suppose ‘mods’ are less likely to notice or respond to the survey as ‘rockers.’ To recover unbiased estimates, we would simply need to weight each group by the inverse probability of sampling, i.e., weight each rocker as half as important as a mod in constructing summary statistics. But for the EAS (and many other situations), we simply don’t know the extent to which each group is under-responding. The best we may be able to do is to consider the sensitivity of our results to the extent of under/oversampling along observable lines. (For 2020, this is the approach we take in considering demographics and key outcomes.) 1.1.1 Considering academic/formal literature I discuss this issue in a very general methodological sense here (a work-in-progress), in my broad set of methodological notes, and offer some (rough) discussion of relevant academic work. I present some key points and reference below. I did a fairly shallow dive into the methodological literature to put our problem in the context of survey sampling methodology, and to consider approaches to similar problems. ‘Probability sampling’ has been the standard approach in survey sampling since random-digit dialing was possible.* *This paragraph draws from the Wikipedia entry on ‘survey sampling’, as well as cited and connected articles. Probability sampling identifies a population of interest and a sample frame meant to capture this population. Rather than appealing to this entire population/frame, probability sampling randomly (or using stratification/clustering) samples a ‘probability share’ (e.g., 1/1000) from this frame. As only a smaller number of people are selected, you can spend more time and money/incentives, trying to make sure they respond, and track and adjust for rates of responses. Furthermore, probability sampling also allows ‘stratification,’ and oversampling of harder-to-reach groups. One can then potentially divide up (‘stratify’) that frame by observable groups, and randomly draw (sample) within each strata with a certain probability. If we have an informative estimate of the TRUE shares in each strata we can sample/re-weight so that the heterogeneous parameter of interest can be said to represent the average value for the true population of interest. In contrast, the EA Survey is a ‘non-probability sample’ Baker et al. (2013a). We have collected survey responses from self-selected ‘convenience’ samples (‘internet surveys’) across several years. Our current approach may be described as a combination of ‘convenience sampling’ (‘river sampling’ and ‘opt-in’) and ‘snowball sampling.’* I have heard claims that ‘internet surveys,’ if done right, with proper adjustments, can be as or more reliable than traditional polling. However, these adjustments depend on external measures and ‘gold standards,’ such as actual electoral outcomes, and large scale repeated census enumerations. In our context there seems to be little potential to reweight or ‘post-stratify’ to recover results that represent the EA population as a whole. Consider the Wikipedia entry on ‘convenience sampling’: Another example would be a gaming company that wants to know how one of their games is doing in the market one day after its release. Its analyst may choose to create an online survey on Facebook to rate that game. Bias The results of the convenience sampling cannot be generalized to the target population because of the potential bias of the sampling technique due to under-representation of subgroups in the sample in comparison to the population of interest. The bias of the sample cannot be measured. [emphasis added] Therefore, inferences based on the convenience sampling should be made only about the sample itself. (Wikipedia, on ‘Convenience sampling,’ cites Borenstein et al, 2017) This entry is deeply pessimistic… for our case. We might consider alternate or additional sampling approaches in future EA Surveys. Selected sampling will not, by itself, do anything to lessen the problem of differential non-participation. However, it is conceivable that we might take improve our representativeness through some combination of … Surveying the general (non-EA) population as part of larger representative surveys to get a sense of the overall composition of EAs (e.g., the gender ratio). However, differential non-response, to these larger surveys would again throw this in doubt. Standard corrections may not be easy: and relative non-response among EAs (e.g., male versus female EAs) may differ from the relative non-response to such surveys in other populations. Tracking, and attempting to adjust for particular rates of non-participation among groups with known compostions, and extending this, by inference, to groups with unknown composition.^* E.g., suppose we knew the true gender composition of EA Global participants was 80/20 male/female, and we see a 90/10 split from EAG participants in the EAS. We might then assign a double weight to female EAG participants in the EAS, and perhaps also assign a double weight to females in other groups where we expect a similar pattern. Additionally, taking probability samples from within known groups we expect to be ‘broadly representative of EA’ (or at least of particular interest) and offering much strong incentives to these individuals. If this lead to very-high participation rates among these probability samples, this would bring us closer to a gold-standard measure, at least for this group of interest. In our posts for the 2020 survey, we aim to focus (as we have, to some extent in the past) on ‘sensitivity testing.’ We might also consider “respondent-driven sampling” in combination with a careful measurement of the network structure of the EA population, and the sharing of the EAS in this network. As noted, the EAS considers a hidden/rare and fluctuating population, with ‘coverage’ limitations. Salganik and Heckathorn (2004a) suggest using “respondent-driven sampling” (or ‘snowball sampling’ or ‘chain referral’) in such contexts, and making adjustments to recover representativeness (which will work only under particular condidtions). The process involves a small number of seeds who are the first people to participate in the study. These seeds then recruit others to participate in the study. This process of existing sample members recruiting future sample members continues until the desired sample size is reached. They note that This research is fairly well summarized by Berg (1988) when he writes, “as a rule, a snowball sample will be strongly biased toward inclusion of those who have many interrelationships with or are coupled to, a large number of individuals.” In the absence of knowledge of individual inclusion probabilities in different waves of the snowball sample, unbiased estimation is not possible. This motivates the authors’ approach, involving measuring the likelihood that an individual is reached as a function of their network, and then downweighting those individuals that are more likely to be sampled. They claim that through the process they propose, “it is possible to make unbiased estimates about hidden populations from these types of samples … asymptotically unbiased no matter how the seeds are selected.” While this approach is compelling, and may hold some potential for future EAS work, this is not feasible with the data we have now. Furthermore, it is not clear whether it would be an improvement. Relying on chain referral may increase the extent to which the EAS participants are skewed towards certain groups. Even if we take on the adjustments advocated in Salganik and Heckathorn (2004a), this may add more ‘bias’ in net. Given the data we have, we thus focus on ‘sensitivity-testing,’ as discussed below.* * We also sketch and discuss some alternative analytical approaches, perhaps for future years, below). 1.2 Sensitivity-checks In our posts for the 2020 EA survey, we will focus (as we have, to some extent in the past) on ‘sensitivity testing.’ For key outcomes of interest, we will consider how our reported estimates vary … by ‘referrer’ (the link that brought the respondent to the EAS), varying the weights assigned to referrers with different characteristics (‘large pool’ vs ‘small pool,’ level of EA-alignment, etc.) by level of self-reported engagement, (In our future ‘Engagement’ posts, we will also consider this by ‘level of self-reported engagement’).* *Those less-engaged are presumably less interested in filling out the survey, and thus ‘under-represented.’ While we might imagine that the views of less-engaged EA’s are less relevant to consider, this may not always be the case, and might not track 1-1 with their lower response rates. and by time-to-respond and ‘agreement to respond to future surveys.’ Why these groupings? Some referrers may be promoting the EAS more than others, and EA’s who identify with certain referrers may visit them more often than EA’s in other mileu. Those less-engaged are presumably less interested in filling out the survey, and thus ‘under-represented.’ While we might imagine that the views of less-engaged EA’s are less relevant to consider, this may not always be the case, and might not track 1-1 with their lower response rates. Reasonably, ‘being less eager to do something’ may leads to procrastination, or to requiring more reminders before you do it. If so, those who took the longest to respond to the survey (at least relative to the first time they first learned about the survey) may better reflect, within each group, those ‘less likely to take the survey’ (or respond to followup surveys). Arguably, this group is under-represented. In future…* *In future we also aim to consider this by demographics and ‘clusters/vectors of demographics’ we particularly anticipate having differential response rates, in light of past survey research. Some demographics (particular considering career and family status) may face a greater time-cost, making them less likely to complete the survey, and leading to under-representation. 1.3 Modeling and bounding the biases In the sensitivity checks below we report values of key demographics and other important outcomes for each of the groupings mentioned above. Taking the extreme values (minima and maxima) of the outcomes across these groupings could be seen to embody fairly extreme and ad-hoc assumptions. For example we report a series of key outcomes for each referrer (and for some groupings of these). We also did this for groupings of level of self-reported engagement). mean_don &lt;- mean(eas_20$donation_2019_c, na.rm=TRUE) n_shared_link &lt;- sum(eas_20$referrer==&quot;Shared link&quot;) n_optin &lt;- sum(eas_20$referrer==&quot;Email; opt-in from prev. EAS&quot;) male_rate_shared_link &lt;- mean(eas_20$d_male[eas_20$referrer==&quot;Shared link&quot;], na.rm=TRUE) sd_male_rate_shared_link &lt;- sqrt(male_rate_shared_link*(1-male_rate_shared_link)) male_rate_optin &lt;- mean(eas_20$d_male[eas_20$referrer==&quot;Email; opt-in from prev. EAS&quot;], na.rm=TRUE) sd_male_rate_optin &lt;- sqrt(male_rate_optin*(1-male_rate_optin)) 1.4 Modeling and bounding the biases In the sensitivity checks below we report values of key demographics and other important outcomes for each of the groupings mentioned above. Taking the extreme values (minima and maxima) of the outcomes across these groupings could be seen to embody fairly extreme and ad-hoc assumptions.* * Consider the largest and smallest value of each measure, across all referrers, of, e.g., ‘share identifying as Male.’ This leads to a low of 59.4117647058824% male (from the ‘shared link’) and a high of 82.5641025641026% male (the opt-in from last year’s survey). Constructing 80% standard statistical confidence intervals to each of these measures we have a lower-CI for ‘shared link’ of 55.0482069474871% and an upper-CI for ‘opt-in link’ of 85.8498321116085%. These bounds are clearly overly wide, i.e., overly conservative, at least in considering the impact of over/under-sampling from each referrer. Clearly, neither the ‘opt-in link’ (the most male group) nor the ‘shared link’ (the most female group) groups are so under-represented that they should constitute the virtual entirety of the EA population. We know that, e.g., 465 completed the survey from the 80K hours link, and 235 reported a level of engagement of 3 or more. This is not a drop in the bucket: estimates of the total number of “active EA’s” range from about 4700 to about 13000, or perhaps a few hundred thousand if we take the widest view (cf. ‘over 150,000 subscribers’ to the 80K hours newsletter).* * Also note, from the same linked post, some benchmarks: 19% of GWWC members are present in 2018 survey ,,, but we might disagree about whether all GWWC members are EEA in terms of ‘being influenced by EA thought’ Informal polls of relatively heavily-engaged audiences record 30-50% response to the EAS (39% in CEA/80K/FHI Oxford offices, 40% for EA forum, 43% of Local group members, and 31-50% for specific local groups In future we might also use total known numbers in particular groups as upper-benchmarks We are working to address these methodological issues more carefully, and work towards a theoretically grounded approach, both in considering the data we have, and our future survey design and implementation. Below, we present some ideas in this direction. 1.5 Other possible approaches (for future consideration) We are working to address these methodological issues more carefully, and work towards a theoretically grounded approach, both in considering the data we have, and our future survey design and implementation. Below, we present some ideas in this direction. Re-weighting approaches? We might consider ‘re-weighting (or ’post-stratification’) to match key demographics of some known group. Suppose we knew the gender and country composition of the members of the Effective Altruism Facebook Group. Under standard assumptions, reweighting the EAS results to match this might reduce the bias of our estimates – at least as a measure of the ‘average responses for those on EA Facebook.’ However: The ‘EA Facebook group’ may not be representative of the EA movement as a whole, and The re-weighting need not reduce the bias from differential response rates, even considering the EA FB group as the sampling frame of interest. For a particular outcome, considering particular subgroup weightings… this would only be guaranteed if the ‘nonresponders within each subgroup’ had the same distribution of this outcome as the overall population within each subgroup. Less extreme (but ad-hoc) sensitivity checking We might also consider sensitivity tests that are ‘less extreme’ than the bounds that might be implied by the tests below. E.g., we could consider…. Some ideas As a first-pass at these sensitivity checks, we might report bounds under ‘somewhat less extreme’ possibilities, under ad-hoc grouping assumptions Each individual referrer’s response rate (among true EA’s) is Normally distributed, with mean 40% and sd 20%. The ‘response rate draws’ are not following groupings of referrers may each have Or drop or downweight by 50% half of the list of referrers with all combinations, report the most extreme one? Or drop any single referrer one by one and find most extreme results Try to classify these groups (or a ‘vector’ of groups and downweight along these lines) By ‘time to respond’ (how to present/test this?) or some ‘likelihood of response?’ For those willing/unwilling to respond to share email for future surveys Another formal test? Consider sensitivity to downweighting by ‘Referrer’ (the link that brought the respondent to the EAS), varying the weights assigned to referrers with different characteristics (‘large pool’ vs ‘small pool,’ level of EA-alignment, etc.) Each referrer/grouping with over 100 responses Ad-hoc groupings: 80K, EA Forum, Email opt-in+shared link+Newsletter, Local Groups, Other 80K, EA Organisations/link (EA Forum, EA Newsletter, opt-in from prev. EAS), Social media/rationalist/blogs (Reddit, LW, SSC, FB, memes), Personal (Groups, Shared link) by level of self-reported engagement 0-2, 3, 4, 5 0-2, 3, 4-5 and by time-to-respond and ‘agreement to respond to future surveys.’ Time to respond relative to survey start date: 4 quantiles, RR of 80%, 60%, 40%, and 20% assumed Time to respond relative to others from same referrer … quantiles and RR as above Agreed to respond to future surveys (no/EAS only/EAS and followups) (20% vs 50% vs 80% RR assumed) Bayesian modeling of outcomes in light of (distributions) of response rates Bayesian modeling of outcomes in light of (distributions) of response rates Perhaps the best approach would be a model that - makes our beliefs over the possible response rates for different groups explicit, - adjusts these in light of new information, - summarizes our uncertainty over possible outcome values in a ‘posterior distribution.’ A very rough sketch of such a ‘Bayesian model’ is folded below. Model components and assumptions: Probability distribution over the total number of (E)EAs (does this matter?) Suppose (all 3+ engaged EAs) for each referrer are in fact EA-affiliated. Critical component: A probability distribution over the ‘true response rate’ for each (referrer) group Benchmarks for this (as reported in earlier post) 19% of GWWC members present in 2018 survey (but are all GWWC members EEA?) 30-50% response rates in informal polls of relatively heavily-engaged audiences* * From an informal poll, 39% in the CEA/80K/FHI Oxford office. Comparing response numbers in the EAS with the EA Groups survey implies 40% response rates for EA forum members, 43% Local group members, and 31-50% for a set of specific local groups, Total ‘members’ of specific referrers. At first pass, we might converge on a conservative guesstimate of: a normal distribution over EEA response rates for each referrer a 40 percent mean response rate (by referrer, and thus overall) A 90% CI for the response rate (of EEAs) for each referrer of 15 - 80 percent (this is totally ad-hoc) However, the hardest component to consider is the correlation between the response rates of sets of referrers . We might expect, e.g., the response rates of SSC and LW to be correlated. We can only partially deal with this by choosing larger groups and defining priors .grouping sets of of referrers. Thus we may need to define a prior over (e.g., if we assume multivatiate normality) the variance/covariance matrix. We do have some benchmark datasets that might help us with this … the SSC survey, EAGx demography … calculate weights to minimize error between our surveys and others … 1.6 References (work considered above and linked) (To be integrated above as well) Salganik and Heckathorn (2004b) Baker et al. (2013b) Särndal, Swensson, and Wretman (2003) Schwarcz et al. (2007) Wright and Peugh (2012) References "],["demog.html", "2 Demographics: considering representativeness 2.1 Sensitivity checks", " 2 Demographics: considering representativeness #key binary/numeric demographics for summary comparisons key_demog &lt;- c(&quot;age_approx&quot;, &quot;d_male&quot;, &quot;d_student&quot;, &quot;race_white&quot;, &quot;d_live_usa&quot;, &quot;income_k_c&quot;, &quot;career_academia&quot;) key_demog_plus &lt;- c(key_demog, &quot;engagement_num&quot;) key_demog_cat &lt;- key_demog_plus key_outcomes &lt;- c(key_demog_plus, &quot;mn_priority_lt_rating&quot;, &quot;lt_top_priority&quot;, &quot;animal_top_priority&quot;, &quot;don_share_inc_19_imp&quot;) #DR: usually I don&#39;t do this but perhaps it makes the code more readable? attach(eas_20) See previous section: Methods: Weighting, representativeness, and sensitivity testing Recapping that discussion: In measuring the demographics of “the global population of those who identify with Effective Altruism” see ‘size of EA’ post here we face: high non-response/non-participation rates, which likely vary by groups and sub-groups, a hidden/rare and fluctuating population, no guarantee that we have complete ‘coverage’ of relevant groups, and we have few or no benchmarks (e.g., no complete enumeration of the population of interest). This makes it difficult to be highly confident in the representativeness of the demographics reported in this post (or even in the year-to-year changes, as response rates). We present this sensitivity testing below. 2.1 Sensitivity checks Following the previous discussion on the unique issues faced by the EA survey, we present a series of sensitivity checks. (Why these groupings? See discussion above.) Of course, we cannot report all measures for all sub-groups and weightings in a single post. We offer only a subset of this, and we aim to offer more in the future (perhaps in a dynamic/interactive presentation.) As noted above, these bounds are clearly overly wide, i.e., overly conservative, at least in considering the impact of over/under-sampling from each referrer and from each ‘willingness to respond’ group. Demographics by ‘referrer’ Respondents come to this survey from a range of ‘referrers’; we can track these links. The table and bar chart below breaks this down: cap &lt;- &quot;Referrer&quot; ( refer_tab &lt;- eas_20 %&gt;% tabyl(referrer_cat) %&gt;% arrange(-n) %&gt;% kable(caption=cap) %&gt;% kable_styling(latex_options = &quot;scale_down&quot;) ) Table 2.1: Referrer referrer_cat n percent 80K hours 465 0.2261673 EA Forum 407 0.1979572 Groups (local) 313 0.1522374 Email; opt-in from prev. EAS 219 0.1065175 EA Newsletter 210 0.1021401 Shared link 208 0.1011673 Less Wrong or SlateStarCodex-Reddit 90 0.0437743 Social media (FB/memes) 60 0.0291829 Giving What We Can 37 0.0179961 Reddit 35 0.0170233 Other 12 0.0058366 library(viridis) ( referrer_bar &lt;- eas_20 %&gt;% filter(referrer_cat!=&quot;Other&quot;) %&gt;% mutate( referrer_sub = case_when( str_detect(referrer, &quot;Groups&quot;) ~ as.factor(referrer), str_detect(referrer, &quot;dankeamemes|EA FB|CEA FB|Hangouts&quot;) ~ as.factor(referrer), str_detect(referrer, &quot;Less Wrong|Slate&quot;) ~ as.factor(referrer), TRUE ~ as.factor(&quot;&quot;)), ) %&gt;% ggplot() + aes(x = forcats::fct_infreq(referrer_cat), fill = referrer_sub) + geom_bar(stat=&quot;count&quot;) + scale_fill_hue() + coord_flip() + ggthemes::theme_fivethirtyeight() + scale_x_discrete(labels=c(&quot;Less Wrong or SlateStarCodex-Reddit&quot;=&quot;LessWrong/SSC-Reddit&quot;, &quot;Email; opt-in from prev. EAS&quot;=&quot;Email; opt-in prev. SSC&quot;))+ guides(fill=guide_legend(title=NULL)) + theme(legend.position = &quot;bottom&quot;) ) Plotly interactive version: ggplotly(referrer_bar) Note on statistics (unfold): I include standard deviation for all nonbinary variables the SD for binary variables doesn’t provide any additional information so I never put this in. (The SD for any binary variable is simply a function of the shares in each category), I do not show the standard error or confidence intervals in these tables because I do not want to suggest “testing for differences in outcome” by these splits. The point here isn’t to show ’look there are no significant differences”; of course there are. The point is “let’s consider what the range might be for the true mean or median of these outcomes,” if we allow that we may be over or under-representing groups along these observable lines. As part of this exercise, I could have also reported confidence intervals for the largest and smallest value of each measure across all subgroups, but this would not add much value in my opinion. We can be pretty sure these extreme values are already overly wide. A more involved take on this would do better to quantify our uncertainty: uncertainty due to standard ‘sampling error’ (any sample is only a draw from the population and may get averages wrong ‘by change’), as well as uncertainty over differential rates of non-response for groups with different ‘outcome variables.’ I sketch what that might look like very roughly here. Below, we report ‘engagement by referrer’ (with non-responses dropped, and 4 ‘other referrers’ dropped), i.e., ‘how engaged are those coming from each referrer.’ This depiction also shows the relative magnitudes of each grouping and subgrouping, allowing us to consider ‘where the action is.’ ( engage_by_ref &lt;- eas_20 %&gt;% filter(referrer_cat!=&quot;Other&quot;) %&gt;% filter(!is.na(engagement)) %&gt;% ggplot() + aes(x = forcats::fct_infreq(referrer_cat), fill = engagement) + geom_bar() + coord_flip() + scale_fill_brewer() + theme_minimal() + guides(fill=guide_legend(title=&quot;Self reported EA engagement level&quot;)) + labs(title=&quot;Engagement by Referrer (2020)&quot;, x = &quot;Referrer&quot;) ) #TODO: add an &#39;overall&#39; bar to this; put NA&#39;s as &#39;zeroes&#39;, i.e., the bar to the left. #TODO: try to preserve colors for each org (or for engagement?) across graphs -- see http://www.cookbook-r.com/Graphs/Colors_(ggplot2)/ &#39;use and reuse pallettes&#39; Next we consider referrer by engagement; i.e., the ‘referrer composition’ and size of each engagment group. (Again, a few ‘other referrers’ are dropped.) ( ref_by_engage &lt;- eas_20 %&gt;% filter(referrer_cat!=&quot;Other&quot;) %&gt;% ggplot() + aes(engagement, fill = referrer_cat) + geom_bar() + coord_flip() + scale_fill_hue() + theme_minimal() + guides(fill=guide_legend(title=&quot;Referrer (groupings)&quot;)) + labs(title=&quot;Referrer by Engagment (2020)&quot;, x = &quot;Self-reported level of engagement&quot;) ) The table below considers how the key ‘demographics’ (as well as engagement) of EAS participants varied by referrer. Characteristics by referrer - table (Note: 12 ‘other referrers’ are dropped.) label_list &lt;- list(age_approx ~ &quot;Age&quot;, d_male ~ &quot;Male&quot;, d_student ~ &quot;Student&quot;, race_white ~ &quot;White (ethnicity)&quot;, d_live_usa ~ &quot;USA-based&quot;, income_k_c ~ &quot;Income in $1000&quot;, career_academia ~ &quot;Academic current career&quot;, mn_priority_lt_rating ~ &quot;Mean prioritization LT (1-5)&quot;, lt_top_priority ~ &quot;LT cause(s) highest&quot;, animal_top_priority ~ &quot;Animal welfare highest&quot;, don_share_inc_19_imp ~ &quot;Donation as share of income, with imputation&quot;, engagement_num ~ &quot;Engagement (1-5 scale)&quot; ) ( demo_tab_ref &lt;- eas_20 %&gt;% filter(referrer_cat!=&quot;Other&quot;) %&gt;% mutate(referrer_cat = as.factor(referrer_cat), referrer_cat= fct_drop(referrer_cat), ) %&gt;% select(all_of(key_outcomes), referrer_cat) %&gt;% tbl_summary( by = referrer_cat, type = c(all_continuous(), engagement_num, mn_priority_lt_rating, don_share_inc_19_imp) ~ &quot;continuous2&quot;, statistic = list(all_continuous() ~ c(&quot;{median}&quot;, &quot;{p10}-{p90}&quot;, &quot;{mean} ({sd})&quot;), all_dichotomous() ~ &quot;{p}%&quot;), label = label_list, missing = c(&quot;no&quot;), digits = list(engagement_num ~ 1, mn_priority_lt_rating ~1) ) %&gt;% modify_footnote( update = all_stat_cols() ~ &quot;* &#39;Age&#39; imputed as current year minus birth-year; a few &#39;other referrer&#39; responses dropped; &#39;Mean prioritization LT&#39; averages priority assigned to X-risk, AI risks, Biosecurity, Nuclear, and broad-LT-ism&#39;; &#39;LT causes highest&#39; indicates that one of these causes was among those the individual ranked most-highly. (Same for &#39;Animal welfare highest&#39;)&quot; ) %&gt;% bold_labels() %&gt;% add_n() %&gt;% add_overall() ) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #jtrtkvwfbp .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #jtrtkvwfbp .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #jtrtkvwfbp .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #jtrtkvwfbp .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #jtrtkvwfbp .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #jtrtkvwfbp .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #jtrtkvwfbp .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #jtrtkvwfbp .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #jtrtkvwfbp .gt_column_spanner_outer:first-child { padding-left: 0; } #jtrtkvwfbp .gt_column_spanner_outer:last-child { padding-right: 0; } #jtrtkvwfbp .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #jtrtkvwfbp .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #jtrtkvwfbp .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #jtrtkvwfbp .gt_from_md > :first-child { margin-top: 0; } #jtrtkvwfbp .gt_from_md > :last-child { margin-bottom: 0; } #jtrtkvwfbp .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #jtrtkvwfbp .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #jtrtkvwfbp .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #jtrtkvwfbp .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #jtrtkvwfbp .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #jtrtkvwfbp .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #jtrtkvwfbp .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #jtrtkvwfbp .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #jtrtkvwfbp .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #jtrtkvwfbp .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #jtrtkvwfbp .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #jtrtkvwfbp .gt_sourcenote { font-size: 90%; padding: 4px; } #jtrtkvwfbp .gt_left { text-align: left; } #jtrtkvwfbp .gt_center { text-align: center; } #jtrtkvwfbp .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #jtrtkvwfbp .gt_font_normal { font-weight: normal; } #jtrtkvwfbp .gt_font_bold { font-weight: bold; } #jtrtkvwfbp .gt_font_italic { font-style: italic; } #jtrtkvwfbp .gt_super { font-size: 65%; } #jtrtkvwfbp .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } Characteristic N Overall, N = 2,0441 80K hours, N = 4652 EA Forum, N = 4072 EA Newsletter, N = 2102 Email; opt-in from prev. EAS, N = 2192 Giving What We Can, N = 372 Groups (local), N = 3132 Less Wrong or SlateStarCodex-Reddit, N = 902 Reddit, N = 352 Shared link, N = 2082 Social media (FB/memes), N = 602 Age 1,598 Median 27 29 26 30 29 31 26 28 30 28 28 10%-90% 21-40 21-48 20-33 22-53 22-40 23-37 20-38 22-41 24-41 21-38 21-35 Mean (SD) 30 (10) 32 (11) 27 (6) 34 (14) 31 (9) 30 (5) 28 (8) 31 (10) 31 (10) 29 (9) 27 (7) Male 1,568 71% 70% 73% 70% 83% 73% 63% 84% 73% 59% 72% Student 1,628 37% 33% 44% 27% 29% 17% 51% 31% 23% 37% 35% White (ethnicity) 1,595 83% 84% 82% 86% 88% 79% 76% 85% 77% 85% 81% USA-based 1,600 39% 45% 41% 45% 36% 43% 22% 65% 62% 32% 40% Income in $1000 1,403 Median 33 33 30 44 41 55 14 49 80 35 22 10%-90% 1-130 0-109 1-114 5-161 3-144 8-152 0-80 7-191 5-214 4-94 3-126 Mean (SD) 61 (138) 49 (76) 65 (202) 72 (98) 63 (81) 72 (75) 47 (135) 105 (229) 105 (149) 44 (42) 82 (235) Academic current career 1,616 18% 22% 17% 16% 18% 17% 19% 15% 14% 14% 29% Engagement (1-5 scale) 1,823 Median 3.0 3.0 4.0 3.0 4.0 3.0 4.0 2.0 3.0 4.0 4.0 10%-90% 2.0-5.0 2.0-4.0 3.0-5.0 2.0-4.0 2.0-5.0 2.0-4.4 2.0-5.0 2.0-4.0 2.0-4.0 2.0-5.0 2.0-5.0 Mean (SD) 3.4 (1.1) 2.9 (1.1) 4.0 (1.0) 3.1 (0.9) 3.6 (1.0) 3.3 (1.0) 3.6 (0.9) 2.6 (0.9) 2.8 (1.1) 3.5 (1.0) 3.6 (1.0) Mean prioritization LT (1-5) 1,578 Median 3.4 3.2 3.4 3.2 3.4 2.8 3.4 3.0 3.0 3.4 3.2 10%-90% 2.3-4.0 2.2-4.2 2.6-4.2 2.2-4.0 2.2-4.0 1.8-3.8 2.5-4.2 2.0-3.9 2.0-3.8 2.4-4.2 2.5-4.0 Mean (SD) 3.3 (0.7) 3.3 (0.7) 3.4 (0.6) 3.2 (0.7) 3.2 (0.7) 2.7 (0.8) 3.4 (0.7) 2.9 (0.8) 2.9 (0.7) 3.3 (0.7) 3.3 (0.6) LT cause(s) highest 1,608 51% 50% 57% 50% 49% 25% 51% 46% 45% 48% 56% Animal welfare highest 1,542 19% 15% 20% 19% 20% 19% 20% 7.8% 20% 17% 31% Donation as share of income, with imputation 1,416 Median 0.02 0.02 0.02 0.02 0.05 0.07 0.02 0.01 0.02 0.02 0.03 10%-90% 0.00-0.14 0.00-0.11 0.00-0.15 0.00-0.12 0.00-0.21 0.00-0.18 0.00-0.20 0.00-0.11 0.00-0.12 0.00-0.12 0.00-0.10 Mean (SD) 0.12 (1.79) 0.09 (0.48) 0.07 (0.14) 0.07 (0.14) 0.09 (0.16) 0.09 (0.12) 0.08 (0.19) 0.03 (0.05) 0.10 (0.22) 0.48 (5.31) 0.05 (0.08) 1 c(&quot;Median&quot;, &quot;10%-90%&quot;, &quot;Mean (SD)&quot;); % 2 'Age' imputed as current year minus birth-year; a few 'other referrer' responses dropped; 'Mean prioritization LT' averages priority assigned to X-risk, AI risks, Biosecurity, Nuclear, and broad-LT-ism'; 'LT causes highest' indicates that one of these causes was among those the individual ranked most-highly. (Same for 'Animal welfare highest') #work on putting in standard errors -- not succesful tbl_se_work &lt;- demo_tab_ref$meta_data %&gt;% select(summary_type, var_label, df_stats) %&gt;% tidyr::unnest(df_stats) %&gt;% mutate( se = case_when( summary_type %in% c(&quot;categorical&quot;, &quot;dichotomous&quot;) ~ (sqrt(p * (1 - p) / N_nonmiss)), summary_type %in% c(&quot;continuous2&quot;) ~ (sd / sqrt(N_nonmiss)) ), label = coalesce(variable_levels, var_label), row_type = ifelse(summary_type == &quot;dichotomous&quot;, &quot;label&quot;, &quot;level&quot;) ) %&gt;% select(variable, row_type, label, se) As noted previously I do not show the standard error or confidence intervals in these tables because I do not want to suggest “testing for differences in outcome” by these splits; we are focusing on sensitivity testing. Nonetheless, I present estimated standard errors below, to put the differences in context. transpose_ok &lt;- function(df) { df %&gt;% t %&gt;% row_to_names(row_number = 1) %&gt;% kable(format=&#39;html&#39;, digits=2, row.names=TRUE, align=&#39;cccccc&#39;, escape = FALSE, caption = &quot;Standard errors of means; for smallest and largest groups&quot;) } hi_low_groups &lt;- function(df) { df %&gt;% mutate(count = n()) %&gt;% ungroup() %&gt;% filter(count==min(count) | count==max(count)) %&gt;% select(-count) } eas_20 %&gt;% select(all_of(key_outcomes), referrer_cat) %&gt;% filter(referrer_cat!=&quot;Other&quot;) %&gt;% group_by(referrer_cat) %&gt;% hi_low_groups %&gt;% group_by(referrer_cat) %&gt;% summarise(across(everything(), list(se = ~sd(.x, na.rm=TRUE)/sqrt(length(.x))))) %&gt;% transpose_ok Table 2.2: Standard errors of means; for smallest and largest groups 80K hours Reddit age_approx_se 0.5279542 1.6443904 d_male_se 0.02129446 0.07705141 d_student_se 0.02189632 0.07250275 race_white_se 0.01690748 0.07250275 d_live_usa_se 0.02310065 0.08411201 income_k_c_se 3.504822 25.105259 career_academia_se 0.01910471 0.06060915 engagement_num_se 0.04875888 0.18215302 mn_priority_lt_rating_se 0.03429825 0.11709040 lt_top_priority_se 0.02322443 0.08614610 animal_top_priority_se 0.01666554 0.06936880 don_share_inc_19_imp_se 0.02216159 0.03788806 Some relevant outcomes are fairly constant across major referrers, such as age, (White) ethnicity, and being in an academic career. About half of those coming from all referrers rank a long-term cause at least as highly as any other non-LT cause (with the notable exception of GWWC). Other outcomes show more substantial variation. E.g., those opting-in from the previous EAS are substantially more male than those who were given a shared link. (Those referred from) the ‘rationalist groups’ (LW, SSC) are also a bit more male than the average, while those referred from ‘local groups’ are somewhat more female. Local groups also contain more students, a much lower share based in the US, and lower-earners, on average. Considering attitudes and behaviors, those referred from rationalist groups are the least engaged on average, while those from EA-Forum are the most-engaged. Similar patterns hold for the response to (absolute, not relative) prioritization of the aggregated long-term cause categories. LW/SSC also appear less likely to prioritize animal welfare, while those coming from Social Media (Dank EA Memes, EA FB, CEA FB, and Hangouts) tend to prioritize this more. Median donations as share of (imputed-where-missing) income is fairly constant around 2% across most referrers at around 2%, although it appears substantially higher for email-opt-ins and GWWC-referrals, and potentially somewhat lower for the rationalist groups. What does this tell us about the sensitivity of our results to under- or over-representation of particular referrers?. Some results are not particularly sensitive – for example,“EA’s tend to be young” across all groups of referrers. Demographics by willingness-to-respond to future surveys and by lateness of response We repeat the previous summary statistics by ‘willingness to respond in future,’ divided into those who did not wish to be contacted again for another EAS in future those willing to be contacted again for another EAS but not for additional relevant surveys those willing to be contacted again for another EAS as well as additional surveys While this breakdown may not be of direct interest, it is relevant to our sensitivity-checking. As discussed, those least willing to respond to future studies may be more representative of under-sampled populations in the current survey. However, in future, we may perhaps avoid using this as a measure for adjusting the importance weights of each response, as it could be prone to manipulation. E.g., those who wished their survey responses to be ‘taken more seriously’ would then have an incentive to respond negatively to these questions. Note that we leave out the 10th and quantiles to save space here; these proved to be fairly similar across groups. ( demo_tab_wtr &lt;- eas_20 %&gt;% mutate(survey_willing = as.factor(survey_willing), survey_willing= fct_rev(survey_willing) ) %&gt;% select(all_of(key_outcomes), survey_willing) %&gt;% tbl_summary( by = survey_willing, type = c(all_continuous(), engagement_num, mn_priority_lt_rating, don_share_inc_19_imp) ~ &quot;continuous2&quot;, statistic = list(all_continuous() ~ c(&quot;{median}&quot;, &quot;{mean} ({sd})&quot;), all_dichotomous() ~ &quot;{p}%&quot;), label = label_list, missing = c(&quot;no&quot;), digits = list(engagement_num ~ 1, mn_priority_lt_rating ~1) ) %&gt;% modify_footnote( update = all_stat_cols() ~ &quot;&#39;Prioritize LT&#39; averages priority assigned to X-risk, AI risks, Biosecurity, Nuclear, and broad-LT-ism&#39;&quot;) %&gt;% bold_labels() %&gt;% add_n() %&gt;% add_overall() ) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #wcgascylwf .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #wcgascylwf .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #wcgascylwf .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #wcgascylwf .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #wcgascylwf .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #wcgascylwf .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #wcgascylwf .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #wcgascylwf .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #wcgascylwf .gt_column_spanner_outer:first-child { padding-left: 0; } #wcgascylwf .gt_column_spanner_outer:last-child { padding-right: 0; } #wcgascylwf .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #wcgascylwf .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #wcgascylwf .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #wcgascylwf .gt_from_md > :first-child { margin-top: 0; } #wcgascylwf .gt_from_md > :last-child { margin-bottom: 0; } #wcgascylwf .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #wcgascylwf .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #wcgascylwf .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #wcgascylwf .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #wcgascylwf .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #wcgascylwf .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #wcgascylwf .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #wcgascylwf .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #wcgascylwf .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #wcgascylwf .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #wcgascylwf .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #wcgascylwf .gt_sourcenote { font-size: 90%; padding: 4px; } #wcgascylwf .gt_left { text-align: left; } #wcgascylwf .gt_center { text-align: center; } #wcgascylwf .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #wcgascylwf .gt_font_normal { font-weight: normal; } #wcgascylwf .gt_font_bold { font-weight: bold; } #wcgascylwf .gt_font_italic { font-style: italic; } #wcgascylwf .gt_super { font-size: 65%; } #wcgascylwf .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } Characteristic N Overall, N = 2,0561 No next EAS, N = 7992 Next EAS only, N = 4522 Next EAS and followup surveys, N = 8052 Age 1,605 Median 27 28 27 28 Mean (SD) 30 (10) 31 (12) 29 (9) 30 (9) Male 1,575 71% 60% 75% 73% Student 1,636 37% 37% 39% 35% White (ethnicity) 1,602 83% 81% 84% 83% USA-based 1,607 39% 40% 36% 39% Income in $1000 1,409 Median 33 36 35 31 Mean (SD) 61 (137) 72 (210) 58 (128) 56 (94) Academic current career 1,624 18% 17% 20% 18% Engagement (1-5 scale) 1,834 Median 3.0 3.0 3.0 4.0 Mean (SD) 3.4 (1.1) 3.0 (1.1) 3.5 (1.0) 3.7 (1.0) Mean prioritization LT (1-5) 1,586 Median 3.4 3.2 3.4 3.4 Mean (SD) 3.3 (0.7) 3.2 (0.7) 3.3 (0.7) 3.3 (0.7) LT cause(s) highest 1,616 51% 46% 51% 53% Animal welfare highest 1,550 19% 16% 18% 20% Donation as share of income, with imputation 1,422 Median 0.02 0.02 0.02 0.03 Mean (SD) 0.12 (1.78) 0.06 (0.13) 0.06 (0.13) 0.18 (2.53) 1 c(&quot;Median&quot;, &quot;Mean (SD)&quot;); % 2 'Prioritize LT' averages priority assigned to X-risk, AI risks, Biosecurity, Nuclear, and broad-LT-ism' In the above table age, student status, (White) ethnicity, academic career, and ‘prioritizing animal welfare most highly’ appear not strongly related to willingness to participate in future surveys. Those least willing to participate are slightly less male, substantially less US-based, slightly-higher earners, (predictably) a bit less-engaged, very slightly less long-termist, and they donate slightly less. Those most willing to take future surveys (EAS and followups) tend to be highly-engaged, and donate somewhat more. Again, presenting standard errors below to put these differences in context: eas_20 %&gt;% mutate(survey_willing = as.factor(survey_willing), survey_willing= fct_rev(survey_willing) ) %&gt;% select(all_of(key_outcomes), survey_willing) %&gt;% group_by(survey_willing) %&gt;% hi_low_groups %&gt;% group_by(survey_willing) %&gt;% summarise(across(everything(), list(se = ~sd(.x, na.rm=TRUE)/sqrt(length(.x))))) %&gt;% transpose_ok Table 2.3: Standard errors of means; for smallest and largest groups Next EAS only Next EAS and followup surveys age_approx_se 0.4148638 0.3291991 d_male_se 0.02038997 0.01572996 d_student_se 0.02294615 0.01685293 race_white_se 0.01737497 0.01311695 d_live_usa_se 0.02262448 0.01722718 income_k_c_se 6.043911 3.324393 career_academia_se 0.01888274 0.01341166 engagement_num_se 0.04776964 0.03473368 mn_priority_lt_rating_se 0.03360644 0.02411332 lt_top_priority_se 0.02354177 0.01760127 animal_top_priority_se 0.01816273 0.01413515 don_share_inc_19_imp_se 0.006227659 0.089325948 By start date (relative to others from same referrer) Below, the results are meant to be grouped into ‘quarters of the population responding within each referrer.’ I.e., is the participant among the earliest 25th percentile, second, third, and latest percentile ‘among those coming from the referrer they came in from.’ * * However, the middle groups are the largest: this is because of ties: large groups come in from a referrer on the same day, probably the day the survey is announced. We did not disaggregate this by times-of-day. Thus, to some extent this could also be picking up the effects of different time zones; e.g., if it is announced late in the (Chicago) evening, EAs in Germany are unlikely to respond until the next day ( demo_tab_timing &lt;- eas_20 %&gt;% select(all_of(key_outcomes), start_date_qtl_by_referrer) %&gt;% tbl_summary( by = start_date_qtl_by_referrer, type = c(all_continuous(), engagement_num, mn_priority_lt_rating, don_share_inc_19_imp) ~ &quot;continuous2&quot;, statistic = list(all_continuous() ~ c(&quot;{median}&quot;, &quot;{mean} ({sd})&quot;), all_dichotomous() ~ &quot;{p}%&quot;), label = label_list, missing = c(&quot;no&quot;), digits = list(engagement_num ~ 1, mn_priority_lt_rating ~1) ) %&gt;% modify_spanning_header(c(&quot;stat_1&quot;, &quot;stat_2&quot;, &quot;stat_3&quot;, &quot;stat_4&quot;) ~ &quot;**Start date vs. others from same referrer**&quot;) %&gt;% bold_labels() %&gt;% add_n() %&gt;% add_overall() ) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #ylsvwtloqg .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #ylsvwtloqg .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #ylsvwtloqg .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #ylsvwtloqg .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #ylsvwtloqg .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #ylsvwtloqg .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #ylsvwtloqg .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #ylsvwtloqg .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #ylsvwtloqg .gt_column_spanner_outer:first-child { padding-left: 0; } #ylsvwtloqg .gt_column_spanner_outer:last-child { padding-right: 0; } #ylsvwtloqg .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #ylsvwtloqg .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #ylsvwtloqg .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #ylsvwtloqg .gt_from_md > :first-child { margin-top: 0; } #ylsvwtloqg .gt_from_md > :last-child { margin-bottom: 0; } #ylsvwtloqg .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #ylsvwtloqg .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #ylsvwtloqg .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #ylsvwtloqg .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #ylsvwtloqg .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #ylsvwtloqg .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #ylsvwtloqg .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #ylsvwtloqg .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #ylsvwtloqg .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #ylsvwtloqg .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #ylsvwtloqg .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #ylsvwtloqg .gt_sourcenote { font-size: 90%; padding: 4px; } #ylsvwtloqg .gt_left { text-align: left; } #ylsvwtloqg .gt_center { text-align: center; } #ylsvwtloqg .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #ylsvwtloqg .gt_font_normal { font-weight: normal; } #ylsvwtloqg .gt_font_bold { font-weight: bold; } #ylsvwtloqg .gt_font_italic { font-style: italic; } #ylsvwtloqg .gt_super { font-size: 65%; } #ylsvwtloqg .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } Characteristic N Overall, N = 2,0561 Start date vs. others from same referrer [0%, 25%), N = 334 [25%, 50%], N = 757 (50%, 75%], N = 577 (75%, 100%], N = 388 Age 1,605 Median 27 27 28 28 28 Mean (SD) 30 (10) 29 (8) 30 (11) 29 (9) 31 (11) Male 1,575 71% 69% 71% 71% 71% Student 1,636 37% 37% 37% 36% 36% White (ethnicity) 1,602 83% 84% 83% 83% 83% USA-based 1,607 39% 39% 40% 38% 37% Income in $1000 1,409 Median 33 30 33 36 31 Mean (SD) 61 (137) 67 (206) 59 (118) 59 (113) 61 (120) Academic current career 1,624 18% 17% 20% 18% 16% Engagement (1-5 scale) 1,834 Median 3.0 4.0 3.0 3.0 3.0 Mean (SD) 3.4 (1.1) 3.7 (1.0) 3.4 (1.1) 3.4 (1.1) 3.4 (1.1) Mean prioritization LT (1-5) 1,586 Median 3.4 3.2 3.4 3.2 3.4 Mean (SD) 3.3 (0.7) 3.2 (0.7) 3.3 (0.7) 3.2 (0.8) 3.3 (0.7) LT cause(s) highest 1,616 51% 50% 51% 51% 51% Animal welfare highest 1,550 19% 22% 20% 18% 15% Donation as share of income, with imputation 1,422 Median 0.02 0.03 0.03 0.02 0.01 Mean (SD) 0.12 (1.78) 0.09 (0.19) 0.07 (0.15) 0.26 (3.42) 0.06 (0.14) 1 c(&quot;Median&quot;, &quot;Mean (SD)&quot;); % Looking across the response quartiles relative to others coming from the same referrers, we don’t see any striking differences in age, gender, student-status, (white) ethnicity, income, LT-prioritization, or donations. Those responding latest are slightly less likely to be US-based (perhaps because of time-difference issues). Those responding earliest tend to be the most engaged (unsurprisingly). There also seems to be some positive relationship between promptness and prioritizing animal welfare. Again, presenting standard errors below to put these differences in context: eas_20 %&gt;% select(all_of(key_outcomes), start_date_qtl_by_referrer) %&gt;% group_by(start_date_qtl_by_referrer) %&gt;% hi_low_groups %&gt;% group_by(start_date_qtl_by_referrer) %&gt;% summarise(across(everything(), list(se = ~sd(.x, na.rm=TRUE)/sqrt(length(.x))))) %&gt;% transpose_ok Table 2.4: Standard errors of means; for smallest and largest groups [0%, 25%) [25%, 50%] age_approx_se 0.4586538 0.3835950 d_male_se 0.02536286 0.01644936 d_student_se 0.02653069 0.01759662 race_white_se 0.02034038 0.01372974 d_live_usa_se 0.02678810 0.01779304 income_k_c_se 11.288396 4.304395 career_academia_se 0.02051612 0.01459380 engagement_num_se 0.05543895 0.03856710 mn_priority_lt_rating_se 0.03727010 0.02503135 lt_top_priority_se 0.02740811 0.01818290 animal_top_priority_se 0.02276067 0.01441929 don_share_inc_19_imp_se 0.010515660 0.005554727 “Engaged mainstream”: By more/less survey-responsive We might want to focus only among the most engaged and those who are highly connected to EA, and consider the sensitivity of these results by proxies of likelihood to complete the survey. Thus we finally consider: those who who have a rating of 4-5 on their engagement score, and is a member of EA FB, EA Forum, or a local EA group, who has taken at least two ‘EA actions’ We consider whether the same set of outcomes differs between the ‘less responsive’ among this group, and the rest. We classify as ‘less responsive’ someone who either: responded in last 20th percentile overall, implying they started after 2020-12-12 * or * Note the earliest start date was 2020-11-13 and the latest was 2021-01-03. did not agree to get emailed to respond to future EAS surveys. engaged_resp_df &lt;- eas_20 %&gt;% filter(engagement_num&gt;=4) %&gt;% filter(num_actions&gt;=2) %&gt;% filter(member_none!=1) %&gt;% mutate( less_willing = case_when( start_date_quantiles==&quot;(80%, 100%]&quot; &amp; referrer_cat3==&quot;Forum/Opt-in/Shared/Newsletter&quot; ~ TRUE, start_date_quantiles==&quot;(80%, 100%]&quot; &amp; referrer_cat3!=&quot;Forum/Opt-in/Shared/Newsletter&quot; ~ TRUE, survey_willing==&quot;No next EAS&quot; ~TRUE, TRUE ~ FALSE ), inside_referrer= referrer_cat3==&quot;Forum/Opt-in/Shared/Newsletter&quot;, willing_x_insider = case_when( less_willing &amp; inside_referrer ~ &quot;less willing, inside ref&quot;, less_willing &amp; !inside_referrer ~ &quot;less willing, outside&quot;, !less_willing &amp; inside_referrer ~ &quot;more willing, inside ref&quot;, !less_willing &amp; !inside_referrer ~ &quot;more willing, outside&quot;, ) ) %&gt;% select(all_of(key_outcomes), willing_x_insider, -engagement_num) ( demo_tab_engaged_responsive &lt;- engaged_resp_df %&gt;% tbl_summary( by = willing_x_insider, type = c(all_continuous(), mn_priority_lt_rating, don_share_inc_19_imp) ~ &quot;continuous2&quot;, statistic = list(all_continuous() ~ c(&quot;{median}&quot;, &quot;{mean} ({sd})&quot;), all_dichotomous() ~ &quot;{p}%&quot;), label = label_list[1:11], missing = c(&quot;no&quot;), digits = list(mn_priority_lt_rating ~1) ) %&gt;% modify_spanning_header(c(&quot;stat_1&quot;, &quot;stat_2&quot;,&quot;stat_3&quot;, &quot;stat_4&quot; ) ~ &quot;**Willingness measure x &#39;inside&#39; vs &#39;outside&#39; referrers**&quot;) %&gt;% modify_footnote( update = all_stat_cols() ~ &quot;&#39;Inside&#39; referrers: Forum/Opt-in/Shared link/Newsletter; Willingness measure described above&quot;) %&gt;% bold_labels() %&gt;% add_n() %&gt;% add_overall() ) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #obcqjwewfv .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #obcqjwewfv .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #obcqjwewfv .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #obcqjwewfv .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #obcqjwewfv .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #obcqjwewfv .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #obcqjwewfv .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #obcqjwewfv .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #obcqjwewfv .gt_column_spanner_outer:first-child { padding-left: 0; } #obcqjwewfv .gt_column_spanner_outer:last-child { padding-right: 0; } #obcqjwewfv .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #obcqjwewfv .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #obcqjwewfv .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #obcqjwewfv .gt_from_md > :first-child { margin-top: 0; } #obcqjwewfv .gt_from_md > :last-child { margin-bottom: 0; } #obcqjwewfv .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #obcqjwewfv .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #obcqjwewfv .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #obcqjwewfv .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #obcqjwewfv .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #obcqjwewfv .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #obcqjwewfv .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #obcqjwewfv .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #obcqjwewfv .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #obcqjwewfv .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #obcqjwewfv .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #obcqjwewfv .gt_sourcenote { font-size: 90%; padding: 4px; } #obcqjwewfv .gt_left { text-align: left; } #obcqjwewfv .gt_center { text-align: center; } #obcqjwewfv .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #obcqjwewfv .gt_font_normal { font-weight: normal; } #obcqjwewfv .gt_font_bold { font-weight: bold; } #obcqjwewfv .gt_font_italic { font-style: italic; } #obcqjwewfv .gt_super { font-size: 65%; } #obcqjwewfv .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } Characteristic N Overall, N = 7431 Willingness measure x 'inside' vs 'outside' referrers less willing, inside ref, N = 782 less willing, outside, N = 1052 more willing, inside ref, N = 2202 more willing, outside, N = 3402 Age 738 Median 26.0 26.0 26.0 26.0 27.0 Mean (SD) 27.5 (6.5) 27.2 (6.4) 27.8 (7.4) 26.8 (5.2) 27.8 (6.9) Male 727 74% 61% 69% 79% 74% Student 739 42% 40% 46% 41% 41% White (ethnicity) 735 83% 78% 83% 85% 83% USA-based 738 36% 37% 38% 42% 32% Income in $1000 651 Median 27 24 31 36 23 Mean (SD) 59 (162) 86 (359) 69 (166) 65 (139) 45 (78) Academic current career 740 19% 21% 26% 16% 19% Mean prioritization LT (1-5) 721 Median 3.5 3.4 3.4 3.6 3.5 Mean (SD) 3.4 (0.6) 3.3 (0.8) 3.4 (0.6) 3.5 (0.6) 3.4 (0.6) LT cause(s) highest 727 59% 58% 66% 58% 58% Animal welfare highest 715 22% 24% 19% 18% 24% Donation as share of income, with imputation 653 Median 0.03 0.02 0.03 0.04 0.03 Mean (SD) 0.20 (2.63) 0.08 (0.16) 0.77 (6.81) 0.09 (0.16) 0.11 (0.46) 1 c(&quot;Median&quot;, &quot;Mean (SD)&quot;); % 2 'Inside' referrers: Forum/Opt-in/Shared link/Newsletter; Willingness measure described above Again, presenting standard errors below to put these differences in context: engaged_resp_df %&gt;% group_by(willing_x_insider) %&gt;% hi_low_groups %&gt;% group_by(willing_x_insider) %&gt;% summarise(across(everything(), list(se = ~sd(.x, na.rm=TRUE)/sqrt(length(.x))))) %&gt;% transpose_ok Table 2.5: Standard errors of means; for smallest and largest groups less willing, inside ref more willing, outside age_approx_se 0.7284186 0.3769116 d_male_se 0.05571278 0.02368125 d_student_se 0.05576861 0.02672521 race_white_se 0.04727164 0.02047766 d_live_usa_se 0.05498129 0.02538740 income_k_c_se 40.69231 4.20770 career_academia_se 0.04624081 0.02125488 mn_priority_lt_rating_se 0.09381151 0.03416881 lt_top_priority_se 0.05621375 0.02684385 animal_top_priority_se 0.04842427 0.02325260 don_share_inc_19_imp_se 0.01803829 0.02471396 "],["eas-engagement.html", "3 Engagement 3.1 Introduction 3.2 Measures of Engagement 3.3 Descriptives of engagement (see forum post [LINK]) 3.4 Descriptives: Engagement by Demographics, Socio-Economic factors, Attitudes/Behaviors, and Paths (and vice-versa) 3.5 Modeling engagement* 3.6 Engagement: age, tenure, period and cohort effects 3.7 Additional – CEA request: cities/areas by group engagement and retention, adapted: 3.8 Conclusions and Future work 3.9 After-post followups/further work", " 3 Engagement firstup &lt;- function(x) { substr(x, 1, 1) &lt;- toupper(substr(x, 1, 1)) x } #moved to build side # eas_20 &lt;- eas_20 %&gt;% sjlabelled::var_labels(engagement_num = &quot;Engagement&quot;, # age_approx = &quot;Age&quot;, # tenure = &quot;Time in EA&quot;, # age_first_inv = &quot;Age first-involved in EA&quot;) scatter_theme &lt;- theme_minimal() Note: This chapter presents (most) of the material from our EAS 2020: Engagement EA forum post [LINK], along with the code and dynamic graphs. The chapter goes into more technical depth than the EA forum post, and presents some additional work and results. (However, some of the material from the forum post is not here, particular where it was created directly in Google Sheets; this is noted and linked below. This work also connects to the work in a previous post/chapter on “Do introducers predict and/or drive engagement?” See also our 2019 post on the same topic 3.1 Introduction We describe people’s self-reported levels of engaged in EA, what activities related to effective altruism they have completed and their group membership. We also describe differences in these modes of engagement across groups (gender, race, age, time in EA etc.) and present a series of models looking at factors associated with higher engagement. This hosted ‘bookdown’ content covers this in more detail, with folded code and some dynamic depictions. 3.1.1 Why do we care about ‘engagement?’ 2019 introduction: In recent years there has been significant interest in the levels of engagement of EAs and in particular, the most engaged members of the community. The focus and resources devoted to those considered “contributors” or “core”(1, 2) (add links) are likely very different to those considered part of the EA “network.” CEA has noted that the level of involvement with EA of typical applicants to EA Globals has risen so much that the typical person who didn’t get accepted to attend has changed from someone who was barely involved with EA to someone who is probably pretty knowledgeable about EA and has been involved for at least a few years. These points remain relevant. We present a descriptive picture of “who is more engaged” because this offers greater understanding of “what the EA movement looks like.” Those who are more engaged are likely to have a greater impact, and thus may be of greater interest for some considerationss. In addition to description, we are also interested in more ambitious predictive and even (at least suggestively) causal modeling of engagement for several reasons, also mentioned in previous posts. These serve three categories of goals Outreach, Planning, and Policy. Outreach: Knowing “who is likely to become engaged” may inform decisionmaking surrounding ‘how much resources to devote to recruiting and supporting EAs,’ and ‘at which age to recruit EAs’ (see further analysis of the latter question below. This motivates a predictive approach: trying to forecast (lifetime) engagement based on factors (e.g., age, career background, source of ‘first heard of EA’) that can be measured, and are fixed at a point in time before the engagement and involvement journey. (Unfold further discussion…) “EA lifetime value?”…. In other words, this can help movement and group leaders (and active EAs) make better decisions about how many resources to put into recruiting and retaining people from different areas and in different ways. One might make an analogy to “customer lifetime value” in marketing – companies will offer more costly promotions to those customers they think will be more valuable over the long term. This is not necessary the way we want to view this; it is just one perspective. Prediction and extrapolation; modeling concerns… If we know ‘which sorts of people were more likely to become engaged’ in the past, this may predict ‘which sorts… that we might recruit now, are likely to become engaged in the future.’ Of course, we should be careful about making these extrapolations, as the nature of background processes may change over time, as well as the links between an observed and observed factors. For example, ‘jazzy people’ in the years 2014-2016 may have tended to also have being a highly prosocially motivated, because the jazz movement was volunteer-based during this period. Thus, being jazzy in 2015 may have been highly predictive of EA engagement in 2020. But if the jazz movement started to pay people to join in 2020, then being jazzy in 2020 may poorly predict EA engagement in 2025. Differential attrition issue… Another factor that limits this: If we use only the 2020 survey, these estimates may be driven by differential attrition from EA, and from filling out the survey, as noted elsewhere. Suppose we find that people who are inherently jazzy (for simplicity, suppose this is an immutable characteristic), who we see in the 2020 survey, tend to be much more highly engaged. This could be because being jazzy is closely linked to engagement, or to another unobserved factor that predicts engagement. In such a case, we may expect this to be a good predictor of future engagement, and this would argue for us trying to heavily recruit jazzy people. However, another possibility is that jazzy people tend to only continue in the movement and fill out the surveys when they are heavily engaged, while non-jazzy people fill out the surveys equally regardless of their engagement level. We can only disentangle this by looking at earlier data and considering the differential rates of attrition. We have some evidence for differential rates of attrition, e.g., by ‘introducer’ – see Attrition from EA/EA survey by introducer in the “How EAs get Involved in EA” post. We are still considering how how to feasibly deal with this as we have fairly low rates of reseponses where people share their emails and thus limited connectivity across years. E.g., on average, an individual in any EA survey can be tracked over only 1.3 surveys. From fold: E.g., on average, an individual in any EA survey can be tracked over only 1.3 surveys 1.31290397944085 surveys) Taking into account both engagement and attrition, over a medium run, this will also inform decisions surrounding “whether and how much to encourage growth,” and how much to “focus on helping those already in the movement take further actions.” A key measure informing this decision is the “conversion rate” between new recruits to EA (who tend to be less engaged. and later heavily engaged EAs. Caveat: Diversity and other concerns… ‘Likelihood of becoming engaged’ may not be the only, or even the principle concern; recruiting diverse EAs from a variety of contexts is likely to be a goal in itself, and may also unlock new networks, opportunities, and approaches. Planning and anticipating movement growth: How is EA (and engagement) likely to grow over time, and in what ways? (Unfold further discussion…) We may want to know how large the movement is likely to grow over time, and what level of engagement we can predict in the future. This could inform choices we make about infrastructure as well as which approaches to focus on. For example (hypothetically), if it is unlikely that we will ever become a large and engaged movement, this may make direct political action less feasible and less worth planning, and we might be less concerned about the dilution of core ideas. Knowing what the composition of the movement is likely to look like in the future (e.g., age, demographics and geography) may also help identify more fruitful possibilities. The EA Survey may help us learn the ways the different participants tend to become more or less engaged over time, as well as whether they leave the movement entirely. This may allow better forecasting and planning. Policy/what works: Knowing “what might lead to people becoming more engaged” will help us choose which approaches to take in bringing people into the movement, encouraging their participation, and promoting different activities and messages. However, this causal inference is a harder target. Policy/what works: Knowing “what might lead to people becoming more engaged” will help us choose ‘policies,’ i.e., understand which approaches to take in bringing people into the movement, encouraging their participation, and promoting different activities and messages. However, this causal inference is a harder target (discussed in fold). To the extent that we do observe the ‘policies’ an individual EA faced (or things related to these, like the self-reported influences). These will tend to be related to other observable and unobservable characteristics (such as country, age, year-joined, individual’s educational choices), which in turn may have direct and indirect effects and relate to other important on observable determinants of engagement. As we do not have clear policy experiments or ‘natural experiments’ (see the literature on causal inference), we can, at best, look for patterns that suggest causal links. Because of this limitation, we will do this only sparingly in the current post/chapter. 3.2 Measures of Engagement 3.2.1 Engagement measures and validation As stated in 2019: It is important to state at the outset that being involved in the community by posting on the Forum, attending lots of events, or working at EA related organizations is not necessarily the same as dedication to EA or having the most impact. Here we examine how engaged in different activities are the 2,513 EAs who responded to the 2019 EA Survey. Naturally, what measure we should use to determine the most engaged EAs in the survey is controversial. Any proxy we select will also necessarily be imperfect as there will almost certainly be exceptions to the rule. In this post we examine potential proxies, which may each capture distinct modes of EA involvement; group membership, activities, and self-reported engagement. For the current post (for the 2020 survey) we focus on self-reported engagement. We give a simple table of self-reported engagement below: eas_20 %&gt;% tabyl(engagement) %&gt;% adorn_pct_formatting(digits = 2) %&gt;% .kable() %&gt;% .kable_styling() engagement n percent valid_percent No engagement 44 2.14% 2.40% Mild engagement 352 17.12% 19.19% Moderate engagement 549 26.70% 29.93% Considerable engagement 544 26.46% 29.66% High engagement 345 16.78% 18.81% NA 222 10.80% #eas_20 %&gt;% tabyl(engagement_num, referrer_cat) In a separate document linked HERE we present our work assessing whether the self-report engagement is meaningfully related to the behavior that are intuitively associated with engagement. The analysis strongly supports this association. 3.3 Descriptives of engagement (see forum post [LINK]) The content in this section was mainly created in created in Google Sheets. Thus we link the forum post here, rather than presenting it again. eas_20_m &lt;- eas_20 %&gt;% select( engagement, starts_with(&quot;action&quot;)) %&gt;% reshape2::melt(id.vars=&quot;engagement&quot;) %&gt;% mutate(counter=1) %&gt;% group_by(engagement, variable) %&gt;% summarise(share = mean(as.numeric(value), na.rm=TRUE)) eas_20_m %&gt;% ggplot(aes(x = engagement, y = share, fill = variable)) + geom_bar(stat = &quot;identity&quot;) + coord_flip() 3.4 Descriptives: Engagement by Demographics, Socio-Economic factors, Attitudes/Behaviors, and Paths (and vice-versa) 3.4.1 Self-reported engagement: key comparisons We consider differences in key characteristics by level of engagement. We first present a numerical table summarizing a key set of socio-demographics, priorities, and behaviors; we present these both overall and for each level of self-reported engagement. ( demo_tab_engagement &lt;- eas_20 %&gt;% mutate(engage_cats_1 = as.factor(engage_cats_1), engage_cats_1= fct_drop(engage_cats_1) ) %&gt;% select(all_of(key_outcomes), engage_cats_1, -engagement_num) %&gt;% tbl_summary( by = engage_cats_1, type = c(all_continuous(), mn_priority_lt_rating, don_share_inc_19_imp) ~ &quot;continuous2&quot;, statistic = list(all_continuous() ~ c(&quot;{median}&quot;, &quot;{p10}-{p90}&quot;, &quot;{mean} ({sd})&quot;), all_dichotomous() ~ &quot;{p}%&quot;), label = label_list[1:11], missing = c(&quot;no&quot;), digits = list(mn_priority_lt_rating ~1) ) %&gt;% modify_spanning_header(c(&quot;stat_1&quot;, &quot;stat_2&quot;, &quot;stat_3&quot;, &quot;stat_4&quot;) ~ &quot;**Self-reported engagement**&quot;) %&gt;% modify_footnote( update = all_stat_cols() ~ &quot;*See notes in text.&quot;) %&gt;% bold_labels() %&gt;% add_n() %&gt;% add_overall() ) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #lldxsltgtb .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #lldxsltgtb .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #lldxsltgtb .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #lldxsltgtb .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #lldxsltgtb .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #lldxsltgtb .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #lldxsltgtb .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #lldxsltgtb .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #lldxsltgtb .gt_column_spanner_outer:first-child { padding-left: 0; } #lldxsltgtb .gt_column_spanner_outer:last-child { padding-right: 0; } #lldxsltgtb .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #lldxsltgtb .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #lldxsltgtb .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #lldxsltgtb .gt_from_md > :first-child { margin-top: 0; } #lldxsltgtb .gt_from_md > :last-child { margin-bottom: 0; } #lldxsltgtb .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #lldxsltgtb .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #lldxsltgtb .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #lldxsltgtb .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #lldxsltgtb .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #lldxsltgtb .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #lldxsltgtb .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #lldxsltgtb .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #lldxsltgtb .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #lldxsltgtb .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #lldxsltgtb .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #lldxsltgtb .gt_sourcenote { font-size: 90%; padding: 4px; } #lldxsltgtb .gt_left { text-align: left; } #lldxsltgtb .gt_center { text-align: center; } #lldxsltgtb .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #lldxsltgtb .gt_font_normal { font-weight: normal; } #lldxsltgtb .gt_font_bold { font-weight: bold; } #lldxsltgtb .gt_font_italic { font-style: italic; } #lldxsltgtb .gt_super { font-size: 65%; } #lldxsltgtb .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } Characteristic N Overall, N = 1,8341 Self-reported engagement 1-2, N = 3962 3, N = 5492 4, N = 5442 5, N = 3452 Age 1,604 Median 27 30 28 26 28 10%-90% 21-41 21-55 21-41 20-34 22-37 Mean (SD) 30 (10) 35 (14) 30 (10) 27 (7) 29 (7) Male 1,574 71% 62% 71% 73% 73% Student 1,635 37% 29% 35% 46% 32% White (ethnicity) 1,600 83% 84% 82% 83% 84% USA-based 1,606 39% 36% 40% 39% 39% Income in $1000 1,409 Median 33 44 37 22 33 10%-90% 1-130 0-125 1-143 1-120 3-122 Mean (SD) 61 (137) 56 (75) 66 (133) 55 (124) 65 (192) Academic current career 1,620 18% 16% 17% 20% 19% Mean prioritization LT (1-5) 1,584 Median 3.4 3.0 3.2 3.4 3.5 10%-90% 2.3-4.0 2.0-4.0 2.2-4.0 2.5-4.0 2.6-4.2 Mean (SD) 3.3 (0.7) 3.0 (0.8) 3.2 (0.7) 3.4 (0.6) 3.4 (0.6) LT cause(s) highest 1,614 51% 38% 47% 58% 58% Animal welfare highest 1,549 19% 14% 15% 26% 17% Donation as share of income, with imputation 1,422 Median 0.02 0.01 0.02 0.03 0.04 10%-90% 0.00-0.14 0.00-0.10 0.00-0.12 0.00-0.22 0.00-0.20 Mean (SD) 0.12 (1.78) 0.05 (0.13) 0.05 (0.12) 0.10 (0.38) 0.32 (3.95) 1 c(&quot;Median&quot;, &quot;10%-90%&quot;, &quot;Mean (SD)&quot;); % 2 *See notes in text. Notes on the above table…* ** This table removes respondents who didn’t report their engagement. ‘Mean prioritization LT’ averages the priority assigned to X-risk, AI risks, Biosecurity, Nuclear, and broad-LT-ism’; ‘LT cause(s) highest’ indicates that one of these causes was among those the individual ranked most-highly. In the above table Gender, (White) ethnicity, student status and academic career don’t seem to have a strong relationship to engagement. The least-engaged seem somewhat older, more female, less likely to be students, and less USA-based. The less-engaged also appear to be less long-termist. The most-engaged seem to donate a larger share of their income. Other patterns are less clear: median income seems to decline in engagement somewhat, while mean income is fairly constant. 3.4.2 Summary charts Descriptive measures also help us locate ‘where the engaged people are,’ and help us compare which groupings are more engaged. Below, we present ‘relative frequency stacked bar charts’ showing the ‘raw’ (uncontrolled) relationships between key characteristics and the levels of self-reported engagement. All bars are grouped from ‘highest to lowest share with 4-5 engagement,’ except for age, which is grouped by youngest to oldest. The bars depict 95% confidence intervals for the ‘shares of each subgroup with 4-5 engagement,’ as well as the narrower 1-standard-error bars. mutate_eng &lt;- function(df) { {df} %&gt;% filter(!is.na(engagement)) %&gt;% mutate(engagement= fct_recode(engagement, &quot;(1) None&quot; = &quot;(1) No engagement&quot;, &quot;(2) Mild&quot; = &quot;(2) Mild engagement&quot; , &quot;(3) Moderate&quot; = &quot;(3) Moderate engagement&quot;, &quot;(4) Considerable&quot; = &quot;(4) Considerable engagement&quot;, &quot;(5) High&quot; = &quot;(5) High engagement&quot;, )) } engage_stack_layers &lt;- list( geom_bar(aes(fill=engagement), position=&quot;fill&quot;), theme(axis.title.x = element_blank(), axis.text.x = element_blank(), axis.ticks.x = element_blank(), axis.ticks.y = element_blank(), axis.title.y = element_blank() ), stat_summary(aes(y = engage_high_n), fun.data = mean_cl_normal, na.rm = TRUE, geom = &quot;errorbar&quot;, colour = &quot;pink&quot;, width = 0.2), stat_summary(aes(y = engage_high_n), fun.data = mean_cl_normal, na.rm = TRUE, geom = &quot;errorbar&quot;, colour = &quot;purple&quot;, width = 0.2, fun.args = list(mult = 1)), coord_flip() ) engage_by_age &lt;- eas_20 %&gt;% mutate_eng %&gt;% ggplot() + aes(x = fct_rev(age_approx_ranges) ) + engage_stack_layers + labs(title = &quot;Engagement x &#39;Age&#39;&quot;, x=&quot;Age&quot;, y=&quot;share&quot;, caption = &quot;95% CI bars for &#39;share 4-5 engaged&#39; in pink, 1 SE in purple&quot;) engage_by_gender &lt;- eas_20 %&gt;% filter(!is.na(engagement)) %&gt;% ggplot() + aes(x = reorder(gender_cat, engage_high_n) ) + engage_stack_layers + labs(title = &quot;... x Gender&quot;, x=&quot;Gender&quot;, y=&quot;share&quot;) engage_by_student &lt;- eas_20 %&gt;% filter(!is.na(engagement)) %&gt;% ggplot() + aes(x = reorder(student_cat, engage_high_n) ) + engage_stack_layers + labs(title = &quot;... x Student&quot;, x=&quot;Student&quot;, y=&quot;share&quot;) engage_by_race &lt;- eas_20 %&gt;% filter(!is.na(engagement)) %&gt;% ggplot() + aes(x = reorder(race_cat, engage_high_n) ) + engage_stack_layers + labs(title = &quot;... x Ethnicity&quot;, x=&quot;Ethnicity&quot;, y=&quot;share&quot;) engage_by_where_live_cat &lt;- eas_20 %&gt;% filter(!is.na(engagement)) %&gt;% ggplot() + aes(x = reorder(where_live_cat, engage_high_n) ) + engage_stack_layers + labs(title = &quot;... x Location&quot;, x=&quot;Where live&quot;, y=&quot;share&quot;) engage_by_city_cat &lt;- eas_20 %&gt;% filter(!is.na(engagement)) %&gt;% ggplot() + aes(x = reorder(city_cat, engage_high_n) ) + engage_stack_layers + labs(title = &quot;... x (Named) big city&quot;, x=&quot;Big&quot;, y=&quot;share&quot;) ( engage_by_cat_stack &lt;- ggarrange(engage_by_age, engage_by_gender, engage_by_student, engage_by_race, engage_by_where_live_cat, engage_by_city_cat, ncol = 2, nrow = 3, heights = c(1, 1), align = &quot;v&quot;, common.legend = TRUE, legend = &quot;bottom&quot;) ) Examining the proportion of respondents who self-identified as levels 1-3 vs 4-5 in terms of engagement, we observe that: Those &gt;34 years of age reported being less engaged Male respondents reported being more engaged Students reported being more engaged Those living in one of the 22 big cities named in the survey ^[These were cities known to have relatively high EA populations: Amsterdam, Auckland, Berlin, Boston / Cambridge (USA), Cambridge (UK) , Canberra, Chicago, London Los Angeles Melbourne, New York City, Oslo, Oxford, Philadelphia, Seattle, SF Bay Area, Stockholm, Sydney, Toronto, Vienna, Washington DC, Zürich] reported being more engaged In terms of country of residence groupings, UK + Ireland were the most engaged, and Canada + Australia + New Zealand the least engaged. 3.4.3 When people get involved in EA/ Time in EA / Age / Age When First Involved in EA This subsection, given in the Forum post, is mainly subsumed by the Engagement: age, tenure, period and cohort effects subsection below. 3.4.4 Gender and self-reported engagement, … and group membership - see forum post [LINK] 3.4.5 Race and and group membership; Race and activities - see forum post 3.4.6 Where people first heard of EA We analyzed differences in engagement between respondents who reported first hearing about EA from different sources in this earlier post and section. For a quick reference, we give a breakdown of engagement by groups of ’where first heard of EA’below (this is a simpler version of a chart presented in “How EAs get involved in EA”). dodge_thing &lt;- list( geom_bar(position=position_dodge2(), stat=&#39;identity&#39;), scale_fill_hue(labels = c(&quot;1-3 engaged&quot;, &quot;4-5 engaged&quot; ) ), theme_minimal(), guides(fill=guide_legend(title=NULL)), theme(legend.position = &quot;top&quot;), guides(fill = guide_legend(title=NULL, reverse = TRUE)), theme(axis.text.x = element_text(angle = -90, vjust = 0, hjust=0)), scale_y_continuous(labels=percent, expand = expansion(mult = c(0,.1))), coord_flip() ) p_load(binom) p_load(standardize) fh_45_data_l &lt;- eas_20 %&gt;% select(d_engage_4_5, first_hear_ea_lump) %&gt;% filter(!is.na(d_engage_4_5)) %&gt;% group_by(d_engage_4_5, first_hear_ea_lump) %&gt;% mutate(fheg_n = n()) %&gt;% group_by(d_engage_4_5) %&gt;% mutate(eng_n = n()) %&gt;% unique() %&gt;% mutate(fheg_share = fheg_n/eng_n) %&gt;% mutate(eg_share_se = sqrt((fheg_share*(1-fheg_share))/eng_n)) %&gt;% ungroup() ci_s &lt;- binom.confint(x=fh_45_data_l$fheg_share*fh_45_data_l$eng_n, n=fh_45_data_l$eng_n, methods=&quot;wilson&quot;) fh_45_data_l &lt;- cbind(fh_45_data_l, ci_s[,5:6]) ( fh_e45_plotl &lt;- fh_45_data_l %&gt;% ggplot() + aes(x = reorder(first_hear_ea_lump,fheg_share), fill=d_engage_4_5, y = fheg_share) + dodge_thing + geom_errorbar(aes(ymin=fheg_share-1.96*eg_share_se, ymax=fheg_share+1.96*eg_share_se), width=.2, colour = &quot;pink&quot;, position=position_dodge(.9)) + labs(title = &quot;First heard of EA (groupings) by &#39;highly engaged&#39;&quot;, subtitle = &quot;95 percent CI&#39;s (normal approx)&quot;, y = &quot;Percent&quot;, x = &quot;&quot;) ) 3.5 Modeling engagement* * This section slightly overlaps some of the material in our “How EAs get involved” post. 3.5.1 Descriptive modeling As mentioned in the introduction, we care “what is associated with engagement holding other things constant?” Although much of our analysis is merely meant to be descriptive, in general we try to leave out ‘confounders’ (especially things that are themselves proxies for engagement). However. we recognize that ‘being in the sample’ (considering attrition) may be a sort of confounder in itself. 3.5.2 Predictive and causal modeling As noted in the introduction [LINK], predictive and/or causal models inform Outreach, Planning, and Policy. We seek to build models that predict… Accurately: predicting outside the data the model was trained on (see the problem of “Overfitting”), and predicting throughout the range of the years of data, including the most recent data (Allowing for trends and trend-differences across years may make the model better at predicting well in the future.) …Based on variables we can and do observe at the time we make relevant policy choices. Thus: considering the limits of the EAS scope, and without using ‘ex-post’ and ‘outcome’ variables such as ‘participation in EA Forum’ (aka ‘leaks’ and ‘colliders’). …For EA individuals, not just for the subset of individuals who remain in EA/in the EA survey. Thus: We need to take attrition (from EA and from the survey) seriously, and potentially make it part of our model. 3.5.2.1 Ideal (future) modeling approach Ideally we would, and will… (unfold) I. Create a measure \\(G\\) (or set of measures) of ‘engagement’ (and or value-added) that captures the outcomes we think we are looking for. Previous ‘clustering’ work (by Kim) may inform this. For the present, we will use “self-reported engagment (or dichotomising this into 1-3 vs 4-5).” As noted above, this measure seems to be ‘validated’ by the cluster analysis. Goals and relationships (theoretical structural model) In a perfect world, we would like to estimate a function for the (real or counterfactual) ‘level of engagement’ of person \\(i\\) in year \\(t\\), with permanent characteristics \\(X_i\\) and time-varying characteristics \\(X_{it}\\) (these are vectors), who became involved in EA in year \\(t_0\\), who was ‘exposed to a vector \\(S_t\\) of EA stimuli in each year since joining,’ summarized as \\(S \\equiv S_t \\forall t \\geq t_0\\). We can write this ‘true structural model’ as \\[G_{it} = f(t, X_i, X_{it}, S, t_0, t) + \\epsilon_{it}\\], where \\(\\epsilon_{it}\\) is an irreducible true random term. In principle, knowing the above ‘true model’…. … would allow us to address a range of causal questions about possible ‘interventions,’ e.g., how engaged would the average German Female who joins EA in 2021 be in 2025 if they were (A) exposed to a heavy diet of LessWrong and three 80K podcasts per month … versus (B) if they were not exposed to Less Wrong but (induced?) to taking the GWWC pledge and becoming vegan. Thus “what is the (causal) effect of (B) relative to (A)?” or similar ‘retrospective’ questions: … who joined EA in 2014 have been in 2020 if they had been exposed to some set of stimuli (C) versus (D)? (Or if they had joined in 2015 instead, etc.) More reasonably, we will never be able to observe all of the important characteristics of the individual, nor her exposures, never know the ‘true functional form’ of the model, nor be able to perfectly distinguish causal relationships from chance. (But we will do our best!) We aim for a more ‘predictive model’ first, while considering issues of causality. For example, considering the previous questions, we may aim to predict… What will be the average level of engagement for a typical individual whom we see, in year 0, in observable group \\(A\\), after \\(\\tau=5\\) years of being in EA’? How does the same measure differ from that of an individual whom we see in group \\(B\\)? I.e., \\[E\\big(G_{t_0+5}|A\\big) - E\\big(G_{t_0+5}|B\\big)\\] Consider “group,” to embody any number of characteristics we observe in the EAS, such as ‘place first heard of EA,’ or ‘country of origin.’ Here we are not asking the causal ‘counterfactual’ question ‘for the same individual how would this differ depending on whether they were in (or had the characteristics of) group A versus B, all else equal.’ All else is not equal: we realize that for any groupings A and B, people in these groups will have very different observable and unobservable characteristics (\\(X_i, X_{it}\\)) from one another, and also will be exposed to a different set of stimuli \\(S\\).* * They may also have joined EA in different calendar years (\\(t_0\\)), but we will explicitly try to keep this constant in our work. Instead, we will focus on making decent predictions to guide our policy choices. One might we mainly care most about making these predictions for people entering in future years, so as to better direct our resources (see above discussion of the ‘three goals’). Knowing that ‘EAs who joined through GWWC in 2014 are more active (in 2021) than those who joined through LW in 2017’ only informs our choices to the extent that these differences are stable, and likely to persist into future years. Choices of variables/features Prediction and outreach strategies: There are a range of categories on which we might want to make policy-relevant predictions about engagement. We may care specifically about the extent to which other things (demographics, initial alignment, etc) predict later engagement. In assessing the impact of a factor such as ‘introducer,’ a causal model might reasonably ‘control’ for other observable features, such as age and gender.* * However, causal interpretation will still require strong assumptions, and ‘controls’ can sometimes introduce additional bias to causal estimates. On the other hand, a predictive model may not want to ‘control’ in the same way. Suppose we were specifically considering the potential of each (e.g., ‘first-heard’) ‘channel’ in recruiting EEAs. Here, e.g., we may want to know whether LessWrong can be expected to outperform 80K allowing that part of this difference may be driven by age or gender differences. Here we might not want to “difference out” the component of the LW effect that comes from these.** ** However, we might bring this decomposition back in a mixed-modeling context. We focus on a few of these below Predictors (and/or causal factors) of interest for outreach questions ‘Place first heard of EA’ Demographics, geography, other identifiable characteristics For forecasting growth (and as ‘controls’ in interpreting the predictive features) We have not (yet) built a full ‘growth model.’ However, the features below may be informative and suggestive. Year entered EA (‘Cohort’): Particularly important in considering the aggregated retrospective data Time in EA (Tenure; hard to distinguish from cohort) Period (‘when’ we are seeing the level of engagement) However, it is difficult to separate period, cohort and tenure/age effects in general as well as in our specific case. In general, \\(Period = Cohort + Tenure\\); we cannot identify the ‘effect’ of all three of these independently, without any further restrictions. For 2020 retrospective data, \\(Period=2020\\) and \\(Cohort = 2020 - Tenure\\). Unless we are willing to make further assumptions (e.g., a linear impact of Tenure), we will necessarily pick up cohort and tenure effects together.* * I discuss ‘Traditional APC and APCC models’ further in my notes here … see “Age-period-cohort effects”… which I hope to expand. More broadly, the growth of ‘engaged EA’ will depend on recruitment rates, attrition, on how people’s engagement changes with with tenure, and whether there are cohort (and secular period) trends towards less/more engagement. Choosing features and modeling target variables (Code below: I define a series of feature sets for modeling, and maybe define the contrast codings and labelings) #targets: bin_out &lt;- &quot;d_engage_4_5&quot; num_out &lt;- &quot;engagement_norm&quot; cat_out &lt;- &quot;engagement&quot; geog &lt;- c(&quot;where_live_cat&quot;, &quot;city_cat&quot;) key_demog &lt;- c(&quot;age_approx_d2sd&quot;, &quot;gender_cat&quot;, &quot;student_cat&quot;, &quot;race_cat&quot;, geog) big_demog &lt;- c(&quot;age_approx_d2sd&quot;, &quot;female_cat&quot;, &quot;student_cat&quot;, &quot;race_cat&quot;, &quot;usa_cat&quot;, &quot;city_cat&quot;) #removed &#39;current career&#39; as that seems closely tied to engagement ergo a potential confounder #removed &quot;d_straight&quot; because there is so much nonresponse there, and I think responding to that signals a high degree of engagement #Add: elite university, country regions #predictors key_predictors &lt;- c(key_demog) controls &lt;- c(&quot;years_involved_d2sd&quot;) #note this assumes those 2009 or earlier started in 2009 robust_controls &lt;- c(&quot;year_involved_groups&quot;, &quot;age_approx_ranges&quot;) possible_endog &lt;- c(&quot;income_d2sd&quot;, &quot;uni_higher_rank_d2sd&quot;, &quot;d_pt_employment&quot;, &quot;d_not_employed&quot;, &quot;d_retired&quot;) other_predictors &lt;- c(&quot;first_hear_ea_lump&quot;) eas_20 %&gt;% sm(&quot;d_live|d_not_em|straight|big_city|uni_higher_rank_d2sd&quot;) %&gt;% vtable::sumtable() (#tab:feature_sets)Summary Statistics Variable N Mean Std. Dev. Min Pctl. 25 Pctl. 75 Max d_not_employed 1636 0.049 0.216 0 0 0 1 d_live_usa 1607 0.386 0.487 0 0 1 1 uni_higher_rank_d2sd 1073 0 0.5 -1.897 -0.178 0.343 0.383 #“no big city” — named ‘other’ as their city. #d_straight — that’s low because so many people didn’t answer this question #career_other: that’s not student nor full time employed #contrasts(normtimeBP02$Nasality) = contr.treatment(4) (Code below: Imputing and normalizing) #note: rescaling work moved to eas_stata_to_r_clean.R eas_20_s &lt;- eas_20 %&gt;% dplyr::select(all_of(c(num_out, cat_out, bin_out, key_predictors, &quot;usa_cat&quot;, &quot;female_cat&quot;, controls, robust_controls, possible_endog, other_predictors))) eas_s_nomissing &lt;- eas_20_s %&gt;% select(all_of(c(cat_out, key_predictors, controls))) %&gt;% filter_all(all_vars(str_detect(as.character(.), pattern = &quot;NA&quot;, negate = TRUE))) %&gt;% gdata::drop.levels() %&gt;% mutate( where_live_cat = relevel(as.factor(where_live_cat), ref=&quot;USA&quot;), city_cat = relevel(as.factor(city_cat), ref=&quot;Other&quot;), student_cat = relevel(as.factor(student_cat), ref=&quot;Non-student&quot;), gender_cat = relevel(as.factor(gender_cat), ref=&quot;Male&quot;), race_cat = relevel(race_cat, ref=&quot;Just white&quot;) ) #missing_to_zero: moved to R-stuff functions.R thing #Recode missing as 0 for all dummies, as a &#39;NA category&#39; for categoricals #also for normalized variables; i.e., set missings to the mean eas_20_s &lt;- eas_20_s %&gt;% mutate(across(matches(&quot;d_|not_just_white&quot;), missing_to_zero)) eas_20_s_imp &lt;- eas_20_s %&gt;% mutate(across(matches(&quot;d2sd&quot;), missing_to_zero)) eas_20_s_imp %&gt;% vtable::sumtable() (#tab:impute_norm_features)Summary Statistics Variable N Mean Std. Dev. Min Pctl. 25 Pctl. 75 Max engagement_norm 1834 0 1 -2.269 -0.404 0.529 1.461 engagement 1834 … (1) No engagement 44 2.4% … (2) Mild engagement 352 19.2% … (3) Moderate engagement 549 29.9% … (4) Considerable engagement 544 29.7% … (5) High engagement 345 18.8% d_engage_4_5 2056 0.432 0.496 0 0 1 1 age_approx_d2sd 2056 0 0.442 -1.31 -0.242 0.063 3.673 gender_cat 2056 … Male 1112 54.1% … Female 423 20.6% … NA 481 23.4% … Other 40 1.9% student_cat 2056 … Non-student 1035 50.3% … NA 420 20.4% … Student 601 29.2% race_cat 2056 … Just white 1223 59.5% … NA 454 22.1% … Not just white 379 18.4% where_live_cat 2056 … USA 621 30.2% … Can/Aus/NZ 178 8.7% … EEA not Anglo 456 22.2% … Other 572 27.8% … UK/IR 229 11.1% city_cat 2056 … Other 839 40.8% … NA 507 24.7% … Named big city 710 34.5% usa_cat 2056 … USA 621 30.2% … Not USA 1435 69.8% female_cat 2056 … Not female 1152 56% … Female 423 20.6% … NA 481 23.4% years_involved_d2sd 2056 0 0.463 -0.585 -0.398 0.165 1.477 year_involved_groups 1761 … 2014 or before 287 16.3% … 2015-16 385 21.9% … 2017-18 525 29.8% … 2019-20 564 32% age_approx_ranges 1605 … [4, 23) 313 19.5% … [23, 26) 290 18.1% … [26, 29) 278 17.3% … [29, 34) 387 24.1% … [34, 120] 337 21% income_d2sd 2056 0 0.414 -0.221 -0.156 0 10.71 uni_higher_rank_d2sd 2056 0 0.361 -1.897 0 0.227 0.383 d_pt_employment 2056 0.034 0.181 0 0 0 1 d_not_employed 2056 0.039 0.193 0 0 0 1 d_retired 2056 0.018 0.131 0 0 0 1 first_hear_ea_lump 1839 … Other/don’t remember 420 22.8% … 80,000 Hours 228 12.4% … Book, article, or blog post 173 9.4% … Educational course 35 1.9% … GiveWell 45 2.4% … Giving What We Can 32 1.7% … LessWrong 151 8.2% … Local or university EA group 141 7.7% … Personal contact 300 16.3% … Podcast 135 7.3% … Slate Star Codex 97 5.3% … TED talk 82 4.5% Ordered logit models of self-reported engagement level We consider the association between a range of features and the respondent’s level of engagement. These (arguably) should still not be interpreted as causal relationships. Below, we construct an ordered logit model, reporting the odds ratios. As noted in our ‘community information’ post, these can be loosely interpreted as the “relative probability of stating a 1 unit higher level of satisfaction,” relative to the base group. Interpreting these estimates… E.g., if the coefficient for ‘jazzy’ is 1.5, this means that, controlling for everything else in the model, comparing any two levels of engagement (2 versus 1, 5 versus 4, etc) jazzy people are approximately 50% more likely to be in the higher group. Note that the ordered logit model imposes a particular functional form: a variable must have proportional relative ‘effect’ on the probability of being in a higher versus a lower category, with this proportional ‘effect’ being the same between any comparison of adjacent categories. However, a strong justification can be made that this is ‘more realistic’ than a linear model, which interprets the 1-5 engagement self report as if it were a meaningful cardinal outcome. ol_mdl &lt;- function(df, rhs) { polr( m_f(cat_out, {{rhs}}), data = df, Hess = TRUE ) %&gt;% broom::tidy(conf.int = TRUE, exponentiate = TRUE) %&gt;% filter(coef.type==&quot;coefficient&quot;) %&gt;% dplyr::arrange(-str_detect(term, &#39;d2sd&#39;)) %&gt;% mutate( term = str_replace_all(term, c(&quot;where_live_cat&quot; = &quot;Where live: &quot;, &quot;d2sd&quot; = &quot; (2 sd norm.)&quot;, &quot;gender_cat&quot; = &quot;Gender: &quot;, &quot;female_catFemale&quot; = &quot;Female (vs. non-female)&quot;, &quot;student_catNA&quot; = &quot;Student: NA&quot;, &quot;student_cat&quot; = &quot;&quot;, &quot;city_catNA&quot; = &quot;City: NA&quot;, &quot;city_cat&quot; = &quot;&quot;, &quot;usa_catNA&quot; = &quot;Where live: NA&quot;, &quot;usa_cat&quot; = &quot;&quot;, &quot;race_catNA&quot; = &quot;Race: NA&quot;, &quot;race_cat&quot; = &quot;&quot;, &quot;age_approx_&quot; =&quot;Age&quot;, &quot;uni_higher_rank_&quot; = &quot;Univ. rank (+)&quot;, &quot;years_involved&quot; = &quot;Years Involved EA&quot;, &quot;d_retired&quot; = &quot;Retired&quot;, &quot;d_&quot; = &quot;&quot;, &quot;first_hear_ea_lump&quot; = &quot;1st heard EA: &quot;, &quot;pt_employment&quot; = &quot;Part-time Employed&quot;, &quot;not_employed&quot; = &quot;Not Employed&quot;, &quot;income_&quot; =&quot;Income&quot;, &quot;Giving What We Can&quot; = &quot;GWWC&quot;, &quot;Slate Star Codex&quot; = &quot;SSC&quot; ) ) ) } rename_eng_mod_list &lt;- c(&quot;where_live_cat&quot; = &quot;Where live: &quot;, &quot;d2sd&quot; = &quot; (2 sd norm.)&quot;, &quot;gender_cat&quot; = &quot;Gender: &quot;, &quot;female_catFemale&quot; = &quot;Female (vs. non-female)&quot;, &quot;student_catNA&quot; = &quot;Student: NA&quot;, &quot;student_cat&quot; = &quot;&quot;, &quot;city_catNA&quot; = &quot;City: NA&quot;, &quot;city_cat&quot; = &quot;&quot;, &quot;usa_catNA&quot; = &quot;Where live: NA&quot;, &quot;usa_cat&quot; = &quot;&quot;, &quot;race_catNA&quot; = &quot;Race: NA&quot;, &quot;race_cat&quot; = &quot;&quot;, &quot;age_approx_&quot; =&quot;Age&quot;, &quot;uni_higher_rank_&quot; = &quot;Univ. rank (+)&quot;, &quot;years_involved&quot; = &quot;Years Involved EA&quot;, &quot;d_retired&quot; = &quot;Retired&quot;, &quot;d_&quot; = &quot;&quot;, &quot;first_hear_ea_lump&quot; = &quot;1st heard EA: &quot;, &quot;pt_employment&quot; = &quot;Part-time Employed&quot;, &quot;not_employed&quot; = &quot;Not Employed&quot;, &quot;income_&quot; =&quot;Income&quot;, &quot;Giving What We Can&quot; = &quot;GWWC&quot;, &quot;Slate Star Codex&quot; = &quot;SSC&quot; ) require(&quot;parallel&quot;) clean_model_p &lt;- function(polr_results) { parallel::mclapply(polr_results, function(x) { broom::tidy(x, conf.int = TRUE, exponentiate = TRUE) %&gt;% filter(coef.type==&quot;coefficient&quot;) }) } ol_engage_naive_m &lt;- eas_20_s_imp %&gt;% polr( m_f(cat_out, c(key_predictors)), data = ., Hess = TRUE ) ol_engage_naive &lt;- eas_20_s_imp %&gt;% ol_mdl(c(key_predictors)) ol_engage_noimp_m &lt;- eas_20_s %&gt;% polr( m_f(cat_out, c(key_predictors, controls)), data = ., Hess = TRUE ) ol_engage_noimp &lt;- eas_20_s %&gt;% ol_mdl(c(key_predictors, controls)) ol_engage_nomissing_m &lt;- eas_s_nomissing %&gt;% polr(m_f(cat_out, c(key_predictors, controls)), data = ., Hess = TRUE ) ol_engage_imp_m &lt;- eas_20_s_imp %&gt;% polr(m_f(cat_out, c(key_predictors, controls)), data = ., Hess = TRUE) ol_engage_imp &lt;- eas_20_s_imp %&gt;% ol_mdl(c(key_predictors, controls)) ##Do: with more robust controls : year_involved_groups, age_approx_ranges ol_engage_imp_m_r &lt;- eas_20_s_imp %&gt;% polr(m_f(cat_out, c(key_predictors, controls, robust_controls)), data = ., Hess = TRUE) ol_engage_imp_r &lt;- eas_20_s_imp %&gt;% ol_mdl(c(key_predictors, controls, robust_controls)) ol_engage_imp_big_m &lt;- eas_20_s_imp %&gt;% polr(m_f(cat_out, c(big_demog, controls)), data = ., Hess = TRUE) ol_engage_imp_big &lt;- eas_20_s_imp %&gt;% ol_mdl(c(big_demog, controls)) ol_engage_possible_endog_m &lt;- eas_20_s_imp %&gt;% polr(m_f(cat_out, c(key_predictors, controls, possible_endog)), data = ., Hess = TRUE) ol_engage_possible_endog &lt;- eas_20_s_imp %&gt;% ol_mdl(c(key_predictors, controls, possible_endog)) fh_imp_n &lt;- eas_20_s_imp %&gt;% smn(&quot;first_hear&quot;) ol_engage_fh_imp_m &lt;- eas_20_s_imp %&gt;% polr(m_f(cat_out, c(key_predictors, controls, fh_imp_n)), data = ., Hess = TRUE) ol_engage_fh_imp &lt;- eas_20_s_imp %&gt;% ol_mdl(c(key_predictors, controls, fh_imp_n)) #pseudo-r-sq ol_engage_imp_m_nag_pr2 &lt;- DescTools::PseudoR2(ol_engage_imp_m, which = &quot;Nagelkerke&quot;) ol_engage_noimp_m_nag_pr2 &lt;- DescTools::PseudoR2(ol_engage_noimp_m, which = &quot;Nagelkerke&quot;) # Models to tidy tibbles for use in plots ol_engage_tidymod &lt;- clean_model_p( list( &quot;(0) Naive&quot; = ol_engage_naive_m, &quot;(1) Baseline&quot; = ol_engage_imp_m, &quot;(1a) Baseline - no imputation&quot; = ol_engage_noimp_m, &quot;(1b) Larger groupings&quot; = ol_engage_imp_big_m, &quot;(4) Possibly endogenous&quot; = ol_engage_possible_endog_m, &quot;(5) First-heard&quot; = ol_engage_fh_imp_m, &quot;Robust controls&quot; = ol_engage_imp_m_r ) ) ol_na_terms &lt;- ol_engage_possible_endog_m$term[grepl(&quot;NA&quot;, ol_engage_possible_endog_m$term)] ol_key_pred_n_ctn &lt;- grep(&quot;d2sd&quot;, names(coef(ol_engage_imp_m)), value = TRUE) ol_key_pred_n_cat &lt;- grep(&quot;first_hear_ea_lump|Intercept|NA|d2sd&quot;, names(coef(ol_engage_imp_m)), value = TRUE, invert=TRUE) ol_na_pred &lt;- grep(&quot;NA|Intercept&quot;, names(coef(ol_engage_imp_m)), value = TRUE) names(ol_na_pred) &lt;- gsub(&quot;_cat&quot;, &quot;: &quot;, ol_na_pred) %&gt;% gsub(&quot;student&quot;, &quot;Employment status&quot;, . ) %&gt;% firstup(.) ol_key_pred_n &lt;- c(ol_key_pred_n_ctn, ol_key_pred_n_cat) names(ol_key_pred_n) &lt;- gsub(&quot;where_live_cat&quot;, &quot;Live: &quot;, ol_key_pred_n ) %&gt;% gsub(&quot;age_approx_d2sd&quot;, &quot;Age (2 sd norm.)&quot;,. ) %&gt;% gsub(&quot;uni_higher_rank_d2sd&quot;, &quot;Uni. rank (+)&quot;, .) %&gt;% gsub(&quot;d2sd&quot;, &quot;(2 sd norm.)&quot;, .) %&gt;% gsub(&quot;student_catStudent&quot;, &quot;Student&quot;, .) %&gt;% gsub(&quot;cat&quot;, &quot;- &quot;, .) %&gt;% #gsub(&quot;canzaus&quot;, &quot;Aus///Can///NZ&quot;, .) %&gt;% gsub(&quot;city_-&quot;,&quot;&quot;, .) %&gt;% firstup(.) %&gt;% gsub(&quot;D_&quot;, &quot;&quot;, .) %&gt;% gsub(&quot;Race_- &quot;, &quot;&quot;, .) %&gt;% gsub(&quot;_&quot;, &quot; &quot;, .) %&gt;% firstup(.) %&gt;% gsub(&quot;Pt&quot;, &quot;PT&quot;, .) fh_n &lt;- grep(&quot;first_hear_ea_lump&quot;, names(coef(ol_engage_fh_imp_m)), value = TRUE) names(fh_n) &lt;- gsub(&quot;first_hear_ea_lump&quot;, &quot;First-heard: &quot;, fh_n) %&gt;% gsub(&quot;X80&quot;, &quot;80&quot;, .) %&gt;% gsub(&quot;Giving What We Can&quot;, &quot;GWWC&quot;, .) %&gt;% gsub(&quot;Slate Star Codex&quot;, &quot;SSC&quot;, .) %&gt;% gsub(&quot;Book, article, or blog post&quot;, &quot;Book/article/blog&quot;, .) %&gt;% gsub(&quot;Local or university EA group&quot;, &quot;Local/Univ. EA group&quot;, .) names_pos_endog =c(&quot;Income (2sd norm)&quot; = &quot;income_d2sd&quot;, &quot;Univ. (+) rank, (2sd norm)&quot; = &quot;uni_higher_rank_d2sd&quot; , &quot;Retired&quot; = &quot;d_retired&quot;, &quot;PT Employment&quot; = &quot;d_pt_employment&quot; , &quot;Not Employed&quot; = &quot;d_not_employed&quot; ) names_big &lt;- c(&quot;Binary: Female (vs. non-female)&quot; = &quot;female_catFemale&quot;, &quot;Binary: Not USA-based)&quot; = &quot;usa_catNot USA&quot; ) ( ol_engage_tbl_m &lt;- huxreg( &quot;(1) Baseline&quot; = ol_engage_imp_m, &quot;(2) Possibly endogenous&quot; = ol_engage_possible_endog_m, &quot;(3) First-heard&quot; = ol_engage_fh_imp_m, tidy_args = list(conf.int = TRUE, prob = 0.95, exponentiate =TRUE), coefs = c(ol_key_pred_n, names_pos_endog, fh_n ), number_format = 2, statistics = c(&quot;N. obs.&quot; = &quot;nobs&quot;), error_pos = &quot;right&quot;, ci_level = .95, error_format = &quot;({conf.low}, {conf.high})&quot;) %&gt;% huxreg_opts %&gt;% set_col_width(c(1, rep(c(0.4, 0.4), times=5))) %&gt;% set_caption(&quot;Ordered logistic models &lt;br&gt; Odds-ratios; 95% CI&#39;s in parentheses; NA ratios hidden&quot;) %&gt;% set_caption_pos(&quot;top&quot;) %&gt;% head(-1) #get rid of missing p-value thing ) (#tab:ol_eng_rename_hux) Ordered logistic models Odds-ratios; 95% CI's in parentheses; NA ratios hidden (1) Baseline(2) Possibly endogenous(3) First-heard Age (2 sd norm.)0.37(0.30, 0.46)0.37(0.29, 0.47)0.37(0.29, 0.46) Years involved (2 sd norm.)4.46(3.66, 5.45)4.44(3.64, 5.43)4.52(3.67, 5.57) Gender - Female0.80(0.65, 0.98)0.79(0.64, 0.97)0.72(0.58, 0.89) Gender - Other1.04(0.58, 1.86)1.00(0.56, 1.79)0.98(0.54, 1.75) Student1.30(1.05, 1.61)1.34(1.07, 1.67)1.25(1.01, 1.55) Not just white0.99(0.79, 1.23)0.98(0.78, 1.23)1.00(0.80, 1.25) Live: Can/Aus/NZ0.83(0.61, 1.13)0.82(0.60, 1.11)0.83(0.61, 1.14) Live: EEA not Anglo1.26(0.99, 1.60)1.26(0.99, 1.60)1.20(0.94, 1.53) Live: Other1.60(1.13, 2.27)1.61(1.14, 2.29)1.51(1.06, 2.15) Live: UK/IR1.44(1.09, 1.92)1.41(1.06, 1.87)1.41(1.05, 1.89) Named big city1.56(1.28, 1.92)1.56(1.27, 1.91)1.53(1.24, 1.87) Income (2sd norm)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.95(0.77, 1.17)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Univ. (+) rank, (2sd norm)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1.17(0.94, 1.47)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Retired&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1.03(0.51, 2.06)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; PT Employment&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1.04(0.67, 1.61)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Not Employed&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1.54(1.00, 2.38)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; First-heard: 80,000 Hours&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.76(0.56, 1.02) First-heard: Book/article/blog&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1.10(0.79, 1.53) First-heard: Educational course&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1.84(0.94, 3.65) First-heard: GiveWell&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1.23(0.68, 2.21) First-heard: GWWC&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.61(0.30, 1.28) First-heard: LessWrong&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.79(0.56, 1.12) First-heard: Local/Univ. EA group&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1.16(0.82, 1.64) First-heard: Personal contact&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1.18(0.90, 1.56) First-heard: Podcast&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.89(0.62, 1.27) First-heard: SSC&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.48(0.32, 0.73) First-heard: TED talk&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1.22(0.79, 1.88) N. obs.1834.00&nbsp;&nbsp;&nbsp;&nbsp;1834.00&nbsp;&nbsp;&nbsp;&nbsp;1828.00&nbsp;&nbsp;&nbsp;&nbsp; In the Ordered Logit models summarized in the above table, continuous variables (income, age, university rank) are de-meaned and divided by two standard-deviations.* * This is for comparability to dummy-coded categorical variables, see Gelman, 2007. Where these are missing they are coded as zero, the mean of the transformed variable. Base groups are set as the most numerous group in each category. Thus, all dummy coefficients represent adjustments from the ‘overall base group’: an individual who is male, works full-time, ‘just White’ ethnicity, USA-based, not based in a (survey-named) big city, and ‘first heard of EA’ response is ‘other or don’t remember.’ The above models include dummy variable ‘controls’ for nonresponses to each of the given categorical variables. These coefficients are hidden in the above table, but shown further below. We next present a forest plot of the coefficients from the baseline model, considering only ex-ante factors (with imputation):* * It is important to note that these are in multivariable models. Thus, while the odds-ratio shifter for ‘Where live: Other’ is among the most positive, this does not imply that the most-engaged EA’s are necessarily in these other countries. We next present a forest plot of the coefficients from the baseline model, considering only ex-ante factors (with imputation). library(ggstatsplot) ( ol_engage_imp_tree &lt;- ol_engage_imp %&gt;% filter(!grepl(&quot;NA|Ageranges|year_involvegroups&quot;,term)) %&gt;% ggstatsplot::ggcoefstats(statistic=t, sort=&quot;ascending&quot;, stats.labels = &quot;TRUE&quot;, title = &quot;Engagement: ex-ante associated factors&quot;, subtitle = &quot;Ordered logit model, 95% CI&#39;s; NA ratios hidden&quot;, vline=FALSE) + ggplot2::labs( x= NULL, y = &quot;Characteristics (normalized)&quot; ) + geom_vline(xintercept=1, colour=&quot;grey&quot;) + geom_text(aes(x=1, label=&quot;Odds=1&quot;, y=10), colour=&quot;brown&quot;, angle=90, vjust = -.9) + scale_x_continuous(trans=&#39;log2&#39;, limits=c(0.25, 8)) ) %&gt;% ggplotly() Next, we present a similar forest plot of the model that includes some characteristics that may not be strictly ex-ante (model 2 in the first table): ( ol_engage_possible_endog_tree &lt;- ol_engage_possible_endog %&gt;% filter(!grepl(&quot;NA$&quot;,term)) %&gt;% ggcoefstats(statistic=t, sort=&quot;ascending&quot;, stats.labels = &quot;TRUE&quot;, title = &quot;Engagement: associated factors &quot;, subtitle = &quot;Ordered logit model, 95% CI&#39;s; Model &#39;(4) Possibly endogenous&#39;; NA ratios hidden&quot;, vline=FALSE) + ggplot2::labs( x= NULL, y = &quot;Characteristics (normalized)&quot; ) + geom_vline(xintercept=1, colour=&quot;grey&quot;) + geom_text(aes(x=1, label=&quot;Odds=1&quot;, y=12), colour=&quot;brown&quot;, angle=90, vjust = -.9) + scale_x_continuous(trans=&#39;log2&#39;, limits=c(0.25, 7.5)) ) %&gt;% ggplotly() Nonresponse: The table below presents the coefficients from a selection of the above models, on the ‘lack of a response to’ (i.e., skipping) certain questions. Finally the table below presents the coefficients (from a selection of the above models) on the ‘lack of a response to’ (i.e., skipping) certain questions. ( ol_engage_tbl_na &lt;- huxreg( &quot;(1) Baseline &quot; = ol_engage_imp_m, &quot;(2) Baseline - no imputation&quot; = ol_engage_noimp_m, &quot;(4) Possibly endogenous&quot; = ol_engage_possible_endog_m, &quot;(5) First-heard&quot; = ol_engage_fh_imp_m, tidy_args = list(conf.int = TRUE, prob = 0.95, exponentiate = TRUE), coefs = c(ol_na_pred), number_format = 2, statistics = c(&quot;N. obs.&quot; = &quot;nobs&quot;), error_pos = &quot;right&quot;, ci_level = .95, error_format = &quot;({conf.low}, {conf.high})&quot;) %&gt;% huxreg_opts %&gt;% set_caption(&quot;Engagement: Ordered logistic models &lt;br&gt; NA Odds-ratios; 95% CI&#39;s in parentheses&quot;) %&gt;% set_caption_pos(&quot;top&quot;) #%&gt;% head(-1) #get rid of missing p-value thing ) Table 3.1: Engagement: Ordered logistic models NA Odds-ratios; 95% CI's in parentheses (1) Baseline (2) Baseline - no imputation(4) Possibly endogenous(5) First-heard Gender: NA0.56(0.33, 0.97)0.58(0.31, 1.08)0.54(0.32, 0.94)0.57(0.33, 0.99) Employment status: NA0.90(0.47, 1.75)3.27(0.56, 21.35)0.90(0.47, 1.76)0.83(0.43, 1.60) Race: NA0.54(0.27, 1.08)0.52(0.20, 1.31)0.55(0.27, 1.11)0.54(0.27, 1.09) City: NA0.93(0.61, 1.41)0.77(0.49, 1.20)0.94(0.62, 1.44)1.00(0.66, 1.52) N. obs.1834.00&nbsp;&nbsp;&nbsp;&nbsp;1604.00&nbsp;&nbsp;&nbsp;&nbsp;1834.00&nbsp;&nbsp;&nbsp;&nbsp;1828.00&nbsp;&nbsp;&nbsp;&nbsp; *** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05. This nonresponse seems to largely be associated with less engagement, particularly for the race/ethnicity question. However, non-response to the ‘location’ question seems to be an exception, perhaps because the base group, USA-residence, tends to be lower-engagement. 3.5.3 Interpretation, robustness, further exploration Comparison across ordered logit models, adjusting variable choices and transformations We next present a series of similar (ordered logistic) models to delve more deeply into what is driving the above, and test robustness. ( ol_engage_tbl_m_compare &lt;- huxreg( &quot;(0) Naive&quot; = ol_engage_naive_m, &quot;(1) Baseline &quot; = ol_engage_imp_m, &quot;(1a) Baseline - no imputation&quot; = ol_engage_noimp_m, &quot;(1b) Larger groupings&quot; = ol_engage_imp_big_m, tidy_args = list(conf.int = TRUE, prob = 0.95, exponentiate =TRUE), coefs = c(ol_key_pred_n, names_big ), number_format = 2, statistics = c(&quot;N. obs.&quot; = &quot;nobs&quot;), error_pos = &quot;right&quot;, ci_level = .95, error_format = &quot;({conf.low}, {conf.high})&quot;) %&gt;% huxreg_opts %&gt;% set_col_width(c(1, rep(c(0.4, 0.4), times=4))) %&gt;% set_caption(&quot;Comparisons: Ordered logistic models &lt;br&gt; Odds-ratios; 95% CI&#39;s in parentheses; NA ratios hidden&quot;) %&gt;% set_caption_pos(&quot;top&quot;) %&gt;% head(-1) #get rid of missing p-value thing ) (#tab:ol_eng_compare) Comparisons: Ordered logistic models Odds-ratios; 95% CI's in parentheses; NA ratios hidden (0) Naive(1) Baseline (1a) Baseline - no imputation(1b) Larger groupings Age (2 sd norm.)0.42(0.34, 0.52)0.37(0.30, 0.46)0.36(0.28, 0.44)0.36(0.29, 0.45) Years involved (2 sd norm.)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4.46(3.66, 5.45)4.51(3.66, 5.58)4.48(3.68, 5.47) Gender - Female0.72(0.58, 0.88)0.80(0.65, 0.98)0.80(0.65, 0.99)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Gender - Other1.23(0.70, 2.16)1.04(0.58, 1.86)1.05(0.59, 1.89)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Student0.89(0.72, 1.09)1.30(1.05, 1.61)1.27(1.02, 1.58)1.28(1.04, 1.59) Not just white0.93(0.75, 1.16)0.99(0.79, 1.23)1.02(0.81, 1.28)1.03(0.83, 1.27) Live: Can/Aus/NZ0.71(0.52, 0.97)0.83(0.61, 1.13)0.86(0.62, 1.17)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Live: EEA not Anglo1.12(0.88, 1.41)1.26(0.99, 1.60)1.28(1.00, 1.63)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Live: Other1.28(0.90, 1.80)1.60(1.13, 2.27)1.56(1.08, 2.25)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Live: UK/IR1.46(1.10, 1.92)1.44(1.09, 1.92)1.44(1.08, 1.91)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Named big city1.77(1.45, 2.16)1.56(1.28, 1.92)1.60(1.30, 1.97)1.51(1.24, 1.83) Binary: Female (vs. non-female)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.79(0.64, 0.97) Binary: Not USA-based)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1.24(1.03, 1.50) N. obs.1834.00&nbsp;&nbsp;&nbsp;&nbsp;1834.00&nbsp;&nbsp;&nbsp;&nbsp;1604.00&nbsp;&nbsp;&nbsp;&nbsp;1834.00&nbsp;&nbsp;&nbsp;&nbsp; Column (0) presents a ‘naive’ model that does not control for time-in-EA. this model may be helpful as a description of the engagement levels of those currently in EA. However, it is confounded with differences that are driven by the changing nature of recruitment into the movement, as is not likely to be predictive (nor causal). Nonetheless, we mostly do not see strong differences from our baseline model, presented (again) in column (1). This does seeem to impact the odds-ratio for ‘Students.’ The naive model suggests students are less engaged, while the baseline model suggests they are engaged at about the same rate as others, given their (typically shorter) tenure in EA.* * The control for ‘years in EA’ also had a more substantial effect on the coefficients of the different ‘first-heard’ coefficients in column (3) of the previous table. Column (1a) repeats the base model, but dropping (rather than imputing) participants that did not respond to the age or ‘years involved’ questions (note the smaller number of observations). These results are very close to the base model.** ** We also ran a comparable model that dropped all cases with missing values for any of the variables in this mode. Again, the results (available by request) are largely similar. Column 1b adjusts the baseline model to use larger groupings. The results here suggest that those based in the USA are less engaged, controlling for other factors. (Other results are similar to previously-reported columns). These models are only able to “explain” a moderate share of the variation in engagement (but note we did not choose the models parameters to maximize this. The pseudo-r-sq for above models (Nagelkerke method) is 0.17 and 0.15 for the “(1) Baseline” and “(2) Baseline - no imputation,” respectively. The comparable statistic for most of the other models is close to that of model (1). Pseudo-r-sq for above models (Nagelkerke method): ol_engage_imp_m_nag_pr2 ## Nagelkerke ## 0.241454 ol_engage_noimp_m_nag_pr2 ## Nagelkerke ## 0.2180222 For the “(1) Baseline” and “(2) Baseline - no imputation,” respectively. The comparable statistic for most of the other models is close to that of model (1). Further controls for age/tenure We present a similar model to the ‘baseline model’ (not shown in above table) with a robust set of controls for age and tenure – in addition to the linear controls for age and tenure we include controls for five age-range groups and four time-in-ea-range groups. The graph below depicts the other coefficients in a model with these controls, lined up next to the previous graph.* The idea is ‘flexibly control for X1, when we care about estimating the impact of X2.’ We don’t know the relationship between X1 and Y, but I believe I need to ‘control for it.’ The better I can control for it the more accurate my measurement of the impact of X2, call the latter a B2 coefficient. The standard approaches include (i) ‘matching in neighborhoods of X1’ (ii) estimate a flexible functional form for x1 like a polynomial and (iii) Control for ranges of X1 as well as a linear control to mop up the rest. One reason to do iii and not ii is that ii can easily go wrong and become sensitive to a few outliers in a way that may mess things up. ( ol_engage_imp_r_tree &lt;- ol_engage_imp_r %&gt;% filter(!grepl(&quot;NA$|Age|involve|Involved&quot;,term)) %&gt;% ggcoefstats(statistic=t, sort=&quot;ascending&quot;, stats.labels = &quot;TRUE&quot;, title = &quot;Engagement: ex-ante associated factors, robust controls&quot;, subtitle = &quot;Ordered logit model, 95% CI&#39;s; NA ratios hidden&quot;, vline=FALSE) + ggplot2::labs( x= NULL, y = &quot;Characteristics (normalized)&quot; ) + geom_vline(xintercept=1, colour=&quot;grey&quot;) + geom_text(aes(x=1, label=&quot;Odds=1&quot;, y=4), colour=&quot;brown&quot;, angle=90, vjust = -.9) + scale_x_continuous(limits=c(0, 5.5)) ) %&gt;% ggplotly() ( engage_reg_v_robust &lt;- ggarrange(ol_engage_imp_tree, ol_engage_imp_r_tree, ncol = 1, nrow = 2, heights = c(1, 1), align = &quot;v&quot;, common.legend = TRUE, legend = &quot;bottom&quot;) ) The results (for variables other than age and tenure are nearly identical, suggesting that these findings are not particularly sensitive to the functional form used to control for age and time in EA.* * Recall: The USA is the base category for ‘where live,’ and ‘where live: other’ is outside Europe and Anglosphere, mainly Asia (top countries in this category: Israel, Singapore, China, Phillippines, Brazil, India, South Africa). It is important to note that these are in multivariable models. Thus, while the odds-ratio shifter for ‘Where live: Other’ is among the most positive, this does not imply that the most-engaged EA’s are necessarily in these other countries.** ** This is probably not driven by our use of an ordered logit model; the linear model of the standardized 1-5 engagement measure finds a similar positive shift. 3.5.3.1 Selection and differential attrition: focus on recent recruits We previously discussed how differential selection and attrition could drive the above models to suggest unwarranted predictions. We thus present a model isolating just those who say they became involved in 2019, 2018, or 2017. This includes most of ‘those with have been in EA less than the average duration.’ However it excludes those who joined in the survey year itself (2020), as those in their first year may be less able to gage their own engagment. We might suppose that the differential selection is less substantial over this shorter range of tenure. We might also imagine that patterns among ‘newer recruits’ are likely to be more reflective of future patterns. If so, the results below might be more predictive of engagement levels, and more useful for our ‘policy choices.’ newby_eas_20_s_imp &lt;- eas_20_s_imp %&gt;% filter(years_involved_d2sd &lt; -0.001 &amp; years_involved_d2sd &gt; -0.5) %&gt;% #this captures people involved in 2018-2020 mutate(year_involved = case_when( #recovering year_involved from trnasformed variable years_involved_d2sd &lt; -.3 ~ &quot;2019&quot;, years_involved_d2sd &gt; -.3 &amp; years_involved_d2sd &lt; -.1 ~ &quot;2018&quot;, years_involved_d2sd &gt; -.1 ~ &quot;2017&quot; ), USA = where_live_cat==&quot;USA&quot; ) older_eas_20_s_imp &lt;- eas_20_s_imp %&gt;% filter(year_involved_groups == &quot;2014 or before&quot; | year_involved_groups == &quot;2015-16&quot;) %&gt;% #this captures people involved in 2018-2020 mutate( USA = where_live_cat==&quot;USA&quot; ) newby_ol_engage_imp &lt;- newby_eas_20_s_imp %&gt;% ol_mdl(c(key_predictors, &quot;years_involved_d2sd&quot;)) older_ol_engage_imp &lt;- older_eas_20_s_imp %&gt;% ol_mdl(c(key_predictors, &quot;years_involved_d2sd&quot;)) newby_ol_engage_possible_endog &lt;- newby_eas_20_s_imp %&gt;% ol_mdl(c(key_predictors, &quot;year_involved&quot;, possible_endog)) newby_ol_engage_possible_endog_USA &lt;- newby_eas_20_s_imp %&gt;% ol_mdl(c(&quot;age_approx_d2sd&quot;,&quot;gender_cat&quot;,&quot;student_cat&quot;, &quot;race_cat&quot;,&quot;USA&quot;, &quot;city_cat&quot;, &quot;year_involved&quot;, possible_endog)) fh_imp_n &lt;- newby_eas_20_s_imp %&gt;% smn(&quot;first_hear&quot;) newby_ol_engage_fh_imp &lt;- newby_eas_20_s_imp %&gt;% ol_mdl(c(key_predictors, &quot;year_involved&quot;, fh_imp_n)) These models involve only 773 responses. As we are only considering three such tenure durations, we include a dummy for each ‘year first involved.’ Given the short tenure, we also do not anticipate that income or university rank could be particularly affected by EA engagement at this point; thus we focus on the larger set of features. ( newby_ol_engage_possible_endog_tree &lt;- newby_ol_engage_possible_endog %&gt;% filter(!grepl(&quot;NA$&quot;,term)) %&gt;% ggcoefstats(statistic=t, sort=&quot;ascending&quot;, stats.labels = &quot;TRUE&quot;, title = &quot;Engagement of those involved in 2017-19: associated factors &quot;, subtitle = &quot;Ordered logit, 95% CI&#39;s; &#39;Possibly endogenous features&#39;; NA ratios hidden&quot;, vline=FALSE) + ggplot2::labs( x= NULL, y = &quot;Characteristics (normalized)&quot; ) + geom_vline(xintercept=1, colour=&quot;grey&quot;) + geom_text(aes(x=1, label=&quot;Odds=1&quot;, y=12), colour=&quot;brown&quot;, angle=90, vjust = -.9) + scale_x_continuous(limits=c(0, 4)) ) %&gt;% ggplotly Making inferences from the above graph, we see greater self-reported engagement among:* * As some of the confidence intervals for these odds ratios cross the threshold of unit (even) odds, these are not all statistically significant in a conventional sense. Nonetheless, one might reasonably update beliefs in this direction. Those located in a (named) big city UK and Ireland (and less so, the EEA) Non-‘western’ countries Those who attended high-ranked universities Students Younger people (the negative of “Age”) (The above list is reported in approximate order of the magnitudes of these odds, also considering the tightness of the confidence bounds.) We see less engagement for living in Canada, Australia, or New Zealand. (The base group, the USA is marginally less engaged; see other models). Comparing a simpler model for those involved from 2017-2019 to a separate model for those involved in earlier years (both of these models use the linear time-in-EA control and the smaller, ex-ante set of variables): ( newby_ol_engage_imp_tree &lt;- newby_ol_engage_imp %&gt;% filter(!grepl(&quot;NA$|Age|involve|Involved&quot;,term)) %&gt;% ggcoefstats(statistic=t, sort=&quot;ascending&quot;, stats.labels = &quot;TRUE&quot;, title = &quot;Engagement of those involved in 2017-19: associated factors &quot;, subtitle = &quot;Ordered logit, 95% CI&#39;s; &#39;Ex-ante features&#39;; NA ratios &amp; age &amp; tenure controls hidden&quot;, vline=FALSE) + ggplot2::labs( x= NULL, y = &quot;Characteristics (normalized)&quot; ) + geom_vline(xintercept=1, colour=&quot;grey&quot;) + geom_text(aes(x=1, label=&quot;Odds=1&quot;, y=5), colour=&quot;brown&quot;, angle=90, vjust = -.9) + scale_x_continuous(limits=c(0, 4.75)) ) %&gt;% ggplotly ( older_ol_engage_imp_tree &lt;- older_ol_engage_imp %&gt;% filter(!grepl(&quot;NA$|Age|involve|Involved&quot;,term)) %&gt;% ggcoefstats(statistic=t, sort=&quot;ascending&quot;, stats.labels = &quot;TRUE&quot;, title = &quot;Engagement of those involved before 2017...&quot;, vline=FALSE) + ggplot2::labs( x= NULL, y = &quot;Characteristics (normalized)&quot; ) + geom_vline(xintercept=1, colour=&quot;grey&quot;) + geom_text(aes(x=1, label=&quot;Odds=1&quot;, y=5), colour=&quot;brown&quot;, angle=90, vjust = -.9) + scale_x_continuous(limits=c(0, 4.75)) ) %&gt;% ggplotly() ( engage_newby_v_older &lt;- ggarrange(newby_ol_engage_imp_tree, older_ol_engage_imp_tree, ncol = 1, nrow = 2, heights = c(1, 1), align = &quot;v&quot;, common.legend = TRUE, legend = &quot;bottom&quot;) ) Although the confidence intervals are rather wide, especially for the longer tenure group, it looks fairly constant. The only major visual difference is that Can/Aus/NZ is ‘positive’ for those who joined in the earlier years (and persisted) and ‘negative’ for recent joiners. But again, this could be driven by differential selection. Linear models (of levels and binary) To consider the previous results’ sensitivity to functional form, we resent linear models considering: self-reported engagement (engagement_num =1-5) as if it were a meaningful cardinal outcome, and also the binary ‘highly engaged’ self-reported outcome of (‘4-5 engagement’ vs ‘1-3 engagement’) #satis_ologit_t0 \\&lt;- eas_20 %\\&gt;% polr(m_f(sat_outcome, t0_satis_vars), data = ., Hess=TRUE) %\\&gt;% #OK my &#39;coefficients as deviations&#39; is not working. Back to the old crappy treatment coding with base groups as modal group in each case #todo: get this to run with a *list* and with purrr, then easy switch to ologit options(contrasts = rep(&quot;contr.treatment&quot;, 2)) #options(contrasts = rep (&quot;contr.sum&quot;, 2)) lm_mdl &lt;- function(df, rhs) { lm( m_f(num_out, {{rhs}}), data = df ) %&gt;% lmtest::coeftest(vcov. = sandwich::vcovHC) } ##Fix this -- its inheriting from outside the environment lm_engage_naive &lt;- eas_20_s_imp %&gt;% lm_mdl(c(key_predictors)) #lm(m_f(num_out, c(&quot;0&quot;, key_predictors)), data = .) %&gt;% #lm(engagement_norm ~ 0 + gender_cat + city_cat, data = .) %&gt;% lm_engage_noimp &lt;- eas_20_s %&gt;% lm_mdl(c(key_predictors, controls)) lm_engage_imp_big &lt;- eas_20_s_imp %&gt;% lm(m_f(num_out, c(big_demog, controls)), data = .) %&gt;% lmtest::coeftest(vcov = sandwich::vcovHC) lm_engage_imp &lt;- eas_20_s_imp %&gt;% lm_mdl(c(key_predictors, controls)) lm_engage_possible_endog &lt;- eas_20_s_imp %&gt;% lm_mdl(c(key_predictors, controls, possible_endog)) fh_imp_n &lt;- eas_20_s_imp %&gt;% smn(&quot;first_hear&quot;) lm_engage_fh_imp &lt;- eas_20_s_imp %&gt;% lm_mdl(c(key_predictors, controls, fh_imp_n)) key_pred_n_cat &lt;- grep(&quot;first_hear_ea_lump|Intercept|NA|d2sd&quot;, names(coef(lm_engage_fh_imp)), value = TRUE, invert=TRUE) na_pred &lt;- grep(&quot;NA|Intercept&quot;, names(coef(lm_engage_fh_imp)), value = TRUE) key_pred_n_ctn &lt;- grep(&quot;d2sd&quot;, names(coef(lm_engage_fh_imp)), value = TRUE) key_pred_n&lt;- c(key_pred_n_ctn, key_pred_n_cat) names(key_pred_n) &lt;- gsub(&quot;d_live&quot;, &quot;Live:&quot;, key_pred_n) %&gt;% gsub(&quot;age_approx_d2sd&quot;, &quot;Age (2sd norm)&quot;, .) %&gt;% gsub(&quot;d2sd&quot;, &quot; (norm)&quot;, .) %&gt;% gsub(&quot;cat&quot;, &quot;- &quot;, .) %&gt;% #gsub(&quot;canzaus&quot;, &quot;Aus///Can///NZ&quot;, .) %&gt;% #gsub(&quot;d_&quot;, &quot;&quot;, .) %&gt;% gsub(&quot;_&quot;, &quot; &quot;, .) %&gt;% firstup(.) fh_n &lt;- grep(&quot;first_hear_ea_lump&quot;, names(coef(lm_engage_fh_imp)), value = TRUE) names(fh_n) &lt;- gsub(&quot;first_hear_ea_lump&quot;, &quot;First-heard: &quot;, fh_n) %&gt;% gsub(&quot;X80&quot;, &quot;80&quot;, .) huxreg_opts &lt;- function(df) { df %&gt;% set_bold(1, everywhere) %&gt;% set_bottom_border(1, everywhere) %&gt;% map_background_color(by_rows(&quot;grey87&quot;, &quot;white&quot;)) %&gt;% set_caption_pos(&quot;bottom&quot;) } ( lm_engage_tbl &lt;- huxreg( &quot;(0) Naive&quot; = lm_engage_naive, &quot;(1) Baseline &quot; = lm_engage_imp, &quot;(2) Baseline - no imputation&quot; = lm_engage_noimp, &quot;(3) Possibly endogenous&quot; = lm_engage_possible_endog, &quot;(3) First-heard&quot; = lm_engage_fh_imp, statistics = c(&quot;N. obs.&quot; = &quot;nobs&quot;), error_pos = &quot;right&quot;, coefs = c(key_pred_n, # note intercept was removed above &quot;Income (norm)&quot;= &quot;income_d2sd&quot;, &quot;Employed: Part-Time&quot; = &quot;d_pt_employment&quot;, &quot;Not Employed&quot; = &quot;d_not_employed&quot;, &quot;Retired&quot; = &quot;d_retired&quot;, fh_n)) %&gt;% huxreg_opts %&gt;% set_col_width(c(.5, rep(.2, times=length(.)-1))) ) Table 3.2: (0) Naive(1) Baseline (2) Baseline - no imputation(3) Possibly endogenous(3) First-heard Age (2sd norm)-0.435 ***(0.056)-0.461 ***(0.052)-0.467 ***(0.052)-0.455 ***(0.063)-0.463 ***(0.052) Years involved (norm)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.702 ***(0.046)0.703 ***(0.047)0.696 ***(0.047)0.696 ***(0.049) Gender - Female-0.173 **&nbsp;(0.055)-0.100&nbsp;&nbsp;&nbsp;&nbsp;(0.051)-0.097&nbsp;&nbsp;&nbsp;&nbsp;(0.052)-0.103 *&nbsp;&nbsp;(0.052)-0.148 **&nbsp;(0.052) Gender - Other0.095&nbsp;&nbsp;&nbsp;&nbsp;(0.151)0.020&nbsp;&nbsp;&nbsp;&nbsp;(0.145)0.024&nbsp;&nbsp;&nbsp;&nbsp;(0.146)0.006&nbsp;&nbsp;&nbsp;&nbsp;(0.144)-0.015&nbsp;&nbsp;&nbsp;&nbsp;(0.144) Student - Student-0.052&nbsp;&nbsp;&nbsp;&nbsp;(0.054)0.130 *&nbsp;&nbsp;(0.051)0.117 *&nbsp;&nbsp;(0.052)0.141 *&nbsp;&nbsp;(0.055)0.108 *&nbsp;&nbsp;(0.052) Race - Not just white-0.033&nbsp;&nbsp;&nbsp;&nbsp;(0.058)0.010&nbsp;&nbsp;&nbsp;&nbsp;(0.055)0.023&nbsp;&nbsp;&nbsp;&nbsp;(0.056)0.002&nbsp;&nbsp;&nbsp;&nbsp;(0.056)0.013&nbsp;&nbsp;&nbsp;&nbsp;(0.056) Where live - Can/Aus/NZ-0.178 *&nbsp;&nbsp;(0.084)-0.097&nbsp;&nbsp;&nbsp;&nbsp;(0.078)-0.081&nbsp;&nbsp;&nbsp;&nbsp;(0.079)-0.108&nbsp;&nbsp;&nbsp;&nbsp;(0.078)-0.093&nbsp;&nbsp;&nbsp;&nbsp;(0.079) Where live - EEA not Anglo0.052&nbsp;&nbsp;&nbsp;&nbsp;(0.063)0.103&nbsp;&nbsp;&nbsp;&nbsp;(0.059)0.108&nbsp;&nbsp;&nbsp;&nbsp;(0.060)0.103&nbsp;&nbsp;&nbsp;&nbsp;(0.060)0.079&nbsp;&nbsp;&nbsp;&nbsp;(0.060) Where live - Other0.123&nbsp;&nbsp;&nbsp;&nbsp;(0.091)0.236 **&nbsp;(0.086)0.223 *&nbsp;&nbsp;(0.090)0.238 **&nbsp;(0.086)0.207 *&nbsp;&nbsp;(0.087) Where live - UK/IR0.169 *&nbsp;&nbsp;(0.072)0.157 *&nbsp;&nbsp;(0.067)0.154 *&nbsp;&nbsp;(0.067)0.140 *&nbsp;&nbsp;(0.069)0.142 *&nbsp;&nbsp;(0.069) City - Named big city0.295 ***(0.052)0.220 ***(0.049)0.227 ***(0.050)0.215 ***(0.050)0.207 ***(0.049) Income (norm)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-0.018&nbsp;&nbsp;&nbsp;&nbsp;(0.070)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Employed: Part-Time&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.025&nbsp;&nbsp;&nbsp;&nbsp;(0.101)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Not Employed&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.185&nbsp;&nbsp;&nbsp;&nbsp;(0.108)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Retired&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-0.003&nbsp;&nbsp;&nbsp;&nbsp;(0.147)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; First-heard: 80,000 Hours&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-0.135&nbsp;&nbsp;&nbsp;&nbsp;(0.077) First-heard: Book, article, or blog post&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.042&nbsp;&nbsp;&nbsp;&nbsp;(0.078) First-heard: Educational course&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.246&nbsp;&nbsp;&nbsp;&nbsp;(0.173) First-heard: GiveWell&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.060&nbsp;&nbsp;&nbsp;&nbsp;(0.153) First-heard: Giving What We Can&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-0.198&nbsp;&nbsp;&nbsp;&nbsp;(0.178) First-heard: LessWrong&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-0.103&nbsp;&nbsp;&nbsp;&nbsp;(0.085) First-heard: Local or university EA group&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.077&nbsp;&nbsp;&nbsp;&nbsp;(0.081) First-heard: Personal contact&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.082&nbsp;&nbsp;&nbsp;&nbsp;(0.068) First-heard: Podcast&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-0.069&nbsp;&nbsp;&nbsp;&nbsp;(0.085) First-heard: Slate Star Codex&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-0.366 ***(0.105) First-heard: TED talk&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.092&nbsp;&nbsp;&nbsp;&nbsp;(0.103) N. obs.1834&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1834&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1604&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1834&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1828&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; *** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05. ( lm_engage_tbl_na &lt;- huxreg( &quot;(0) Naive&quot; = lm_engage_naive, &quot;(1) Baseline &quot; = lm_engage_imp, &quot;(2) Baseline - no imputation&quot; = lm_engage_noimp, &quot;(3) Possibly endogenous&quot; = lm_engage_possible_endog, &quot;(3) First-heard&quot; = lm_engage_fh_imp, statistics = c(&quot;N. obs.&quot; = &quot;nobs&quot;), error_pos = &quot;right&quot;, coefs = c(&quot;(Intercept)&quot;, na_pred)) %&gt;% huxreg_opts %&gt;% set_col_width(c(.5, rep(.2, times=length(.)-1))) ) Table 3.2: (0) Naive(1) Baseline (2) Baseline - no imputation(3) Possibly endogenous(3) First-heard (Intercept)0.002&nbsp;&nbsp;(0.056)-0.096&nbsp;&nbsp;(0.053)-0.097(0.054)-0.102&nbsp;&nbsp;(0.056)-0.044(0.066) gender_catNA-0.153&nbsp;&nbsp;(0.152)-0.279 *(0.142)-0.248(0.169)-0.291 *(0.142)-0.263(0.140) student_catNA-0.119&nbsp;&nbsp;(0.193)0.013&nbsp;&nbsp;(0.173)0.719(0.525)0.014&nbsp;&nbsp;(0.175)-0.018(0.171) race_catNA-0.410 *(0.195)-0.285&nbsp;&nbsp;(0.181)-0.269(0.252)-0.276&nbsp;&nbsp;(0.181)-0.282(0.180) city_catNA-0.048&nbsp;&nbsp;(0.120)-0.107&nbsp;&nbsp;(0.114)-0.189(0.124)-0.101&nbsp;&nbsp;(0.115)-0.080(0.115) N. obs.1834&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1834&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1604&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1834&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1828&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; *** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05. Trying to automate the above lm_mdl &lt;- function(df, mod) { lm( m_f(num_out, {{rhs}}), data = df ) %&gt;% coeftest(vcov = sandwich::vcovHC) } eng_models_list &lt;- list( lm_engage_naive = &#39;m_f(num_out, c(key_predictors)&#39;, lm_engage_imp = &#39;m_f(num_out, c(big_demog, &quot;uni_higher_rank_d2sd&quot;, controls)&#39; ) eng_model_frame &lt;- tibble(model = eng_models_list) %&gt;% mutate(model_name = names(model)) %&gt;% mutate(model_name = names(model)) eng_model_frame &lt;- eng_model_frame %&gt;% mutate(fit = map(eng_model_frame, ~lm(., data = eas_20_s_imp) %&gt;% coeftest(vcov = sandwich::vcovHC) ) ) Notes: As in the Ordered Logit models, nonresponses for each response are included as separate categories. All “NA” coefficients are hidden. The outcome variable is standardized (de-meaned and divided by one SD). Continuous variables (income, age, university rank) are de-meaned and divided by two standard-deviations. (This is for comparability to dummy-coded categorical variables, see Gelman [ref]) . Where these are missing they are coded as zero, the mean of the transformed variable (except in the “no imputation” column, where these are left out of the regression, leading to a smaller sample size.) Base groups are set as the most numerous group in each category. All dummy coefficients represent adjustments from the ‘overall base group’: an individual who is Male, Works full-time, ‘Just White’ ethnicity, USA-based, not based in a (survey-named) big city, First heard of EA: ‘Other or don’t remember.’ 3.6 Engagement: age, tenure, period and cohort effects We examine the relationship between the year when people first got involved in EA (which tells us how long they’ve been in EA or their ‘tenure’), their current age and the age they were when they first got involved in EA. See also “Tenure and ‘age first heard’ vs engagement” in demography chapter/post. Aspirationally: We would like to separate cohort, trend, and age effects here; we will have more possibility to do this if we combine data from earlier years. “Engagement by years since joining, controlling for year and age” “Engagement by year, controlling for years since joining and age”… 3.6.1 Engagement by tenure/age: ‘prediction for “outreach at what age?”’ A major concern might be: ‘What is the optimal age to reach out to EA’s?’ In a best-case we’d want to estimate the function (not ‘customer lifetime value’ but…) ‘effective lifetime value’ (\\(ELV\\)) as a function of ‘age first heard of EA’ (\\(afh\\)), and everything else (\\(X\\)): \\[ELV = f(AFH, X)\\] and look for the values of AFH that maximizes this, perhaps averaging over the ‘everything else’ stuff. Of course, we don’t know ELV, and it would take a great effort (as well as controversial assumptions) to construct this: More simply, we could plot: Engagement at age \\(A\\) as a function of age-first-heard (AFH): This would combine both Tenure effects, as those who started younger have been in longer and unfortunately, differentially attrited, adding a possible bias, and Receptiveness-at-age effects (e.g., earlier inculcation is stronger) Selection-at-age effects (e.g., those who we tend to recruit younger might be more engage-prone) Engagement \\(T\\) years after first-heard as a function of AFH, combining Receptiveness-at-age effects (e.g., earlier inculcation is stronger) standard life-cycle age effects selection-at-age effects Simple ‘engagement level by age’ roughly capturing the life-cycle age effects but combining a variety of effects, including, e.g., ‘younger people might be more active,’ and ‘young people tend to have been in EA for less time’ 3.6.2 Engagement by age and tenure Below, we plot the ‘engagement level by age’ for the 2020 survey data… #aet &lt;- eas_20 %&gt;% ungroup() %&gt;% dplyr::select(age_approx_ranges, engagement_num, tenure) #p_load(scatterplot3d) #scatterplot3d(eas_20$engagement, eas_20$age_approx, eas_20$tenure, highlight.3d=TRUE, col.axis=&quot;blue&quot;, col.grid=&quot;lightblue&quot;, main=&quot;scatterplot3d - 1&quot;, pch=20) #ggExtra to add densities ( engage_by_age &lt;- eas_20 %&gt;% ggplot() + aes(x = age_approx, y = engagement_num) + geom_point(size = 0.30, colour = &quot;#0c4c8a&quot;, position = position_jitter(seed = 42, width = 0.1, height = 0.2)) + geom_smooth(span = 0.71) + scatter_theme + xlim(10L, 75L) + labs(y = get_label(eas_20$engagement_num), x = get_label(eas_20$age_approx))+ labs(title = &quot;Engagement (2020) by age&quot;) ) %&gt;% ggplotly() Looking at the average level of engagement of EAs of different ages, we observe a non-linear trend, with engagement flat or slightly increasing until the mid-to-late 20s and then declining. However, this should be expected to be strongly confounded with time-in-EA (or ‘tenure’), as EAs who have been in longer might be expected to be both older and more engaged than those who have joined EA more recently. (And age, being tied to year-first-involved, may also reflect differences in the cohorts introduced to EA).) Noting this, we plot tenure against age below: ( tenure_by_age &lt;- eas_20 %&gt;% ggplot() + aes(x = age_approx, y = tenure) + geom_point(size = 0.30, colour = &quot;#0c4c8a&quot;, position = position_jitter(seed = 42, width = 0.1, height = 0.2)) + geom_smooth(span = 0.71) + scatter_theme + xlim(10L, 75L) + labs(y = get_label(eas_20$tenure), x = get_label(eas_20$age_approx)) + labs(title = &quot;Tenure by age (2020)&quot;) ) %&gt;% ggplotly() Indeed, tenure seems to increase steeply in age for ages below about 30. This could occur mechanically from an age-barrier to being introduced to EA; perhaps most people are not introduced to it until university. Engagement by Age, ‘faceted’ by tenure (time in EA): We also plot the relationship between age and average engagement for different groups of cohorts (0-1, 1-2, 2-3, 3-5 and 5-11 years in EA). Here we still see a pattern of average engagement sharply increasing and then declining with increasing age. However, for each successively earlier set of cohorts (i.e. people who have been in EA longer), the peak age for engagement is commensurately older. label_x &lt;- function(p) { b &lt;- ggplot_build(p) x &lt;- b$plot$data[[b$plot$labels$x]] p + scale_x_continuous( attributes(x)$label, breaks = attributes(x)$labels, labels = names(attributes(x)$labels) ) } ( engagement_by_age_facet_tenure &lt;- eas_20 %&gt;% ggplot() + aes(x = age_approx, y = engagement_num) + geom_point(size = 0.20, colour = &quot;#0c4c8a&quot;, position = position_jitter(seed = 42, width = 0.1, height = 0.2)) + geom_smooth(span = 0.71) + scatter_theme + facet_grid(vars(), vars(tenure_ranges)) + xlim(10L, 75L) + ylim(0, 5.5) + labs(title = &quot;Engagement by age&quot;, subtitle = &quot;Faceted by time in EA&quot;) + labs(y = get_label(eas_20$engagement_num), x = get_label(eas_20$age_approx)) ) %&gt;% ggplotly() Engagement appears to decrease in age for all tenure ranges. The peak of engagement is around 20-years-old. However, this apparent ‘peak’ at age 20 may be illusory. Further data and modeling are needed (see note). It might be that the age-20 thing is a ‘real peak’ (i.e., that people age 20 are more active than people age 18). But the CI’s are wide in the faceted data. To get a more precise estimate of ‘age 18’ vs ‘age 20’ (holding tenure constant) we need to look more carefully, within a model with, e.g., a linear tenure term Even within the tenure facets, there are variations in tenure, which may be driving the ‘bump at the beginning’ … those who are older still tend to have more tenure. (Also remember that this could be driven by a persistence/selection effect). Engagement by tenure: ( engagement_by_tenure_overall &lt;- eas_20 %&gt;% ggplot() + aes(x = tenure, y = engagement_num) + geom_point(size = 0.30, colour = &quot;#0c4c8a&quot;, position = position_jitter(seed = 42, width = 0.1, height = 0.2)) + geom_smooth(span = 0.75) + scatter_theme + labs(title = &quot;Engagement by time in EA&quot;) + labs(y = get_label(eas_20$tenure), x = get_label(eas_20$engagement_num)) ) %&gt;% ggplotly() Engagement by tenure, ‘faceted’ by age groupings: ( engagement_by_tenure_facet_age &lt;- eas_20 %&gt;% ggplot() + aes(x = tenure, y = engagement_num) + geom_point(size = 0.30, colour = &quot;#0c4c8a&quot;, position = position_jitter(seed = 42, width = 0.1, height = 0.2)) + geom_smooth(span = 0.75) + scatter_theme + facet_grid(vars(), vars(age_approx_ranges), scales = &quot;free&quot;) + labs(title = &quot;Engagement by time in EA&quot;, subtitle = &quot;Faceted by Age&quot;) + labs(y = get_label(eas_20$engagement_num), x = get_label(eas_20$tenure)) ) %&gt;% ggplotly Engagement appears to increase in tenure for all age range (the ‘dip’ for the 26-29 age range has very wide confidence intervals and appears driven by a few observations). The slope appears particular positive in the first few years. However, given that this is recall data (2020 retrospective only), we cannot rule out that this is driven by a selectivity effect (only those who are engaged choose to persist). We plot this again on a single graph: (engage_age_group_tenure &lt;- eas_20 %&gt;% ggplot() + aes(x = age_approx, y = engagement_num, colour = tenure_ranges, group = tenure_ranges) + geom_point(size = 0.20, colour = &quot;#0c4c8a&quot;, position = position_jitter(seed = 42, width = 0.1, height = 0.2)) + geom_smooth(span = 0.71, se=F) + scatter_theme + xlim(15L, 75L) + ylim(0, 5.5) + labs(title = &quot;Engagement by age, grouped by tenure:&quot;) ) %&gt;% ggplotly 3.6.3 Engagement by ‘Age-first-involved’ and tenure Below, we also depict each of the above graphs in terms of ‘age-first-involved’ (AFI) and tenure. Note again that, as we are only using 2020 recall data here, \\(tenure = 2020 - year\\_first\\_involved\\). Thus, this simply implies a re-labeling and a shifting, as seen below. ( engage_by_age_first_involved &lt;- eas_20 %&gt;% ggplot() + aes(x = age_first_inv, y = engagement_num) + geom_point(size = 0.20, colour = &quot;#0c4c8a&quot;, position = position_jitter(seed = 42, width = 0.1, height = 0.2)) + geom_smooth(span = 0.71) + theme_minimal() + xlim(10L, 75L) + labs(title = &quot;Engagement by age first involved&quot;) ) %&gt;% ggplotly require(&quot;ggpubr&quot;) ( figure &lt;- ggarrange(engage_by_age_first_involved, engage_by_age, ncol = 2, nrow = 1, heights = c(1, 1), align = &quot;v&quot;, common.legend = TRUE, legend = &quot;bottom&quot;) ) Engagement by age first involved, faceted by tenure: ( engagement_by_afi_facet_tenure &lt;- eas_20 %&gt;% ggplot() + aes(x = age_first_inv, y = engagement_num) + geom_point(size = 0.20, colour = &quot;#0c4c8a&quot;, position = position_jitter(seed = 42, width = 0.1, height = 0.2)) + geom_smooth(span = 0.71) + scatter_theme + facet_grid(vars(), vars(tenure_ranges)) + xlim(10L, 75L) + ylim(0, 5.5) + labs(title = &quot;Engagement by age first involved, faceted by tenure&quot;, subtitle = &quot;Faceted by time in EA&quot;) + labs(y = get_label(eas_20$engagement_num), x = get_label(eas_20$age_first_inv)) ) ( engage_afi_vs_age_facet_tenure &lt;- ggarrange(engagement_by_afi_facet_tenure, engagement_by_age_facet_tenure, ncol = 1, nrow = 2, heights = c(1, 1), align = &quot;v&quot;, common.legend = TRUE, legend = &quot;bottom&quot;) ) Note that above, these are simply shifted versions of the same graphs.* * I prefer the bottom graph, as I suspect that that ‘age’ is the more important thing to emphasise. I suspect that, holding tenure constant… … life-cycle-age: “I’m now 20, so I can be active vs. I’m 35 and I have a mortgage and 4 kids” plays a greater effect than “receptivity at the age when I joined EA” (‘I got involved at 20 when I was impressionable’) Next, the ‘effect’ of tenure, faceted by age first involved (vs. age) engagement_by_tenure_facet_afi &lt;- eas_20 %&gt;% ggplot() + aes(x = tenure, y = engagement_num) + geom_point(size = 0.30, colour = &quot;#0c4c8a&quot;, position = position_jitter(seed = 42, width = 0.1, height = 0.2)) + geom_smooth(span = 0.75) + ggthemes::theme_solarized_2() + facet_grid(vars(), vars(age_first_inv_ranges), scales = &quot;free&quot;) + labs(title = &quot;Engagement by tenure, faceted by age-first-involved&quot;) ( engagement_by_tenure_facet_afi_vs_age &lt;- ggarrange(engagement_by_tenure_facet_afi, engagement_by_tenure_facet_age, ncol = 1, nrow = 2, heights = c(1, 1), align = &quot;v&quot;, common.legend = TRUE, legend = &quot;bottom&quot;) ) The above graphs differ only slightly, as the definition of the quantiles used for faceting are slightly different. Finally, the analogue to the grouped (single-graph) plots: engage_afi_group_tenure &lt;- eas_20 %&gt;% ggplot() + aes(x = age_first_inv, y = engagement_num, colour = tenure_ranges, group = tenure_ranges) + geom_point(size = 0.20, colour = &quot;#0c4c8a&quot;, position = position_jitter(seed = 42, width = 0.1, height = 0.2)) + geom_smooth(span = 0.71, se=F) + theme_minimal() + xlim(15L, 75L) + ylim(0, 5.5) + labs(title = &quot;Engagement by age-first-involved, grouped by tenure:&quot;) ( engage_afi_vs_age_group_tenure &lt;- ggarrange(engage_afi_group_tenure, engage_age_group_tenure, ncol = 2, nrow = 1, heights = c(1, 1), align = &quot;h&quot;, legend = &quot;bottom&quot;) ) The above graphs are nearly identical but for the slight shift in the x-axis, and the inclusion of the NA tenure-range category (we cannot infer age-first-involved where individual’s did not answer this question).* * There also seem to be some very small differences in the shape of the smoothed plots; this might result from a quirk in the smoothing algorithm, or some rounding issue, I am not sure. 3.6.4 See also: Attrition from EA/EA survey by introducer 3.7 Additional – CEA request: cities/areas by group engagement and retention, adapted: ( retain_engage_by_area &lt;- eas_20 %&gt;% mutate( city = as.character(city), country = as.character(country), cea_region_selection = case_when( str_detect(city, &quot;London|New York|SF Bay|DC&quot;) ~ city, str_detect(country, &quot;Netherlands|Germany&quot;) ~ country, TRUE ~ &quot;Other&quot;, ), group_made_more_engaged = as.numeric(engaged_local_groups==&quot;Made me a lot more likely to stay engaged&quot;|engaged_local_groups==&quot;Made me more likely to stay engaged&quot;) ) %&gt;% filter(!is.na(engaged_local_groups)) %&gt;% ggplot() + aes(x = reorder(cea_region_selection, group_made_more_engaged) ) + geom_bar(aes(fill=engaged_local_groups), position=&quot;fill&quot;) + stat_summary(aes(y = group_made_more_engaged), fun.data = mean_cl_normal, na.rm = TRUE, geom = &quot;errorbar&quot;, colour = &quot;white&quot;, width = 0.35) + stat_summary(aes(y = group_made_more_engaged), fun.data = mean_cl_normal, na.rm = TRUE, geom = &quot;errorbar&quot;, colour = &quot;brown&quot;, width = 0.35, fun.args = list(mult = 1)) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + labs(title = &quot;&#39;Impact of groups on engagement&#39; by select areas&quot;, x=&quot;City/country&quot;, y=&quot;share&quot;, caption = &quot;95% CI bars for &#39;Made more/ a lot more likely&#39; in white, 1 SE in brown&quot;) + coord_flip(ylim = c(0, 1)) ) Above, for a select list requested by CEA. Note that this excludes some larger cities and countries. The above should be treated cautiously. There are several other things wrong with the inferences one might draw from this analysis. Differential selection (e.g., one city’s EA group is very insular and exclusive, so only those who are really in the clique join it and report high levels) Differential baseline characteristics of EA’s in different cities 3.8 Conclusions and Future work This post has presented a descriptive picture of the ways EAs engage, how they rate their own engagement, and how these relate to other attitudes and observable characteristics. This broadly aids our understanding of “what engagement in the EA movement looks like” and “who/what/where” EA’s engage. Summarizing some of our findings (unfold) Self-reported engagement is strongly associated with membership in EA groups and with taking more EA-relevant actions, arguing for the validity of this measure ‘Engagement tends to decrease in age after age-20 but increase with time-in-EA’ People reporting that they ‘first heard of EA’ from certain sources (such as “Educational Courses, and Personal Contact” tend to have higher engagement than average, even after controlling for factors like age and time-in-EA Those living in the (named) big cities, as well as certain geographic regions tend to have higher engagement than average, even after controlling for other factors However, given our retrospective data, many of these differences could reflect differential attrition processes between groups, as discussed above. In addition to description, we are also interested in more ambitious predictive and even causal modeling of engagement for several reasons. As discussed in the supplement [LINK], we may care about (i) Outreach, (ii) Planning, and (iii) Policy. Key questions include Which types of people are more or less likely to become engaged in EA, and how does this inform EA organizations’ optimal outreach strategies, if at all? What approaches lead people to become more involved in EA? How large is the EA movement likely to grow over time, and what levels (and types) of engagement  can predict this? This could inform our plans for building infrastructure, as well as our impact strategies and approaches.  We suspect that more in-depth analysis of these issues is warranted, and we hope to pursue this going forward. For example:,  We are working to bring together the EA survey data across years, allowing us to separate “time in EA” from “year joined EA,” and perform “Age-Period-Cohort” analysis. Considering “movement growth”: We hope to combine this with medium-term prediction models explicitly quantifying our uncertainty into probabilistic forecasts of key outcomes. We aim to build (ML) models to predict engagement outcomes from initially-observable characteristics.  In particular, we could initial characteristics/responses from earlier EAS data to predict presence in later surveys, as one measure of engagement. (We can connect some participants across surveys through anonymized emails.) We expect causal inference, learning what approaches would “make people become more involved,” will  be more difficult. Key explanatory variables are entangled, and were not ‘experimentally assigned’: the ways that people are introduced to EA, the groups they are associated with, their experiences, and the ways that EA groups and organizations interact with members, etc. Nonetheless, further analysis, using techniques from the fields of causal inference, statistics, and econometrics, may allow us to make some reasonable causal inferences 3.8.1 Future engagement and retention modeling (after forum-post additions) see Ben West post CEA published a new analysis of retention based on their own data https://forum.effectivealtruism.org/posts/TeCsTp7pZPFQtJhme/estimates-of-highly-engaged-ea-retention 3.9 After-post followups/further work 3.9.1 Does engagement in EA make people more long-termist? From post: As we can see, average support for Near-termist causes declines with increases in engagement, while support for Longtermist and Meta causes increases. Question from Arepo I would love to see research into the direction of causality here. I think it’s very easy to assume engagement drives the realisation of belief in longtermism, and much EA messaging supports this - eg Will’s(?) statement that longtermism might be the biggest breakthrough of the EA movement. But I know many people for whom it seemed to run the other way - they lost interest over time in part because of the movement’s obsession with replacing concrete short term value with (as they see it) motivated speculation. We can separate at possible mechanisms that might be driving the above observation; we may seek to measure to what extent: Engagement \\(\\rightarrow\\) Lt-ism: Time spent in EA and/or engagement in EA leads people to become more long-termist? LT-ism \\(\\rightarrow\\) engagement: People who are less long-termist become less engaged and/or drop out? In measuring this, we need to consider underlying year-on-year trends that may complicate estimation: Trends to Lt-ism in the underlying population: Considering any fixed group of potential recruits (e.g., those people that would have joined EA in 2015). This group may themselves be becoming more (or less) LT-ist over the years, even before exposure to EA. Differential (self) selection of recruits over time: As the EA movement trends to LT-ism, people who are less long-termist are less likely to join. Approaches to answering this For 2.  LT-ism –&gt; Engagement: (?)  A. With ‘connected data’ we could measure whether those in the earlier years’ data who express LT-ist attitudes are more likely to appear in later years’ data, and to be more engaged (this relates to a ‘next project’ we are discussing and working on) B. Even with unconnected multi-year data we can consider people coming from groups that… presumably are likely to be more LT-ist (‘first-heard = LessWrong’ etc.) …coming from the same cohorts (e.g., joined EA in 2015) … get bigger or smaller across EA surveys, relative to less-LT-ist-seeming groups (And we could do the same for ‘number of 4+ engaged’ in each group) … E.g., suppose the cohort “joined in 2015, heard of EA from GWWC” shrinks from 2017-2020, while the cohort “joined in 2015, heard of EA from LW” increases … this may suggest less-LT-ist people are dropping out more. (But all of this assumes that dropout from the survey is proportional to dropout from the movement) #From https://stackoverflow.com/questions/62028925/how-do-i-catch-errors-in-inline-code-chunk-in-r-markdown knitr::knit_hooks$set( evaluate.inline = function (code, envir = knit_global()) { v = try(eval(xfun::parse_only(code), envir = envir)) knitr::knit_print(v, inline = TRUE, options = knitr::opts_chunk$get()) }, inline = function(x) { if (any(class(x) == &quot;try-error&quot;)) { as.vector(x) } else x }) # knitr::knit_hooks$set(inline = function(x) { # if(is.double(x)) # x &lt;- sprintf(&quot;%1.1f&quot;, x) # }) "],["eas_donations.html", "4 Donation 4.1 Introduction and summary Total EA donations, magnitudes in context 4.2 Career paths: Earning-to-give 4.3 Donation totals: descriptives 4.4 Donation and income for recent years 4.5 Which charities (causes and categories) are EAs donating to? 4.6 Donations: plans and aspirations versus actual (reported) donations 4.7 Donations versus next year’s plans 4.8 Model of EA donation behavior 4.9 Appendix: Extra analysis and robustness checks", " 4 Donation Linked to forum post Link EA Survey 2020 Series: Donation Data #eval=FALSE because this is already done in Main source(here(&quot;code&quot;, &quot;modeling_functions.R&quot;)) eas_20 &lt;- readRDS(here(&quot;data&quot;, &quot;edited_data&quot;, &quot;eas_20.Rdata&quot;)) eas_all &lt;- readRDS(here(&quot;data&quot;, &quot;edited_data&quot;, &quot;eas_all_private.Rdata&quot;)) eas_20_cy &lt;- readRDS(here(&quot;data&quot;, &quot;edited_data&quot;, &quot;eas_20_cy.Rdata&quot;)) source(here::here(&quot;build&quot;,&quot;labelling_eas.R&quot;)) # needs to have been run also -- some of these objects are used below # Folder to save plots in plots_folder &lt;- here(&quot;analysis&quot;, &quot;plots&quot;, &quot;donations_20&quot;) Note on feedback (unfold) I’d love to get your feedback on this report. It’s in the ‘bookdown’ format produced through Rmd, (with folded code as well as some other folding supplemental bits in case you are curious, but these could be ignored) Written by me with heavy input from Oska Fentem and guidance from David Moss and others (including Peter Wildeford and Nik Vetr). Much/most of this will be input into an EA Forum post, but that post may leave out some of the more technical and detailed content, and then refer/link to this hosted report (embedded with the other reports). (Most) margin notes will become footnotes in the forum post. Folding boxes will mainly be dropped in the forum version. Ideally, you could leave your feedback right in the web site using the Hypothes.is tool (in our private group; see thread, but public is OK too). If you have difficulties with that, or with any part of this format, please let me know. Of course I also appreciate feedback in any form, including in Slack, a document, on the Github repo, etc. I hope this work may be relevant even beyond this specific context, and thus would love loads of feedback because I think represents somewhat of a change in how we’re addressing the EA survey (e.g., the cross-year analysis) because I/we hope to apply some of these methods and formats to other projects and other data in the movement building, EA messaging, and fundraising space! Thanks so much!! 4.1 Introduction and summary Charitable donation (and earning-to-give) has been, and continues to be a prominent, prevalent, and impactful component of the Effective Altruism movement. The EA Survey has been distributed between 2014 and 2020, at roughly 15 month intervals. As a result, surveys were released at various points in the year, ranging from April to August, and no survey was released in 2016. In each survey we asked EAs about their charitable donations in the previous year, and their predicted donations for the year of the survey. Our work in this post/section reports on the 2020 survey (2019 giving), but our analysis extends to all the years of the EA survey. In this post (and the accompanying ‘bookdown’ supplement chapter), we consider donation responses, presenting both raw numbers, and descriptive, predictive, and causally-suggestive analysis. We present simple numbers, statistical comparisons, vizualisations, and descriptive and ‘predictive’ (machine learning) models. We cover a range of topics and concerns, including: the total magnitude of EA giving and its relationship to non-EA giving, career paths and ‘earning to give’, the broad relationship between EA giving and individual characteristics (such as employment status and country, and income), donations versus income trends across recent years, which causes EAs are donating to, and EA’s donation plans versus realized donations (and future plans). Our modeling work work considers how donations (total, share-of-income, and ‘donated over 1000 USD’) jointly relates to a range of characteristics. We first present ‘descriptive’ results focusing on a key set of observable features of interest, particularly demographics, employment and careers, and the ‘continuous features’ age, time-in-EA, income, and year of survey. We next fit ‘predictive’, allowing the ‘machine learning’ models themselves to choose which features seem to be most important for predicting donations. * Note (to put in EA Forum post only): A ‘dynamic version’ of this document (an R-markdown/Bookdown), with folded code, margin notes, some interactive graphs and tables, and some additional details, can be found here. This may be helpful for anyone that wants to dig into this more deeply, and perhaps for those who are data, code, and statistics-inclined. In the narrative below, we simply refer to “donations” rather than “reported donations” for brevity. Unless otherwise mentioned, all figures simply add, average, or otherwise summarize individual responses from the EA Survey years mentioned. Programmers note: Most/many numbers included in the text below are soft-coded, and thus can automatically adjust to future data or adapted data. However, where we cite previous posts, these numbers are largely hand-coded from previous work. require(scales) #can also move stuff to plotting_functions.R # Define breaks and limits breaks &lt;- c(0, 10^(1:10)) max_lim &lt;- max(filter(eas_all, !year %in% c(2014, 2015))[c(&quot;donation_usd&quot;, &quot;donation_plan_usd&quot;)], na.rm=TRUE) density_breaks &lt;- seq(0, 1, 0.2)[-1] # Define same parameters for x and y axis scales &lt;- list(limits = c(0, max_lim), trans = scales::pseudo_log_trans(base=10), breaks = breaks, labels = scales::label_number_si(prefix = &quot;$&quot;), expand=c(0,0)) scatter_theme &lt;- theme_minimal() donate_charity_names &lt;- eas_20 %&gt;% dplyr::select(matches(&quot;donate_&quot;)) %&gt;% dplyr::select(-matches(&quot;action_|_later&quot;)) %&gt;% names() don_tot_freq &lt;- eas_20 %&gt;% summarise(across(c(all_of(donate_charity_names)), ~sum(as.numeric(.x) &gt; 0, na.rm = TRUE))) %&gt;% slice(1) %&gt;% unlist(., use.names=TRUE) dev_health_chars &lt;- c(&quot;donate_deworm_the_world_c&quot;, &quot;donate_givewell_c&quot;, &quot;donate_schistosomiasis_control_c&quot;, &quot;donate_give_directly_c&quot;, &quot;donate_against_malaria_found_c&quot;, &quot;donate_global_health_develop_c&quot;) animal_chars &lt;- c(&quot;donate_mercy_for_animals_c&quot;, &quot;donate_humane_league_c&quot;, &quot;donate_ea_animal_welfare_fund_c&quot;, &quot;donate_good_food_institute_c&quot;, &quot;donate_ace_c&quot;) ea_meta_chars &lt;- c(&quot;donate_rethink_charity_c&quot;, &quot;donate_80k_c&quot;, &quot;donate_cea_c&quot;, &quot;donate_ea_foundation_c&quot;, &quot;donate_ea_meta_fund_c&quot;) lt_ai_chars &lt;- c(&quot;donate_machine_intelligence_c&quot;, &quot;donate_long_term_future_fund_c&quot;) other_chars &lt;- c(&quot;donate_center_applied_rational_c&quot;, &quot;donate_global_health_develop_c&quot;, &quot;donate_other1_c&quot;, &quot;donate_other2_c&quot;, &quot;donate_other3_c&quot;, &quot;donate_other4_c&quot;, &quot;donate_other5_c&quot;) all_chars &lt;- c(dev_health_chars, animal_chars, ea_meta_chars, lt_ai_chars, other_chars) #all_char_labels &lt;- list(animal_don = &quot;Animal welfare&quot;, dev_don = &quot;Global health + development&quot;, ea_meta_don = &quot;EA meta and organization&quot;, lt_ai_don=&quot;Long term &amp; AI&quot;, other_don = &quot;Other&quot; ) -- moved to #all_char_labels2 &lt;- list(dev_don = &quot;Global health + development&quot;, animal_don = &quot;Animal welfare&quot;, ea_meta_don = &quot;EA meta and organization&quot;, lt_ai_don=&quot;Long term &amp; AI&quot;, other_don = &quot;Other&quot; ) -- moved to #here::here(&quot;build&quot;,&quot;labelling_eas.R&quot;) # moved to build side: # eas_20 &lt;- eas_20 %&gt;% sjlabelled::var_labels(all_char_labels) count_notna &lt;- function(x) sum(!is.na(x)) where_don_dummies &lt;- c(&quot;d_dev_don&quot;, &quot;d_animal_don&quot;, &quot;d_ea_meta_don&quot;, &quot;d_lt_ai_don&quot;, &quot;d_other_don&quot;) # Construct charity-specific aggregations (?move to build side) where_don_vars &lt;- c(&quot;dev_don&quot;, &quot;animal_don&quot;, &quot;ea_meta_don&quot;, &quot;lt_ai_don&quot;, &quot;other_don&quot;) eas_20 &lt;- eas_20 %&gt;% mutate( num_named_dons = rowSums(!is.na(select(., one_of(all_chars)))), dev_don = rowSums(across(all_of(dev_health_chars)), na.rm = TRUE), d_dev_don = dev_don &gt; 0, animal_don = rowSums(across(all_of(animal_chars)), na.rm = TRUE), d_animal_don = animal_don&gt;0, ea_meta_don = rowSums(across(all_of(ea_meta_chars)), na.rm = TRUE), d_ea_meta_don = ea_meta_don&gt;0, lt_ai_don = rowSums(across(all_of(lt_ai_chars)), na.rm = TRUE), d_lt_ai_don = lt_ai_don&gt;0, other_don = rowSums(across(all_of(other_chars)), na.rm = TRUE), d_other_don = other_don&gt;0 ) %&gt;% mutate_at(.vars =where_don_vars, funs(ifelse(num_named_dons==0, NA, .)) ) eas_20 %&lt;&gt;% labelled::set_variable_labels(.labels = as.list(all_char_labels), .strict=FALSE) pct_tot &lt;- function(x) { x/NROW(eas_20)*100 } num_don &lt;- sum(eas_20$donation_2019_c&gt;0, na.rm=TRUE) num_na_don &lt;- sum(is.na(eas_20$donation_2019_c)) zero_don &lt;- sum(eas_20$donation_2019_c==0, na.rm=TRUE) tot_don &lt;- sum(eas_20$donation_2019_c, na.rm=TRUE) #for all years, for USA nonstudents only tot_don_all_usa &lt;- sum(eas_all$donation_usd[eas_all$d_live_usa==1 &amp; eas_all$d_student==0], na.rm=TRUE) tot_inc_all_usa &lt;- sum(eas_all$income_c_imp_bc5k[eas_all$d_live_usa==1 &amp; eas_all$d_student==0], na.rm=TRUE) tot_share_don_us_nonstudent &lt;- tot_don_all_usa/tot_inc_all_usa tot_don_dev &lt;- sum(eas_20$dev_don, na.rm=TRUE) tot_don_animal &lt;- sum(eas_20$animal_don, na.rm=TRUE) tot_don_ea_meta &lt;- sum(eas_20$ea_meta_don, na.rm=TRUE) tot_don_lt_ai &lt;- sum(eas_20$lt_ai_don, na.rm=TRUE) med_don &lt;- median(eas_20$donation_2019_c, na.rm=TRUE) mean_don &lt;- mean(eas_20$donation_2019_c, na.rm=TRUE) mean_don_not_new &lt;- mean(eas_20$donation_2019_c[eas_20$year_involved_n!=year_s], na.rm=TRUE) mean_don_18 &lt;- mean(eas_all$donation_usd[eas_all$year==2019], na.rm=TRUE) mean_don_18_not_new &lt;- mean(eas_all$donation_usd[eas_all$year==2019 &amp; eas_all$year_involved!=&quot;2019&quot;], na.rm=TRUE) plan_donate_2019_c &lt;- filter(eas_all, year == 2019) %&gt;% pull(donation_plan_usd) mean_plan_18_19 &lt;- mean(plan_donate_2019_c, na.rm=TRUE) med_plan_18_19 &lt;- median(plan_donate_2019_c, na.rm=TRUE) med_not_new &lt;- median(eas_20$donation_2019_c[eas_20$year_involved_n!=year_s], na.rm=TRUE) top_1p3don &lt;- eas_20 %&gt;% select(donation_2019_c) %&gt;% slice_max(donation_2019_c, prop =.013) %&gt;% sum() top_1p3share &lt;- top_1p3don/tot_don 4.1.1 Summary (some key results and numbers) 55.5% of EAs in the 2020 survey reported making a charitable donation in 2019, 13.7% reported making zero donations, and 30.8% did not respond to this question. (Thus, of those who responded, 80.3% reported making a donation in the prior year.) Participants reported total donations of 10,695,926 USD in 2019 (cf 16.1M USD in 2018). However, the number of survey participants has declined somewhat, from 2509 in 2019 (1704 of whom answered the donation question) to 2056 (1423 answering the donation question) in 2020.* Over the past years, we see no strong trend in median or mean donation amounts reported. * All figures here refer to survey responses, so we won’t write ‘reported in the survey’ each time. These (2019-20) numbers exclude a single survey donation response in the billions that was ruled to be implausible. A total of 2 observations were dropped for implausible income, donations, or ages. Averages are for those who answered the donation question(s), including those who reported donating zero. Nonresponses are not counted in these statistics except where specifically mentioned. Unless otherwise mentioned, all figures simply add, average or otherwise summarize individual responses from the EA Survey years mentioned. The median annual donation in 2019 was 528 USD (cf 683.92 USD in 2018). The mean (reported) annual donation for 2019 was 7,516 USD (cf 9,370 for 2018) or 8,607 USD excluding those who joined in 2020 (cf 10,246 USD for 2018 excluding those who joined in 2019). The median annual donation in 2019 excluding those who joined EA in 2020 was 761 USD (cf. 990 USD for the comparable median for 2018/2019 and 832 USD for 2017/2018). (See ’donation and income trends in EA’ for more details). In 2019 1.3% of donors accounted for $6,437,404 in donations or 60% of the survey total. (Cf in 2018 1.3% of donors accounted for 57% of donations.) med_don_share &lt;- median(eas_20$don_share_inc_19, na.rm = TRUE) med_don_share_imp_bc &lt;- median(eas_20$don_share_inc_19_imp_bc5k, na.rm = TRUE) earn_filter &lt;- quos(d_student==0, income_c&gt;10000) med_don_share_imp_ns_10k &lt;- eas_20 %&gt;% filter(!!!earn_filter) %&gt;% summarise(med=median(don_share_inc_19, na.rm = TRUE)) tot_inc &lt;- sum(eas_20$income_c, na.rm=TRUE) tot_inc_imp_bc &lt;- sum(eas_20$income_c_imp_bc5k, na.rm=TRUE) share_don_gt_10pct &lt;- sum(eas_20$don_share_inc_19&gt;=.1, na.rm = TRUE)/sum(!is.na(eas_20$don_share_inc_19)) share_don_gt_10pct_imp &lt;- sum(eas_20$don_share_inc_19_imp_bc5k&gt;=.1, na.rm = TRUE)/sum(!is.na(eas_20$don_share_inc_19_imp_bc5k)) share_don_gt_5pct_imp &lt;- sum(eas_20$don_share_inc_19_imp_bc5k&gt;=.05, na.rm = TRUE)/sum(!is.na(eas_20$don_share_inc_19_imp_bc5k)) share_don_gt_10pct_earn &lt;- eas_20 %&gt;% filter(!!!earn_filter) %&gt;% transmute(share_don_gt_10pct = sum(don_share_inc_19&gt;=.1, na.rm = TRUE)/sum(!is.na(don_share_inc_19)) ) %&gt;% unlist %&gt;% .[1] #don gt 10pct ... by gender #eas_20 %&gt;% # mutate(d_don_gte10_imp = don_share_inc_19_imp&gt;=.1) %&gt;% # tabyl(gender_manual, d_don_gte10_imp) %&gt;% tabylstuff() The median percentage of income donated in 2019 was 2.96% (cf 3.23% in 2018). However, if we impute “0 and missing incomes” at “group medians for student-status and country,”* the median percentage of income donated was 2% for 2019. * Many respondents do not reveal their income, or report zero or implausibly small incomes (if we consider income to include transfers and family support); among these, many do report donations. To get a meaningful measure of average shares of income donated (and other stats) including these individuals, we need to put some measure reflecting yearly spending power in the denominator. We thus make a rough imputation, selecting the average income for individuals from their same country and same student-status who do report an income value. To avoid sensitivity to outliers, countries with small numbers of participants are lumped together into an “other” group for this imputation. Where this (or reported income) falls below 5000 USD, we ‘bottom-code’ it this as at 5000 USD. (Note that we hope to improve this imputation in future work, incorporating features such as age in the imputation.) Mean share of total (imputed) income donated was 9.44% (imputing income where below 5k or missing) or 12.5% without imputation. 20% of EAs who answered the donation question reported donating 10% or more of their income in 2019 (if we impute income; otherwise 25.6% without imputation; this compares to 20% in 2018, without imputation). The median percent of income donated by full-time-employed non-students who earned more than $10,000 was 2.92%, and of this group 23.9% donated 10% of their income or more in 2019 (cf 3.38% and 24% in 2018). Overall, those taking the EA survey tend to report donating a substantially greater share of income than those in the general US population – (web link). pct_don &lt;- function(x) { sum(don_tot_freq[x])/sum(don_tot_freq)*100 } pct_ddon &lt;- function(x) { op( sum(x != 0, na.rm=TRUE)/sum(notNA(x), na.rm=TRUE)*100 ) } don_stats &lt;- eas_20 %&gt;% filter(num_named_dons&gt;0) %&gt;% select(all_of(where_don_vars)) %&gt;% vtable::sumtable( summ=c(&#39;notNA(x)&#39;, &#39;sum(x != 0)&#39;, &#39;sum(x != 0)/notNA(x)&#39;, &#39;mean(x)&#39;, &#39;sd(x)&#39;, &#39;pctile(x)[50]&#39;, &#39;pctile(x)[90]&#39;), summ.names = c(&#39;Number of Responses&#39;, &#39;Number reporting donation to cause&#39;, &#39;Share of reporters donating to cause&#39;, &quot;Mean donation of reporters (including 0&#39;s)&quot;, &#39;Sd&#39;, &quot;Median&quot;, &quot;90th pct&quot;), digits=c(0,0,2,0,0,0,0), simple.kable = TRUE, labels = all_char_labels2, #it&#39;s a horrible workaround but we need to have the order of these the same as the table order ... I think it&#39;s a flaw of sumtable title = &quot;Donations by category (where indicated)&quot;, out=&quot;kable&quot;) %&gt;% kable_styling() #todo (low-priority) -- replace with .summ hijacked command n_rep_char &lt;- sum(eas_20$num_named_dons&gt;0, na.rm=TRUE) don_stats_by_gwwc &lt;- eas_20 %&gt;% mutate(`GWWC Pledge` = case_when( action_gwwc==1 ~ &quot;Yes&quot;, action_gwwc==0 ~ &quot;No&quot; )) %&gt;% filter(num_named_dons&gt;0) %&gt;% select(all_of(where_don_vars), `GWWC Pledge`) %&gt;% vtable::sumtable(group = &quot;GWWC Pledge&quot;, group.test=TRUE, summ=c(&#39;notNA(x)&#39;,&#39;sum(x != 0)/notNA(x)&#39;, &#39;mean(x)&#39;, &#39;sqrt(var(x)/length(x))&#39;, &#39;pctile(x)[50]&#39;), summ.names = c(&#39;N Responses&#39;, &#39;Share positive&#39;, &#39;Mean&#39;, &quot;Median&quot;), digits=c(0,2, 0,0,0), simple.kable = TRUE, labels = all_char_labels2, #it&#39;s a horrible workaround but we need to have the order of these the same as the table order ... I think it&#39;s a flaw of sumtable title = &quot;Donations by category (where indicated), by GWWC&quot;, out=&quot;kable&quot;) %&gt;% row_spec(1:1, bold = TRUE) %&gt;% kable_styling() ddon_stats_by_gwwc &lt;- eas_20 %&gt;% mutate(`GWWC Pledge` = case_when( action_gwwc==1 ~ &quot;Yes&quot;, action_gwwc==0 ~ &quot;No&quot; )) %&gt;% filter(num_named_dons&gt;0) %&gt;% select(all_of(where_don_dummies), `GWWC Pledge`) %&gt;% vtable::sumtable(group = &quot;GWWC Pledge&quot;, group.test=TRUE, summ=c(&#39;notNA(x)&#39;,&#39;sum(x != 0)/notNA(x)&#39;), summ.names = c(&#39;N Responses&#39;, &#39;Donated to... ?&#39;), digits=c(0,2), simple.kable = TRUE, labels = all_char_labels2, #it&#39;s a horrible workaround but we need to have the order of these the same as the table order ... I think it&#39;s a flaw of sumtable title = &quot;Binary: Indicated donating to category, by GWWC&quot;, out=&quot;kable&quot;) %&gt;% row_spec(1:1, bold = TRUE) %&gt;% kable_styling() # .kable() %&gt;% # .kable_styling(&quot;striped&quot;) #todo (low-priority) -- replace with .summ hijacked command While 69.2% of respondents answered the donation question, only 20.9% answered at least one question about where they donated. Among these, the charity that the most EAs stated that they donated to was the Against Malaria Foundation (AMF), with 122 reported donations (out of a total of 1462 reported donations). Global Poverty charities continue to attract the largest counts and amounts of donations. 62% of those who answered the relevant question reported donating to this category. 26.9% of the total ‘where donated’ reports were to global poverty charities. We sum 1,703,870 USD in total donations reported as specifically going to global poverty charities. This compares to 27.3% reporting donating, 10.5% of donations and \\(\\$\\) 645,086 total donated for animal charities, 17.2%, 5.81% and \\(\\$\\) 330,910 for EA movement/meta charities, and 18.2%, 5.61% and \\(\\$\\) 418,403 for long term and AI charities, respectively. Evidence is mixed on whether EAs’ donations in a year tend to exceed or fall short of the amount they planned to donate (as they reported in previous surveys). For the small share that can be tracked across years, donations tend to exceed plans (by around 60 USD at median, but over 1000 USD at mean). However, the overall distribution of donations for a particular year (including all respondents) tends to fall short of the distribution of planned donations (by about 450 USD at median and over 2000 at mean). While at median EAs tend to report planning to donate the same amount this next year that they donate in each particular year, the average (mean) plan for next year is significantly larger. Our descriptive models basically find that:* age, being in a named ‘top EA’ big city, having taken the GWWC pledge, and an Earning-to-Give career are positively associated with donations, while being ‘not employed’ (and to a lesser extent non-male gender and student status are negatively associated with this; donation are roughly proportionally associated with income (approximately ‘unit elastic’), as well as with age and ‘time in EA’ (with elasticities around 0.54 to 0.63, respectively). Our predictive (ML) models highlight the importance of income and (to a lesser extent) age (each positively related to donation incidence and amounts). These models perform moderately well, particularly in predicting ‘whether donated 1k USD or more’ (here it attains about 74% accuracy compared to 54% accuracy from simply ‘guessing the most common outcome’). * Caveat: not all of these coefficients are statistically significant by standard metrics. These results are ‘statistically stronger’ for our model of ‘whether donated 1000 USD or more.’ Why does the EA Survey ask about donations? What does it tell us? What is the “theory of change” for how learning about donation behavior will improve outcomes? We present some reasons why this may be useful:* * This should be considered a medium-run project: we will not be able to address all of these questions in the current post. The magnitude of EAs’ donations informs ‘how much weight can we throw around’ in asking charities etc to appeal to us as a community? While we have other measures (discussed below) of the overall amounts and largest donations, the EA Survey conveys additional information about the donations of ‘large groups of moderate-income people who explicitly identify with EA.’ This may offer insight into ‘what motivates and impedes donation behavior.’ Donation behavior may be seen as one measure of EA engagement; our evidence may thus offer insight into ‘what motivates engagement.’ Observing changes in donation patterns across time may alert us to potential problems and important changes in priorities, values, and the nature of the EA movement. Being able to predict future donation behavior may also help EA organizations better anticipate, budget, and plan (in conjunction with their existing data and models). Predicting and describing typical donation rates can inform decisions like “which EAs seem likely to have more impact if they choose to go into direct work versus earning-to-give.”* * My impression is that previous work on ‘should I work directly for good or earn-to-give’ has tended to focus on earning potential, presuming that those who are in large amounts will donate at a certain planned rate. However, an equally important question may be \"what share or amount of income should we expect people who pursue earning-to-give to end up donating? This question seems particularly important in the presence of value drift. (However, one might argue that the individual’s own understanding of his or her future behavior might dominate, and not be easily integrated with the insight that we gain from the broad predictions using survey data.) Perhaps more controversially (and we are raising this idea but not promoting it), EAs’ donation amounts might be seen as incentive-compatible ‘votes’ telling us what people in the movement want the EA movement to focus on? However, note people need not be truthfully reporting here, so if we allow for mis-statement, this is far from incentive compatible. Total EA donations, magnitudes in context Considering the magnitude of the donations… The $10,695,926 USD in donations reported above seems likely to be a small share of total EA-affiliated giving, perhaps less than 1/4 of the total (excluding the super-rich and institutional givers), perhaps even a far smaller share (see extrapolations below). Previous estimates suggest that, even among very highly-engaged EAs, only about 40% complete the EA survey. While we might assume that people with a lower ‘cost of time’ (and, all equal, lower incomes) are likely to be over-represented in the EA survey, those who donate more might be more likely to respond to these particular questions. Other estimates suggest that only about 20% of GWWC members complete the survey. As noted above, only 69.2% of survey respondents answered the ‘past year donation’ question in 2020. We present some extrapolations below, our own and others. Even within the survey, the largest mass of donations are heavily concentrated among a few givers. We expect that the distribution of donations in EA overall is even more heavily skewed, with large donors and foundations (such as Tuna and Moskowitz of Open Philanthropy accounting for a lion’s share. The table below uses data from Open Phil’s Grants database, divided by year and cause area).* effectivealtruismdata.com provide further interesting visualizations of the magnitude, sources, and recipients of EA donations. library(scales) research_terms &lt;- &quot;research|univ|study|UC|trial|scholar|fellow|macreoeconomic|rethink|study|feasibility|analysis|evaluation&quot; focus_area_names &lt;- c( `Criminal Justice Reform` = &quot;Crime/Justice&quot;, `Farm Animal Welfare` = &quot;Farm Animal&quot;, `Global Health &amp; Development` = &quot;Glob. Health/Dev.&quot;, `Scientific Research` = &quot;Scient. Res.&quot;, `Potential Risks from Advanced Artificial Intelligence` = &quot;AI risk&quot;, `Biosecurity and Pandemic Preparedness` = &quot;Biosec.&quot;, `Other areas` = &quot;Other&quot;, `Macroeconomic Stabilization Policy` = &quot;Macro-econ&quot;, `Global Catastrophic Risks` = &quot;Glob. Catastr. Risk&quot;, `Immigration Policy` = &quot;Immig. Policy&quot;, `Land Use Reform` = &quot;Land Ref.&quot;, `U.S. Policy` = &quot;US policy&quot;, `History of Philanthropy` = &quot;Hist. of Phil.&quot; ) open_phil_grants &lt;- read.csv(&quot;https://www.openphilanthropy.org/giving/grants/spreadsheet&quot;) %&gt;% as_tibble() %&gt;% mutate( amount = as.numeric(gsub(&#39;[$,]&#39;, &#39;&#39;, Amount)), amount_usd_k = amount/1000, date = lubridate::my(Date), year = lubridate::year(date), focus_area = dplyr::recode(Focus.Area, !!!focus_area_names), focus_area = as.factor(focus_area)) %&gt;% select(-Amount, -Date) ( op_res_grants_tab_yr_area &lt;- open_phil_grants %&gt;% dplyr::group_by(year, focus_area) %&gt;% # drop_na(!!yvar, !!treatvar) %&gt;% summarise(total = sum(amount_usd_k, na.rm = TRUE)) %&gt;% spread(year, total, fill=0) %&gt;% adorn_totals(&quot;row&quot;) %&gt;% adorn_rounding(digits = 0) %&gt;% arrange(-`2020`) %&gt;% rename_with(~snakecase::to_sentence_case(.)) %&gt;% # Change focus_area to Focus Area .kable(caption = &quot;Open Philanthropy grants by year and area, in $1000 USD&quot;, col.names = NA) %&gt;% row_spec(1:1, bold = TRUE) %&gt;% .kable_styling(&quot;striped&quot;) ) Table 4.1: Open Philanthropy grants by year and area, in $1000 USD Focus area 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 Total 3,100 3,045 29,978 34,627 135,666 312,480 197,047 297,963 273,776 146,992 Glob. Health/Dev. 2,000 2,550 22,134 26,971 66,054 124,217 75,105 40,706 101,671 32,788 Scient. Res. 0 0 0 0 9,039 47,550 25,160 53,860 67,203 3,163 Biosec. 0 0 0 300 5,323 28,841 9,388 21,566 26,468 9,580 Farm Animal 0 0 0 0 14,436 27,957 27,977 39,870 25,057 14,319 AI risk 0 0 0 1,186 6,564 43,222 4,160 63,244 15,847 62,961 Other 1,100 0 1,300 210 2,872 6,144 18,140 13,018 14,677 11,098 Crime/Justice 0 445 3,000 1,141 24,591 21,421 20,375 55,522 10,534 2,537 Glob. Catastr. Risk 0 0 0 500 3,170 9,118 12,901 1,803 5,701 4,622 Immig. Policy 0 0 2,780 915 1,324 1,800 400 1,785 3,700 0 Macro-econ 0 0 435 2,179 1,906 1,405 2,450 3,150 2,317 5,323 Land Ref. 0 0 0 773 387 640 890 3,440 600 600 Hist. of Phil. 0 50 25 2 0 166 0 0 0 0 US policy 0 0 303 450 0 0 100 0 0 0 Extrapolations and further benchmarks: Ben Todd’s recent post estimates that the EA community is donating $420 million per year, which “has grown maybe about 21% per year since 2015,” and “around 60% was through Open Philanthropy, 20% through other GiveWell donors, and 20% from everyone else.” A recent post by tylermaule estimates $263 million in ‘funding ’global funding of EA causes.’* * This relies on Open Phil’s Grants Database, GiveWell’s Metrics Report, EA funds intake figures, and Animal Charity Evaluators’ Metrics report. Giving What We Can reports roughly $70 million in donations per year, in recent years.** ** At end of Dec. 2020 they reported that their roughly 5000 members “donated more than $203,443,730”to highly effective charities\". In December 2019 the comparable figure was 126.8 million, suggesting that roughly 77 million was donated in a single year. However, the same figure: $25,309,348, was listed both in December of 2018 and 2017, so the figures may not be constantly updated. GWWC gives data on the destinations of ‘GWWC donations that go through EA funds.’ GiveWell reported “GiveWell donors contributed over $150 million to our recommended charities in 2019.” Of course, the above large donations/grant totals may not all be coming from donors aligned with EA, and may not entirely go towards the most effective charities. The donations also may not be well-described by the donations recorded in the EA survey. in the fold/footnote, we consider the importance of EA-aligned donations in comparison to non-EA donations to similar causes. We return to this in a supplemental appendix section (web link), specifically focusing on US nonstudents, comparing these to results from a national survey. A further question is whether the few hundreds of millions of dollars in EA-aligned donations is substantial in comparison to non-EA donations to similar causes (e.g., developmentaid “Top trends in private philanthropic donations for development” reports the OECD figure of $7.8 Billion in private philanthropic donations for development in 2018, and 200-300 billion in total charitable donations per year from the USA alone.) Some quick responses: Naturally, we anticipate EA donations will tend to be much more effective per dollar, perhaps orders of magnitude more so. (A basic case, with some references, is given here. However, Tomasik and others present credible arguments for being skeptical of the claims of vast differences in effectiveness within a given domain.) Even if EA donations were small in relation to global giving, they still have an important impact, and this is the domain we can control. (Relatedly, we should not fall victim to the ‘drop in the bucket’ and ‘proportion dominance’ biases in considering this.) “Where, when, and how much EAs are giving” may be an important informative measure of beliefs and priorities (discussed further below). extrap_tot_ea_don &lt;- (tot_don + tot_don*0.5 * (num_na_don/(num_don+zero_don))) / 0.3 Our own rough extrapolations suggest, perhaps very conservatively, $43.6 million USD could be a reasonable central guess for the total amount of annual donations coming from non-billionaire EAs, i.e., the sort of EAs who respond to the EAS.* * This extrapolation simply multiplies the reported $10,695,926 USD by 1 + 0.445 and divides by 2, to adjust for the share of respondents who did not answer this question, presuming they give at half the rate of those who do answer. Next we divide by 0.3, averaging the 20% and 40% estimates of EA survey nonresponse noted above. I presume that billionaire EAs are extremely unlikely to complete the survey or report their total donations in this form. Implicitly, we assume respondents are reporting accurately. This extrapolation should not be taken too seriously. David Moss has taken this one step further, with a brief ‘Fermi estimate’ in Guesstimate making the uncertainty over each parameter explicit, and expressing a confidence/credible interval with midpoint 78 million and 95% bounds 41-140 million USD. 4.2 Career paths: Earning-to-give Although there may have been a recent decline in earning-to-give (ETG), it continues to be a popular career path. (We discuss career paths further in the EA Survey 2020: Demographics post under ‘Careers and education’*) * In an earlier version of that post, the “which of the following best describes your current career” result had been misstated, showing the share of responses to this multi-response question rather than the share of individuals selecting ETG. “We were requested to change the question between 2018/2019 and 2020… but looking at non-students (who are largely already in their careers), the responses across years may still be comparable and appear to show a slight decline in E2G” In the tables and graphs below, the apparent steep drop in the number indicating ETG from the 2019 to the 2020 survey seems likely to be overstated (as a result of a requested change in the question language and options provided).* * Question texts 2018: “What broad career path are you planning to follow?” [4 options] 2019: “If you had to guess, which broad career path(s) are you planning to follow?” [9 options] 2020: “Which of the following best describes your current career?” [11 options] Note that the changing composition of EA survey respondents may also affect this. Still, the responses for non-students might be less sensitive to the changes in the survey question as they are more likely to be in a career path as their ‘current career.’ These responses also suggest some decline in EtG. etg_rates_all &lt;- eas_all %&gt;% filter(year&gt;2014) %&gt;% group_by(year) %&gt;% summarise( &quot;Count&quot; = n(), &quot;Share ETG&quot; = mean(as.numeric(d_career_etg)) ) etg_rates_ns &lt;- eas_all %&gt;% filter(year&gt;2014) %&gt;% filter(d_student==0) %&gt;% group_by(year) %&gt;% summarise( &quot;Count&quot; = n(), &quot;Share ETG&quot; = mean(as.numeric(d_career_etg)) ) ( etg_rates_tab &lt;- bind_cols(etg_rates_all, etg_rates_ns[-1]) %&gt;% magrittr::set_names(c(&quot;Year&quot;, &quot;All responses&quot;, &quot;Share EtG&quot;, &quot;Nonstudents&quot;, &quot;Nonstudents: Share EtG&quot;)) %&gt;% kable(caption = &quot;Rates of &#39;Earning-to-give&#39; by year and student status (see caveats)&quot;, digits=3) %&gt;% .kable_styling() ) Table 4.2: Rates of ‘Earning-to-give’ by year and student status (see caveats) Year All responses Share EtG Nonstudents Nonstudents: Share EtG 2015 2362 0.217 980 0.322 2017 1845 0.220 671 0.380 2018 2599 0.303 1791 0.336 2019 2509 0.283 1898 0.262 2020 2056 0.151 1035 0.232 # tabyl(year, d_career_etg) %&gt;% # tabylstuff_nocol(cap = &quot;Non-students only; Rates of &#39;Earning-to-give&#39; (see caveat)&quot;) # # ( # etg_rates_ns &lt;- eas_all %&gt;% # filter(d_student==0) %&gt;% # tabyl(year, d_career_etg) %&gt;% # tabylstuff_nocol(cap = &quot;Non-students only; Rates of &#39;Earning-to-give&#39; (see caveat)&quot;) # ) # ( # etg_rates_tab &lt;- eas_all %&gt;% # group_by(year, d_student) %&gt;% # filter(!is.na(d_student)) %&gt;% # summarise( &quot;Count&quot; = n(), # &quot;Share ETG&quot; = mean(as.numeric(d_career_etg)) # ) %&gt;% # pivot_wider(names_from =d_student, # values_from=c(Count, &quot;Share ETG&quot;) # ) %&gt;% # set_names(c(&quot;Year&quot;, &quot;Nonstudents&quot;, &quot;Students&quot;, &quot;Nonstudents: Share EtG&quot;, &quot;Students: Share EtG&quot;)) %&gt;% # kable() %&gt;% # .kable_styling() #) #todo - medium priority: combine the above tables into a single table: overall, just for students with just n, (etg_rates_plot &lt;- eas_all %&gt;% group_by(year, d_student) %&gt;% filter(year&gt;2014) %&gt;% filter(!is.na(d_student)) %&gt;% #@oska (low-med priority todo): we should functionalize these mutations for computing se and CIs (or find someone who has done). We do it again and again, and the code is bulky #maybe incorporate my se_bin function #@oska todo ... also functionalize or otherwise preserve a good version of this graph # Calculate standard error, confidence bands and change student factor levels summarise( m_etg = mean(as.numeric(d_career_etg)), se = se_bin(d_career_etg)) %&gt;% mutate( etg_low = m_etg - 1.96*se, etg_high = m_etg + 1.96*se, d_student = as.factor(if_else(d_student == 0, &quot;Non-student&quot;, &quot;Student&quot;)), year = as.factor(year)) %&gt;% ggplot(aes(x=year, y=m_etg, colour = d_student, group = d_student)) + geom_pointrange(aes(ymin = etg_low, ymax = etg_high), position = position_dodge(width=0.5)) + # Ensure that bars don&#39;t overlap geom_line(position = position_dodge(width=0.5)) + xlab(&quot;Mean (and 95% CI) response share in &#39;Earning-to-give&#39;&quot;) + ylab(&quot;Share of sample&quot;) + scale_color_discrete(&quot;&quot;) + # Remove legend title scale_y_continuous(labels = scales::percent_format(accuracy = 1L), limits=c(0,NA), oob = scales::squish) + # Change y-axis to percentages theme(legend.position = c(0.9, 0.95), #legend.background = element_rect(fill=alpha(&#39;blue&#39;, 0.001)), legend.key = element_blank()) ) The decline in ETG is less dramatic among non-students (over 23% of non-student respondents still report ETG as their ‘current career’), but it nonetheless appears to be fairly strong and consistent from 2017-present.* * We do not include 2014 in the above tables and plots because of very low response rates to the student status and EtG-relevant questions. 4.3 Donation totals: descriptives Overall donations, totals by groups Below, we present a histogram of positive reported 2019 donations by all respondents. Note that: the horizontal axis is on a logarithmic scale, 13.7% of the 2,056 total respondents reported donating zero, and 30.8% of the total respondents did not report their donation amount. As noted above, we will often simply refer to ‘donations’ rather than ‘reported donations,’ for brevity. eas_20$don_19_p1 &lt;- as.numeric(eas_20$donation_2019_c+1) #adapting from EA survey 2019 Rscript_analysis.md donation_2019_c &lt;- eas_20$donation_2019_c require(scales) don_breaks &lt;- c(50, 100, 200, 300, 500, 1000, 2500, 5000, 10000, 25000, 50000, 100000, 250000, 500000, 1000000, 2500000) eas_20 %&lt;&gt;% rowwise() %&gt;% mutate(donation_2019_c_50 = max(donation_2019_c, 50)) %&gt;% ungroup ( donhist_19 &lt;- eas_20 %&gt;% hist_plot_lscale(eas_20$donation_2019_c_50, breaks = don_breaks) + geom_vline_mean(donation_2019_c) + geom_vline_med(donation_2019_c) + geom_vline_90(donation_2019_c) + labs(title=&quot;Histogram of 2019 Donations&quot;, x=&quot;2019 $ Donations (bottom-coded at 50)&quot;, y = &quot;Number of respondents&quot;) ) # Todo (medium importance): Overlay a display of &#39;overall percentage shares&#39; ... so we know where the 80th and 90th percentile are, etc. In 2019 we reported: a donation of 1000 USD per year … would place one in the top half of EA donors (specifically, the 55th percentile), whereas being in the top 10% of donors would require donating 11,000 USD and the top 1% 110,000 USD. The results for 2020 (for 2019 donations) are comparable; the median donation (of those reporting) is 528 USD, a donation of $1000 puts you in the 59.5th percentile. Being in the top 10% requires donating 9,972 and being in the top 1% means donating 89,560 USD. As in previous years, the mean far exceeds the median, (and falls close to the 90th percentile!); a very small number of very large donations dwarf the size of most others. We illustrate this in the ‘treemap’ plot below, which divides the total reported contributions into groups by size-of-contribution. require(treemapify) geom_treemap_opts &lt;- list(treemapify::geom_treemap(alpha = 0.7), geom_treemap_text(fontface = &quot;italic&quot;, colour = &quot;white&quot;, place = &quot;centre&quot;, grow = TRUE, min.size = 1 ), theme(legend.position = &quot;none&quot;, plot.title = element_text(hjust = 0.5)) ) ( don_share_by_size &lt;- eas_20 %&gt;% select(donation_2019_c, donation_2019_c_split) %&gt;% group_by(donation_2019_c_split) %&gt;% summarise(total_don = sum(donation_2019_c, na.rm=TRUE)) %&gt;% mutate(don_share = round(total_don/sum(total_don)*100)) %&gt;% filter(!is.na(donation_2019_c_split)) %&gt;% ggplot(aes(area = total_don, fill= donation_2019_c_split, # Include percentage of total donation label = paste(donation_2019_c_split, paste0(don_share, &quot;%&quot;), sep = &quot;\\n&quot;))) + geom_treemap_opts + ggtitle(&quot;Share of total 2019 donation amount, by donation size&quot;) ) Over a third of total reported contributions reported for 2019 come from contributions over 500,000 USD, with another 20% coming from contributions between 25k and 100k. Contributions of under 2500 USD represent less than 5% of the total. Next we consider ‘which career paths are driving total donation totals?’; mapping the share of total 2019 donations similarly, accompanied by a table of their overall shares of respondents, for comparison.* * This figure excludes 486 participants who provided no response to the career question, 0.236 of the sample. These participants reported a total of $$2,766,310 in donations which makes up 25.9% of the total reported donations for 2019. #library(treemapify) ( don_by_career &lt;- eas_20 %&gt;% select(career_, donation_2019_c) %&gt;% group_by(career_) %&gt;% filter(!is.na(career_)) %&gt;% summarise(total_don = sum(donation_2019_c, na.rm=TRUE), n = n()) %&gt;% mutate(don_share = round(total_don/sum(total_don)*100), freq = n/sum(!is.na(eas_20$career_)) ) %&gt;% ggplot(aes(area = total_don , fill=freq, # Include percentage of total donation label = paste(career_, paste0(don_share, &quot;%&quot;), paste0(&quot;(Pop:&quot;, round(freq*100) , &quot;%)&quot;), sep = &quot;\\n&quot;))) + geom_treemap_opts + # theme(legend.position = &quot;bottom&quot;) + #todo -- add title to legend explaining that it&#39;s the survey pop; get better colors for this scale_fill_continuous(name = &quot;Frequency&quot;, label = scales::percent, trans = &quot;reverse&quot;) + labs(title= &quot;Share of 2019 donations by career path&quot;, subtitle = &quot;(Share of survey population in parentheses; darker = larger share)&quot;) ) career_tab &lt;- eas_20 %&gt;% mutate(Career = na_if(career_, &quot;na&quot;)) %&gt;% filter(!is.na(Career)) %&gt;% tabyl_ow_plus(Career, caption=&quot;Shares in each career path&quot;, title_case = TRUE) #Todo: the right column needs to be x100 or say &#39;share&#39; instead of &#39;percent&#39; Those reporting ‘for profit-earning to give’ career paths represent the largest share, nearly half of the total donations, despite making up only about 15% of the sample (of those answering this question). Those with ‘for profit’ careers who do not say they are earning to give donate about 15% of the total, roughly in proportion to their 12% share of the sample. However all of these differences may reflect differences in income and wealth levels, as well as differences in underlying characteristics of people who choose different career paths. Direct work does not seem to be obviously coming at the expense of donations. Those pursuing careers working at EA-affiliated non-profits account for a somewhat higher share of donations (12%) than their (8%) share of the sample. (However, we do not know how much these particular EAs would have given had they chosen a different career.) Obviously, income levels are different between these career paths. We put this in perspective in the plot below. grp_sum &lt;- function(df, xvar, yvar, groupvar) { df %&gt;% dplyr::select({{xvar}}, {{yvar}}, {{groupvar}}) %&gt;% group_by({{groupvar}}) %&gt;% drop_na({{xvar}}, {{yvar}}, {{groupvar}}) %&gt;% summarise( mn_y = mean({{yvar}}), mn_x = mean({{xvar}}), med_y = median({{yvar}}), med_x = median({{xvar}}), se_y = sd({{yvar}}, na.rm=TRUE)/sqrt(length({{yvar}})), se_x = sd({{xvar}}, na.rm=TRUE)/sqrt(length({{xvar}})) ) %&gt;% group_by({{groupvar}}) %&gt;% # Calculate confidence intervals mutate( lower = max(0, mn_y - 1.96*se_y), upper = mn_y + 1.96*se_y ) } plot_grp &lt;- function(df, groupvar, labsize=4, labangle=90, force = 1, fp = 1, mo=10, bp=1, arrow=NULL) { df %&gt;% ggplot(aes(x=mn_x, y=mn_y, label = {{groupvar}})) + geom_point() + geom_abline(intercept = 0, slope = 0.1, colour=&quot;violetred1&quot;) + geom_smooth(method=lm, alpha=0.7) + geom_errorbar(aes(ymin = lower, ymax = upper), alpha=0.7) + scale_y_continuous( oob = scales::squish) + scale_x_continuous( oob = scales::squish) + ggrepel::geom_text_repel( size = labsize, angle = labangle, max.overlaps=mo, force=1, force_pull = fp, box.padding = bp, arrow = arrow, color=&quot;brown&quot;, alpha=0.75) } ( don_inc_career_plot &lt;- eas_20 %&gt;% mutate(Career = na_if(career_, &quot;na&quot;)) %&gt;% filter(!is.na(Career)) %&gt;% grp_sum(income_c_imp_bc5k, donation_2019_c, Career) %&gt;% plot_grp(Career, labsize=3) + xlab(&quot;Mean income in USD (imputed if &lt;5k/missing)&quot;) + ylab(&quot;Mean donations, CIs&quot;) + scale_y_continuous(limits=c(-10000, 30000), oob = scales::squish) ) The plot above depicts mean income and mean donations by ‘career group,’ with 95% CI’s for the latter. We superimpose a ‘line of best fit’ (blue, with smoothed 95% intervals for this rough fit) and a ‘10% of income donation’ line (red). Unsurprisingly, for-profit ‘not-EtG’ are below the fitted line, and ‘for-profit EtG’ above this line, although 95% CIs are fairly wide. We also note that among people in non-profit careers, there are similar average incomes whether or not the non-profit is EA-aligned, but the non-profit EA people seem to donate somewhat more (although the CI’s do overlap). Next, we present reported donation amounts by income groupings (imputing income where missing or below 5000 USD).* * However, the figure does remove observations where income as well one of either country or student status is missing, thus income cannot be simply imputed from these. #p_load(treemapify) ( don_share_by_income &lt;- eas_20 %&gt;% select(donation_2019_c, income_c_imp_bc_k, income_c_imp_split) %&gt;% filter(!is.na(income_c_imp_bc_k)) %&gt;% group_by(income_c_imp_split) %&gt;% summarise(total_don = sum(donation_2019_c, na.rm=TRUE), n = n()) %&gt;% mutate(don_share = round(total_don/sum(total_don)*100), freq = n/sum(!is.na(eas_20$income_c_imp_split))) %&gt;% ggplot(aes(area = total_don, fill= freq, # Include percentage of total donation label = paste(income_c_imp_split, paste0(don_share, &quot;%&quot;), paste0(&quot;(Pop:&quot;, (round(freq*100, 1)) , &quot;%)&quot;), sep = &quot;\\n&quot;))) + geom_treemap_opts + scale_fill_continuous(name = &quot;Frequency&quot;, label = scales::percent, trans = &quot;reverse&quot;) + labs(title= &quot;Share of 2019 donations by income groups&quot;, subtitle = &quot;(Share of survey population in parentheses; darker = larger share)&quot;) ) earn_tab &lt;- eas_20 %&gt;% tabyl_ow_plus(income_c_imp_split) Compare the above graph to the ‘donations by donations size’ graph. The largest earners (the 6 people earning 1 million USD or more) represent 35% of the donations (cf the largest donors represent 36% of the donations). However, the second-highest earners, the 8 people earning between 500k and 1 million USD represent only 6% of the donations (cf 20% from the second-highest donation group). In fact, the second largest share of total 2020 donations come from the second-largest (in population) income-group in our sample, the 395 people earning between 50K and 100K USD. Finally, we report donation totals by country. First for 2019 donations alone: #p_load(treemapify) ( don_share_country &lt;- eas_20 %&gt;% select(donation_2019_c, country_big) %&gt;% group_by(country_big) %&gt;% summarise(total_don = sum(donation_2019_c, na.rm=TRUE), n = n()) %&gt;% mutate(don_share = round(total_don/sum(total_don)*100), freq = n/sum(!is.na(eas_20$country))) %&gt;% ungroup() %&gt;% filter(don_share != 0 &amp; !is.na(country_big)) %&gt;% ggplot(aes(area = total_don, fill= freq, # Include percentage of total donation label = paste(country_big, paste0(don_share, &quot;%&quot;), paste0(&quot;(Pop:&quot;, op(round(freq*100, 0)) , &quot;%)&quot;), sep = &quot;\\n&quot;))) + geom_treemap_opts + #scale_fill_continuous(name = &quot;Frequency&quot;, label = scales::percent, trans = &quot;reverse&quot;) + scale_fill_continuous(name = &quot;Frequency&quot;, label = scales::percent, trans = &quot;reverse&quot;) + labs(title= &quot;Share of 2019 donations by country&quot;, subtitle = &quot;(Share of survey population in parentheses; darker = larger share)&quot;) ) #; darker = larger share Next, pooling across all years of the EA survey (without any weighting or adjustment): ( don_share_country_all_years &lt;- eas_all %&gt;% select(donation_usd, country, year) %&gt;% filter(!is.na(country)) %&gt;% group_by(country) %&gt;% summarise(total_don = sum(donation_usd, na.rm=TRUE), n = n()) %&gt;% ungroup() %&gt;% mutate(don_share = round(total_don/sum(total_don)*100), freq = n/sum(!is.na(eas_all$country))) %&gt;% filter(don_share &gt; 0.1) %&gt;% mutate(country = snakecase::to_title_case(country)) %&gt;% ggplot(aes(area = total_don, fill= freq, # Include percentage of total donation label = paste(country, paste0(don_share, &quot;%&quot;), paste0(&quot;(Pop:&quot;, op(round(freq*100, 0)) , &quot;%)&quot;), sep = &quot;\\n&quot;))) + geom_treemap_opts + scale_fill_continuous(name = &quot;Frequency&quot;, label = scales::percent, trans = &quot;reverse&quot;) + theme(legend.position = &quot;none&quot;, plot.title = element_text(hjust = 0.5)) + labs(title= &quot;Share of total (all years) donation amounts by country&quot;, subtitle = &quot;(Share of survey population in parentheses; darker = larger share)&quot;) ) And again, ‘Winsorizing’ donations at 100K USD (setting larger donations at this value), to reduce the impact of outliers: ( don_share_country_all_years_w &lt;- eas_all %&gt;% select(donation_usd, country, year) %&gt;% filter(!is.na(country)) %&gt;% rowwise() %&gt;% mutate(donation_usd_w = min(donation_usd, 100000)) %&gt;% ungroup() %&gt;% group_by(country) %&gt;% summarise(total_don_w = sum(donation_usd_w, na.rm=TRUE), n = n()) %&gt;% ungroup() %&gt;% mutate(don_share = round(total_don_w/sum(total_don_w)*100), freq = n/sum(!is.na(eas_all$country))) %&gt;% filter(don_share &gt; 0.1) %&gt;% mutate(country = snakecase::to_title_case(country)) %&gt;% ggplot(aes(area = total_don_w, fill= freq, # Include percentage of total donation label = paste(country, paste0(don_share, &quot;%&quot;), paste0(&quot;(Pop:&quot;, op(round(freq*100, 0)) , &quot;%)&quot;), sep = &quot;\\n&quot;))) + geom_treemap_opts + scale_fill_continuous(name = &quot;Frequency&quot;, label = scales::percent, trans = &quot;reverse&quot;) + theme(legend.position = &quot;none&quot;, plot.title = element_text(hjust = 0.5)) + labs(title= &quot;Share of 100k-Winsorised donations by country; all years&quot;, subtitle = &quot;(Share of survey population in parentheses; darker = larger share)&quot;) ) #TODO - @oska -- UK and USA in all-caps above We report the shares (0-1) of the total survey population coming from each country below: #TODO - @oska -- capitalization below #TODO - @oska -- sort by shares below ( country_tab &lt;- eas_all %&gt;% group_by(country_big) %&gt;% filter(year&gt;2014) %&gt;% mutate( year_2020 = case_when( year==2020 ~ &quot;2019 share.&quot;, TRUE ~ &quot;pre-2019 share.&quot; ), `Country` = str_to_title(country_big), ) %&gt;% tabyl(`Country`, year_2020) %&gt;% adorn_percentages(&quot;col&quot;) %&gt;% .kable(digits=2, caption=&quot;Shares (0-1) of survey population by country; larger countries only&quot;, label=TRUE) %&gt;% .kable_styling() ) Table 4.3: Shares (0-1) of survey population by country; larger countries only Country 2019 share. pre-2019 share. Australia 0.04 0.05 Canada 0.03 0.04 Czech Republic 0.02 0.00 France 0.02 0.01 Germany 0.06 0.05 Netherlands 0.02 0.01 New Zealand 0.02 0.01 Norway 0.02 0.01 Other 0.11 0.06 Sweden 0.01 0.01 Switzerland 0.02 0.02 Uk 0.11 0.13 Usa 0.30 0.32 NA 0.22 0.29 and we give a year-by-year animation of the shares of donations from each country: #d_anim &lt;- &quot;Y&quot; #library(gganimate) anim_filename &lt;- here(plots_folder, &quot;animated_tree_plot.gif&quot;) if (exists(&quot;d_anim&quot;)) { if (d_anim == &quot;Y&quot;) { animated_dons_country &lt;- eas_all %&gt;% select(year, donation_usd, country_big) %&gt;% group_by(year, country_big) %&gt;% filter(year&gt;2014) %&gt;% summarise(total_don = sum(donation_usd, na.rm=TRUE)) %&gt;% mutate(don_share = round(total_don/sum(total_don)*100)) %&gt;% ggplot(aes(area = total_don, fill= country_big, # Include percentage of total donation label = paste(country_big, paste0(don_share, &quot;%&quot;), sep = &quot;\\n&quot;))) + geom_treemap_opts + ggtitle(&quot;Share of total 2019 reported donation amounts by country&quot;) anim &lt;- animated_dons_country + transition_states(year, state_length = 3) + ggtitle(&quot;Share of total {closest_state} reported donation amounts by country&quot;) gganimate::anim_save(anim_filename, anim) anim } else{ knitr::include_graphics(anim_filename) } } if (!exists(&quot;d_anim&quot;)){ knitr::include_graphics(anim_filename) } #Todo (medium importance): slo In 2019, the largest summed donation amount came from the UK (about 11% of the sample but 41% of the donations) and the USA (30% of the sample and 37% of the donations). Across all years: the USA represents the largest amount of donations, with the UK a close second, Again, the UK ‘punches far above its weight.’ Note that the UK share may be understated, if UK donors claim the matching ‘Gift Aid’ but do not report it as part of their donation.* * In the UK the government’s ‘Gift Aid’ policy supplements all reported donations made by UK taxpayers by an additional 25%. Again, these raw difference may reflect differences in income and life circumstances among survey respondents from different countries. The outsized UK share also seems to be driven by a few large outlying donations – when we Winsorise donations at 100K USD, the UK no longer overperforms. We have shown ‘where the donations were in 2019’ (and across years). However, we are not suggesting that this provides direct evidence of differences in EA generosity by country. We return to presenting a ‘controlled descriptive picture’ in our modeling work. 4.3.1 Donation (shares) versus income and GWWC pledge 2018 post: We also looked at the percentages of pre-tax income that EAs were donating, based on the 1,563 EAs who disclosed both income and donation data. As in previous years, most EAs were donating significantly less than the 10% Giving What We Can Pledge… However, as the graph below shows, there is a marked ‘bump’ in the donors giving at around the 10% figure, perhaps due to the Giving What We Can Pledge target around this amount, or due to the figure’s wider popularity as a target (e.g. in tithing). Below, we depict donations as a share of income. The histograms below are first only for those with positive reported incomes, and next with the previously discussed income imputation. The blue vertical line depicts the share of total (imputed) income donated by all respondents, with the green line depicting the median and the red line the 90th percentile. These plots show similar patterns as in 2018. scale_x_set &lt;- list(scale_x_continuous(limits=c(0,0.35), n.breaks=20)) ( don_share_inc_19_hist &lt;- eas_20 %&gt;% hist_plot(don_share_inc_19) + geom_vline_med(eas_20$don_share_inc_19, tgap=0.01) + geom_vline_mean(tot_don/tot_inc, tgap=0.01, label = &quot;Overall share&quot;) + geom_vline_90(eas_20$don_share_inc_19, tgap=0.005) + scale_x_set + labs(title=&quot;2019 Donations/Income (no imputing)&quot;, x=&quot;2019 Donations/income&quot;, y=&quot;Number of respondents&quot;) + ylim(0, 300) ) ##Todo -- Medium priority: mean is missing # todo -- low priority: make the above histogram bigger, it&#39;s smaller than the rest don_share_inc_19_hist_imp &lt;- eas_20 %&gt;% hist_plot(don_share_inc_19_imp_bc5k) + geom_vline_mean(tot_don/tot_inc_imp_bc, tgap=0.01, label = &quot;Overall share&quot;) + geom_vline_med(eas_20$don_share_inc_19_imp_bc5k, tgap=0.005) + geom_vline_90(eas_20$don_share_inc_19_imp_bc5k, tgap=0.005) + scale_x_set + labs(title=&quot;2019 Donations/Income (with imputing)&quot;, x=&quot;2019 Donations/income (with imputing)&quot;, y = &quot;Number of respondents&quot;) + ylim(0, 300) don_share_inc_19_hist_imp #Todo -- Medium priority(@oska): convert to &#39;share of respondents&#39;, add cumulative plot don_share_inc_19_hist_imp %&gt;% ggplotly() The noticeable spike at 10% likely reflects the GWWC pledge (we return to this further below). As noted above, 20% of EAs reported a donation at or above 10% of their (imputed) income in 2019. 36% reported an amount at or above 5%. #Donations and donation shares -- scatterplots by income and GWWC &#39;action&#39; p_load(ggpubr) op_ax &lt;- function(x) round(as.numeric(x), digits=2) scale_y_don &lt;- scale_y_log10( name = &quot;Donation amount (bottom-coded at $50)&quot;, # labels = scales::dollar, labels = scales::label_number_si(prefix = &quot;$&quot;), n.breaks = 10, limits = c(50, NA) ) don_income_gwwc_sp &lt;- eas_all %&gt;% filter(year==2020) %&gt;% ggpubr::ggscatter( x = &quot;income_c_imp_bc_k&quot;, y = &quot;donation_usd_min50&quot;, color = &quot;d_gwwc_ever&quot;, size = 0.8, xlab = &quot;Income in $1k USD (imputed where missing or lt 5k)&quot;, repel = TRUE, palette = &quot;jco&quot;, yscale = &quot;log10&quot;, xscale = &quot;log10&quot;, add = &quot;loess&quot;, add.params = list(color = &quot;black&quot;, fill = &quot;lightgray&quot;), conf.int = TRUE ) + labs(title = &quot;Donations by income (log scales)&quot;) + scale_x_log10(name=&quot;Income in $1K USD (imputed if &lt;5k/missing)&quot;, labels = op_ax, n.breaks=5, limits=(c(5,5000))) + labs(colour = &quot;Mentioned taking GWWC pledge&quot;) + scale_y_don + theme(axis.text.x = element_text( angle = 90, vjust = 0.5, hjust = 1 )) don_income_gwwc_sp_gwwc &lt;- eas_all %&gt;% filter(year==2020) %&gt;% ggplot(aes(x = income_c_imp_bc_k, y = donation_usd_min50, color = d_gwwc_ever)) + geom_point(size = 1, alpha = 0.7) + # draw the points geom_smooth(aes(method = &#39;loess&#39;, fill = d_gwwc_ever)) + # @Oska -- note I am using local smoothing here. scale_x_log10(name = &quot;Income in $1K USD (imputed if below 5k/missing)&quot;, n.breaks = 5, limits = c(5, 5000)) + scale_y_log10( name = &quot;Donation amount (bottom-coded at $50)&quot;, # labels = scales::dollar, labels = scales::label_number_si(prefix = &quot;$&quot;), n.breaks = 10, limits = c(50, NA) ) + scale_color_discrete(name = &quot;GWWC pledge&quot;) + scale_fill_discrete(guide = &quot;none&quot;) + theme(axis.text.x = element_text( angle = 90, vjust = 0.5, hjust = 1 ), legend.position = c(.87,.15), legend.background = element_rect(fill=alpha(&#39;blue&#39;, 0.01))) ##Todo -- Medium priority - clean up the above a bit more... get the axes better so that we can really see the &#39;large mass in the middle a bit better. Maybe slightly smaller dots and bolder smoothed lines, perhaps different colors for the CI shading for each # - perhaps use geom_pointdensity with different shapes to indicate regions of &quot;larger mass&quot; # #TODO -- Add some layer to better capture the masses *exactly at* 10pct # REVIEW # We should note that this doesn&#39;t include those who donate nothing due to the log scale (pseudo log scale is a bit weird here as well) require(ggpointdensity) don_share_income_by_X &lt;- eas_all %&gt;% filter(year==2020) %&gt;% mutate(income_c_imp_bc5k_k = income_c_imp_bc5k/1000) %&gt;% rowwise() %&gt;% mutate(don_share_inc_19_imp_bc5k = min(don_share_inc_19_imp_bc5k, 0.4)) %&gt;% ungroup() %&gt;% group_by(d_gwwc_ever_0) %&gt;% mutate(med_gwwc = median(don_share_inc_19_imp_bc5k, na.rm=TRUE)) %&gt;% ungroup() %&gt;% group_by(engage_high_n) %&gt;% mutate(med_eng = median(don_share_inc_19_imp_bc5k, na.rm=TRUE)) %&gt;% ggplot(aes(x = income_c_imp_bc5k_k, y = don_share_inc_19_imp_bc5k)) + ggpointdensity::geom_pointdensity(adjust=0.25) + geom_smooth(method = &quot;loess&quot;) + #geom_hline_med(y) + geom_hline(yintercept=0.1, linetype=&quot;dashed&quot;, size=0.5, color = &quot;red&quot;) + scale_y_continuous(labels = scales::label_percent(accuracy = 1L)) + scale_x_log10(breaks = scales::log_breaks(n=7)) + scale_color_viridis_c(&quot;density of respondents&quot;) + xlab(&quot;Income in $1K USD (imputed if missing, bottom-code at 5k)&quot;) + theme(axis.title.x = element_text(size = 10)) + ylab(&quot;Donations/Income (top-code at 40%)&quot;) don_share_income_by_engage_sp &lt;- don_share_income_by_X + geom_hline(aes(yintercept=med_eng), linetype=&quot;dashed&quot;, size=0.5, color = &quot;blue&quot;) + facet_wrap(~engage_high_n, nrow=3) + ylab(&quot;Donations/Income (top-coded at 50%)&quot;) + labs(title=&quot;By &#39;High-engagement&#39;: 2019 &#39;Don. shares of income&#39; by income (w. imputing)&quot;) don_share_income_by_gwwc_sp &lt;- don_share_income_by_X + geom_hline(aes(yintercept=med_gwwc), linetype=&quot;dashed&quot;, size=0.5, color = &quot;blue&quot;) + facet_wrap(~d_gwwc_ever_0) + labs(title=&quot;By GWWC: 2019 &#39;Don. share of income&#39; by income (w/ imputing)&quot;) How do donations relate to income, and does this relationship differ between those who mention that they took the Giving What We Can (10%) pledge? We first simply plot reported donations against income, simply dividing individuals (points) by whether they mention having taken the GWWC pledge. don_income_gwwc_sp We give a scatterplot of reported donations against income, faceted by GWWC pledge, with separate locally-smoothed conditional means (and 95% confidence intervals for these conditional means). (The figure below is for 2019 donations only.) don_income_gwwc_sp_gwwc Unsurprisingly, those with higher incomes, and those who took the GWWC pledge tend to report donating more. On average, the GWWC pledgers report giving more throughout the whole range of income, and the 95% confidence intervals are distinct for most of the range.*, ** * This agrees with what we reported in 2019: “In the EA Survey 2019 data, the median percentage of income donated by someone who had taken the GWWC Pledge was 8.87%, short of the 10% target, though there could be some noise around how respondents reported income and donations. Nevertheless, this of course could be influenced by GWWC Pledge takers being students, not employed or only recently having taken the Pledge. We addressed this question in more depth last year (link): GWWC members donate more than non-GWWC members, both absolutely and as a percentage of income but ~40% of self-reported GWWC members were not reporting donation data that is consistent with keeping their pledge, a trend most likely to be the result of attrition over time.” ** Note that the smaller group who did not respond to the GWWC pledge prompt but did provide a donation response seems to resemble the non-pledgers. We thus lump these groups together in the subsequent analysis. Next we plot donations as shares of income against income for non-GWWC pledgers (combined with non-responders) and GWWC pledgers. The median for each group is given by the dashed blue line, and the dashed red line represents 10 percent of income. don_share_income_by_gwwc_sp The relationship between income and ‘share of income donated’ dips down for the lowest incomes, but for the mass of ‘substantial donors’ the curve is fairly flat, and then seems to increase at higher incomes. As expected, GWWC pledgers tend to donate closer to 10% of income than do the rest. In each year substantially larger shares of those who report having made a GWWC pledge report donating 10% or more. Below, we tabulate this by donation year and by ’whether they report having ever made a GWWC pledge, for individuals who report income over 5000 USD and who report zero or positive donations: ( tab_don_by_year_pledge &lt;- eas_all %&gt;% filter(!is.na(d_don_10pct_bc5k) &amp; year&gt;=2015) %&gt;% mutate(`Survey year` = year, d_don_plan_10pct = as.numeric(donation_plan_usd/income_c_imp_bc5k &gt;=0.1), d_don_plan_10pct = if_else(year&lt;2018, NaN, d_don_plan_10pct)) %&gt;% group_by(d_gwwc_ever_0, `Survey year`) %&gt;% summarise(n = n(), &quot;Donated 10% of income&quot; = mean(d_don_10pct_bc5k), &quot;Donated 10% of income (plan)&quot; = mean(d_don_plan_10pct, na.rm=TRUE) ) %&gt;% rename(&quot;Ever GWWC pledge&quot; = d_gwwc_ever_0) %&gt;% adorn_rounding(digits = 2) %&gt;% kable(caption = &quot;GWWC pledgers: Don. 10%+ of income by survey year (exclusions: see text)&quot;, label=TRUE) %&gt;% .kable_styling() ) Table 4.3: GWWC pledgers: Don. 10%+ of income by survey year (exclusions: see text) Ever GWWC pledge Survey year n Donated 10% of income Donated 10% of income (plan) No/NA 2015 819 0.13 NaN No/NA 2017 673 0.16 NaN No/NA 2018 1221 0.13 0.19 No/NA 2019 1125 0.12 0.16 No/NA 2020 960 0.11 0.19 Yes 2015 352 0.36 NaN Yes 2017 354 0.35 NaN Yes 2018 668 0.40 0.53 Yes 2019 579 0.37 0.48 Yes 2020 463 0.40 0.48 Among those who report having ever taken a GWWC pledge (and who report donations, and excluding those reporting incomes below 5000 USD), less than half report donating 10% in the past year. However, this may be an underestimate, as some people are reporting having pledged for this/next year, while donation reports are for the previous year.* * Furthermore, this does not tell us that people are failing to meet an active pledge. The question asks about having ever taken the GWWC pledge’; some of these people might have ended their pledge at some point. Our 2018 post report found a rate slightly higher than 50%.** This is closer to the above figure for ‘plan to donate in the current year,’ which hovers around 50%.*** ** The rates we report may also be lower than those reported in the 2018 post because here we exclude those earning less than 5000 USD. *** In the online appendix (web link we also plot donations by income by self-reported level of engagement (1-3 versus 4-5). Unsurprisingly, those who report greater engagement tend to donate more. 4.3.2 Employment and student status We present income and donation statistics for those “statuses” with more than 50 respondents in the forest plot below (a full table of statistics for each group can be found in the bookdown appendix).* In each of the forest plots in this subsection, the blue line presents a simple linear best-fit of these points, and the red line represents a 10% donation rate. * In stratifying donation and income statistics by employment/student status we exclude those who gave no information on this question (or who answered that they prefer not to answer). (These nonresponses make up 20.4% of the sample). se &lt;- function(x) sqrt(var(x)/length(x)) sumstatvec &lt;- c(&quot;{median}&quot;, &quot;{p10}-{p90}&quot;, &quot;{mean} [{se}] ({sd})&quot;) doninclabs &lt;- list(income_k_c ~ &quot;Income in $1000 USD&quot;, donation_2019_c ~ &quot;2019 donation (in USD)&quot;, donation_2020_c ~ &quot;2020 planned donation&quot;) don_inc_by_student &lt;- eas_20 %&gt;% group_by(status_) %&gt;% mutate( status_ = as.character(status_), large_group = case_when( n()&lt;50 ~ &quot;Other&quot;, TRUE ~ status_) ) %&gt;% ungroup() %&gt;% dplyr::select(income_k_c, donation_2019_c, donation_2020_c, large_group) %&gt;% tbl_summary(by = large_group, type = c(all_continuous()) ~ &quot;continuous2&quot;, statistic = list(all_continuous() ~ sumstatvec), label = doninclabs, missing = c(&quot;no&quot;) ) %&gt;% bold_labels() %&gt;% add_n() %&gt;% add_overall() #TODO: High -- fix the column labels #todo (low) -- we use this several times and it&#39;s a good format; let&#39;s functionalise it #Todo (medium): Bootstrapping the SE of the median would be nice, see, e.g., https://clayford.github.io/dwir/dwr_12_generating_data.html library(ggrepel) # # 1.summarize donation and income (mean and 95pct CI for each) by status_ # 2. plot median (and mean) donation by income for each group (income lowest to highest) # 3. fit a line/curve of donation by income for each group (do for ) -- replace with the regression line based on the population not the groups # 4. Add error bars (for donations, not income) -- hard to do for median, though #TODO -- High Priority: Make this nice in the ways discussed (@oska it seems you have already started this) # why are the error bars not surrounding the point? # make it pretty (use your judgment), fix labels, add median colored dot, ( don_inc_status_plot &lt;- eas_20 %&gt;% mutate( status_ = str_replace_all( status_, c(&quot;_&quot; = &quot; &quot;) ) ) %&gt;% grp_sum(income_c_imp_bc5k, donation_2019_c, status_) %&gt;% plot_grp(status_, labsize=3, fp=0.3, force=5, mo=20, bp=1.5, arrow = arrow(length = unit(0.02, &quot;npc&quot;)) ) + xlab(&quot;Mean income in USD (imputed if &lt; 5k/missing)&quot;) + ylab(&quot;Mean donations, 95% CIs&quot;) + scale_y_continuous(limits=c(-10000, 30000), oob = scales::squish) ) # Todo (low): Plot regression line for full pop # Todo: HIGH -- get this to look nicer, label it better, add better axis breaks (every 5k for donation, every 20k for income) #Todo (Medium) -- add plots for the medians #Todo Donations generally track income by this aggregation, with some groups possibly ‘under-performing’ or ‘over-performing’; we return to this in our descriptive modeling.* *Note that thus is reporting means and not medians. The ‘self-employed’ group clearly reflects outliers, and it’s upper CI is truncated at 30000 to save space. 4.3.3 Donations by country Donations and income by country We report similar income and donation statistics for all countries with more than 50 respondents: ( don_income_by_ctry &lt;- eas_20 %&gt;% dplyr::select(income_k_c, donation_2019_c, donation_2020_c, country_big) %&gt;% tbl_summary( by = country_big, sort = all_categorical() ~ &quot;frequency&quot;, #reverse this ordering or maybe reverse sort by average income type = c(all_continuous()) ~ &quot;continuous2&quot;, statistic = list(all_continuous() ~ sumstatvec), label = doninclabs, missing = c(&quot;no&quot;) ) %&gt;% bold_labels() %&gt;% add_n() %&gt;% add_overall() ) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #vpgijjswgs .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #vpgijjswgs .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #vpgijjswgs .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #vpgijjswgs .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #vpgijjswgs .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #vpgijjswgs .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #vpgijjswgs .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #vpgijjswgs .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #vpgijjswgs .gt_column_spanner_outer:first-child { padding-left: 0; } #vpgijjswgs .gt_column_spanner_outer:last-child { padding-right: 0; } #vpgijjswgs .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #vpgijjswgs .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #vpgijjswgs .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #vpgijjswgs .gt_from_md > :first-child { margin-top: 0; } #vpgijjswgs .gt_from_md > :last-child { margin-bottom: 0; } #vpgijjswgs .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #vpgijjswgs .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #vpgijjswgs .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #vpgijjswgs .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #vpgijjswgs .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #vpgijjswgs .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #vpgijjswgs .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #vpgijjswgs .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #vpgijjswgs .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #vpgijjswgs .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #vpgijjswgs .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #vpgijjswgs .gt_sourcenote { font-size: 90%; padding: 4px; } #vpgijjswgs .gt_left { text-align: left; } #vpgijjswgs .gt_center { text-align: center; } #vpgijjswgs .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #vpgijjswgs .gt_font_normal { font-weight: normal; } #vpgijjswgs .gt_font_bold { font-weight: bold; } #vpgijjswgs .gt_font_italic { font-style: italic; } #vpgijjswgs .gt_super { font-size: 65%; } #vpgijjswgs .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } Characteristic N Overall, N = 1,6071 Australia, N = 82 Canada, N = 59 France, N = 51 Germany, N = 123 Netherlands, N = 51 Other, N = 402 United Kingdom, N = 218 USA, N = 621 Income in $1000 USD 1,384 Median 33 36 27 13 17 15 22 36 50 10%-90% 1-130 7-109 3-86 0-42 2-70 0-64 0-83 3-82 2-192 Mean [se] (SD) 60 [4] (136) 49 [5] (46) 41 [6] (42) 18 [3] (17) 28 [3] (29) 31 [6] (38) 37 [3] (44) 69 [17] (243) 85 [6] (146) 2019 donation (in USD) 1,397 Median 533 872 231 178 355 237 327 660 1,000 10%-90% 0-9,577 0-7,271 0-6,948 0-3,551 0-4,971 0-2,367 0-6,450 0-6,600 0-16,180 Mean [se] (SD) 7,348 [1,956] (73,113) 3,647 [971] (8,411) 2,753 [930] (6,769) 1,178 [283] (1,919) 1,582 [273] (2,850) 925 [226] (1,536) 4,069 [1,777] (31,444) 21,019 [12,693] (182,619) 7,211 [864] (20,215) 2020 planned donation 1,377 Median 1,000 1,636 761 473 947 395 592 1,320 2,000 10%-90% 0-12,020 11-12,360 0-8,676 0-4,660 17-5,823 0-4,438 0-7,000 0-7,867 0-21,000 Mean [se] (SD) 9,831 [2,001] (74,249) 4,852 [964] (8,404) 2,909 [844] (6,142) 2,026 [514] (3,450) 2,216 [360] (3,692) 1,358 [280] (1,901) 3,515 [604] (10,654) 24,930 [11,970] (170,546) 12,033 [2,345] (54,382) 1 c(&quot;Median&quot;, &quot;10%-90%&quot;, &quot;Mean [se] (SD)&quot;) #todo (medium?): make a stem-leaf thing here #todo (High): add *medians* to the above # don_inc_status_plot &lt;- eas_20 %&gt;% # dplyr::select(status_, donation_2019_c, income_k_c) %&gt;% # group_by(status_) %&gt;% # drop_na(status_, donation_2019_c, income_k_c) %&gt;% # summarise(across(c(donation_2019_c, income_k_c), # list(mean=mean, # median=median, # se = ~sd(.x)/sqrt(length(.x))))) %&gt;% # group_by(status_) %&gt;% p_load(ggimage) country_codes &lt;- tibble(country = c(&quot;Australia&quot;, &quot;Canada&quot;, &quot;France&quot;, &quot;Germany&quot;, &quot;Netherlands&quot;, &quot;Other&quot;, &quot;United Kingdom&quot;, &quot;USA&quot;), code = c(&quot;ac&quot;, &quot;ca&quot;, &quot;fr&quot;, &quot;de&quot;, &quot;nl&quot;, &quot;yt&quot;, &quot;gb&quot;, &quot;us&quot;)) ( don_inc_country_plot &lt;- eas_20 %&gt;% grp_sum(income_c_imp_bc5k, donation_2019_c, country_big) %&gt;% left_join(., country_codes, by = c(&quot;country_big&quot; = &quot;country&quot;)) %&gt;% plot_grp(country_big) + xlab(&quot;Mean income in USD (imputed if &lt;5k/missing)&quot;) + ylab(&quot;Mean donations, CIs&quot;) + scale_y_continuous(limits=c(-3000, 30000), oob = scales::squish) ) #+ggimage::geom_flag() Above, we plot donations and income by country of residence for the countries with the largest number of EA respondents. We fit a simple best-fit (least-squares) line in blue, and add a red line depicting a 10% donation rate. Again, donations generally track income, with some under and over-performers (see later modeling). The UK clearly contains some notable donation outliers, leading to very large confidence intervals for the UK mean (truncated above at 30000 USD). plot_box_pt_viol &lt;- function(df, yvar, groupvar, notch=TRUE) { df %&gt;% dplyr::select({{yvar}}, {{groupvar}}) %&gt;% ggplot() + aes({{groupvar}}, {{yvar}}) + geom_point(size = 0.30, colour = &quot;grey&quot;, position = position_jitter(seed = 42, width = 0.3, height = 0.01)) + geom_boxplot(alpha=0.7, notch=notch, color=&quot;black&quot;) + geom_violin(alpha=0.4, color = &quot;pink&quot;) + scatter_theme + scale_y_log10() } ( don_by_country_viol_20 &lt;- eas_20 %&gt;% plot_box_pt_viol(donation_2019_c, country_big, notch=TRUE) + labs(title = &quot;Donation amounts by country (2019)&quot;) ) ( don_by_country_viol_all &lt;- eas_all %&gt;% plot_box_pt_viol(donation_usd, where_live_cat, notch=TRUE) + labs(title = &quot;Donation amounts by country grouping (2013-2019)&quot;) ) ( don_by_yr_viol_all &lt;- eas_all %&gt;% mutate(year=as.factor(year)) %&gt;% plot_box_pt_viol(donation_usd, where_live_cat, year) + ggplot() + labs(title = &quot;Donation amounts by year&quot;) ) Donations, age and years in EA Next, we consider how donations may increase or decrease with ‘time-in-EA’ (i.e., ‘tenure’). As discussed in other posts and bookdown chapters, this may be reflecting differences in who stays in EA (and continues responding to the survey) as much as it reflects how people themselves change from year to year. Below, we plot donations by tenure, breaking this down by age groups. don_by_tenure_facet_age &lt;- eas_all %&gt;% filter(year==2020) %&gt;% filter(!is.na(age_ranges)) %&gt;% ggplot() + aes(x = tenure, y = donation_usd_min50) + geom_point(size = 0.15, colour = &quot;#0c4c8a&quot;, position = position_jitter(seed = 42, width = 0.1, height = 0.001)) + geom_smooth(span = 0.75) + scatter_theme + facet_grid(vars(), vars(age_ranges), scales = &quot;free&quot;) + labs(title = &quot;2019 donation by time in EA&quot;, subtitle = &quot;Faceted by Age ranges&quot;) + labs(x = get_label(eas_20$tenure)) + scale_y_don don_by_tenure_facet_age don_by_tenure_facet_age %&gt;% ggplotly() Donations appear positively associated with tenure for nearly all age groups, with perhaps some flattening out after 5 or so years, for some age groups. Donations also appear positively associated with age for each level of tenure. We return to this in our descriptive (and causally-suggestive) models. We next report the comparable chart for donation as share of income: donshare_by_tenure_facet_age &lt;- eas_20 %&gt;% filter(!is.na(age_approx_ranges)) %&gt;% ggplot() + aes(x = tenure, y = don_share_inc_19_imp_bc5k) + geom_point(size = 0.15, colour = &quot;#0c4c8a&quot;, position = position_jitter(seed = 42, width = 0.1, height = 0.001)) + geom_smooth(span = 0.75) + scatter_theme + facet_grid(vars(), vars(age_approx_ranges), scales = &quot;free&quot;) + labs(title = &quot;2019 donation as share of (imputed) income by time in EA&quot;, subtitle = &quot;Faceted by Age ranges&quot;) + labs(x = get_label(eas_20$tenure)) + ylab(element_blank()) + ylim(0, 0.3) donshare_by_tenure_facet_age donshare_by_tenure_facet_age %&gt;% ggplotly As a share of income, we again see donations positively associated with time in EA, at least for the older age groups.* * This also holds when we look within groups of ‘referrers’ (which link took a respondent to the survey.) We report a graph on this in the online appendix as a robustness check (web link). This suggests that the association with tenure is not entirely driven by differences in the composition of those referred to the survey. By referrer Next, we consider how donations vary by ‘which referrer’ (i.e., which link) took an individual to the EA survey. Again, the blue line gives linear fit (for group means), and the red line the slope for donating 10% of income. ( don_inc_referrer_plot &lt;- eas_20 %&gt;% grp_sum(income_c_imp_bc5k, donation_2019_c, referrer_cat) %&gt;% plot_grp(referrer_cat) + scale_y_continuous(limits=c(0, 15000), oob = scales::squish) + xlab(&quot;Mean income by group in USD (imputed if &lt;5k/missing)&quot;) + ylab(&quot;Mean donations by group, CIs&quot;) + ggtitle(&quot;Donation by income and referrer&quot;) ) # (Todo?) I wonder if we should get rid of the blue line and gray line for this … or replace it with one from an individual-based regression At the referrer level we see no strong association of income and donation, however, these confidence intervals are very wide. While 80000 Hours and social media appear to be ‘under-performers,’ for most groups of referrers the confidence intervals are too wide to make very strong inferences. (Furthermore, as always, these differences may reflect other underlying differences between the samples collected from these referrers, such as differences in ‘time-in-EA.’) 4.4 Donation and income for recent years We can consider the reported amounts donated in each year of the EA survey (EAS), as well as the average reported. However, neither of these can be easily interpreted to tell us whether EAs (as individual or in total) have been donating more or less in recent years; neither as individuals nor in total. The year-to-year change in survey responses, and differential representativeness makes this challenging.* * As discussed in other posts and the online bookdown supplement chapter, the EAS may also not be representative of the EA population cross-sectionally, i.e., it may over or under-represent certain demographic or interest-oriented subpopulations. Still, if this unrepresentativeness is ‘constant from year to year,’ the total reported donations in each year will at least provide a reliable measure of how the donations of this (somewhat nonrepresentative) weighted average is changing from year to year. Note that the issue of cross-sectional representativeness (and changes in this) is equally relevant to questions of ‘average donations’ as it is to questions of ‘total donations.’ (Further discussion of this can be found in the Bookdown at this point). If the EAS response rates (and the response rates to the donation question in particular) vary year-to-year in proportion to the total size of the EA population representative, we may want to simply focus on the totals, which should move in proportion to the true totals.* On the other hand, suppose the number of responses to the EAS fluctuates from year to year not in proportion to the size of EA, but its composition is representative of the EA movement as a whole. In this case it may be more reliable to report mean or median donations of EAS respondents, and combine this with extrapolations and ‘guesstimates’ based on separate estimates of changes in the size of EA (themselves in informed by data including the EA survey). To the extent that the EAS response total is both fluctuating (independently of the size of EA) and nonrepresentative, we may be only able make statements about changes in donations among particular subgroups, and even then the within-subgroup composition may change. Because of these limitations: we report both totals and averages below, we advise caution in interpreting the amounts and changes we return to this in a controlled model, which is also subject to similar limitations, we defer more detailed analysis of this question for future work. The plot and tests below depict and consider the year-to-year changes in donations as reported in the EA surveys for each year.* *We exclude the year 2014, because of the very low response rate to the donation question in this survey. We first consider donation rates in each year for those who answer the donation question (reporting 0 or positive amounts). We give the share of positive responses, the mean, median, and 80th percentile donation, and the standard deviation for each year: library(ggstatsplot) library(pairwiseComparisons) ( don_by_year_tab &lt;- eas_all %&gt;% filter (year&gt;=2015) %&gt;% sumtab(donation_usd, year, caption=&quot;Donations by year&quot;, digits=c(0, 0, 2, 0, 0, 0,0)) %&gt;% kable_styling() #redundant but helps with parsing ) Table 4.3: Donations by year year N share &gt; 0 Mean Median P80 Std.dev. 2015 1171 0.76 5775 333 3759 (39271.5) 2017 1028 0.84 9505 657 5790 (75452.24) 2018 1889 0.85 9763 740 5201 2019 1704 0.82 9370 684 5000 (87598.4) 2020 1423 0.80 7516 528 4347 (72810.66) The above only considers people who did answer donation questions. At an extreme we could consider all non-responses as reflecting people who made (little or) no donations, for a lower bound on on donation rates. As a compromise measure, probably a tighter lower bound, we might assume that people willing to report their incomes are generally willing to answer financial questions. Thus if they do not report their donations it seems more reasonable to suspect that they did not donate in a big way. We thus consider the subset of the above who reported their income, considering similar statistics as above for a modified donation variable, coded as ‘0’ where the donation was not reported. ( don0_by_year_tab &lt;- eas_all %&gt;% filter(!is.na(income_c) &amp; year&gt;2014) %&gt;% #rowwise() %&gt;% #mutate(donation_usd_0 = if_else(is.na(donation_usd), 0, donation_usd)) %&gt;% #ungroup() %&gt;% sumtab(donation_usd_0, year, caption=&quot;Donations by year for those reporting income (missings coded as 0)&quot;, digits=c(0, 0, 2, 0, 0, 0, -1, 0)) %&gt;% kable_styling() ) Table 4.3: Donations by year for those reporting income (missings coded as 0) year N share &gt; 0 Mean Median P80 Std.dev. 2015 1033 0.69 4746 250 3094 (35095.05) 2017 1008 0.82 8905 615 5118 (75243.94) 2018 1835 0.83 9952 740 5201 (139809.56) 2019 1682 0.82 9443 684 5000 (88165.41) 2020 1409 0.80 7452 528 4098 (73109.73) #todo same for GWWC people (member_gwwc needs reconciling) #todo -- include a &#39;total donations row&#39;. maybe plot/graph this stuff; Next, we present a combined scatterplot, violin plot, and stem and leaf plot, depicting the densities of donation amounts in each year. We present this first with level outcomes (but log scales) and then for the ‘log (donation+1)’ outcome. ( don_by_year_viol_test &lt;- eas_all %&gt;% #select(donation_usd_min50, year) %&gt;% #select(donation_usd, year) %&gt;% mutate(year = year-1) %&gt;% filter(year&gt;2014) %&gt;% ggbetweenstats(y = donation_usd, x = year, ylab = &quot;Donations (USD)&quot;, # plot.type = &quot;violin&quot;, # type of plot type=&quot;parametric&quot;, conf.level = 0.95, # pairwise.display = &quot;significant&quot;, #p.adjust.method = &quot;hol&quot;, #results.subtitle = &quot;false&quot;, title = &quot;Donations by year, 2016-2020&quot; ) + theme(legend.position=&quot;none&quot;) + ylim(50, NA) + scale_y_continuous(trans = &quot;pseudo_log&quot;, breaks = breaks, labels = scales::dollar_format()) ) ( don_by_year_viol_test_ldon &lt;- eas_all %&gt;% #select(donation_usd_min50, year) %&gt;% #select(donation_usd, year) %&gt;% mutate(year = year-1, ldon1 = log(donation_usd+1)) %&gt;% filter(year&gt;2014) %&gt;% ggbetweenstats(y = ldon1, x = year, ylab = &quot;Log (Donations +1)&quot;, # plot.type = &quot;violin&quot;, # type of plot type=&quot;parametric&quot;, conf.level = 0.95, # pairwise.display = &quot;significant&quot;, #p.adjust.method = &quot;hol&quot;, #results.subtitle = &quot;false&quot;, title = &quot;(Log) donations by donation year, 2016-2019&quot; ) + theme(legend.position=&quot;none&quot;) ) # + geom_signif(comparisons = list(c(&quot;2018&quot;, &quot;2019&quot;), c(&quot;2014&quot;, &quot;2019&quot;)), step_increase = 0.05, test = &quot;wilcox.test&quot;) #%&gt;% ggplotly() #Below: replaced this with &#39;wilcox, the nonparametric test&#39; ... but note that is on top of the tests given by the ggbetweenstats command #+ geom_signif(comparisons = list(c(&quot;2018&quot;, &quot;2019&quot;), c(&quot;2017&quot;, &quot;2019&quot;), c(&quot;2013&quot;, &quot;2019&quot;)), step_increase = 0.1, test = &quot;wilcox.test&quot;) While the linear plots and tests of donation amounts suggest no substantial or significant differences in overall donations between these years, the log specification does suggest some year-to-year differences, with (log) 2019 donations being significantly lower than 2017 donations, even after accounting for multiple comparisons. We return to this, to some extent, in our descriptive modeling.* *While this may merit further investigation, the differences in response composition across years make statistical inference challenging, and we thus do not make this our main focus. Cross-year differences could be inflated or masked by these changes. 4.5 Which charities (causes and categories) are EAs donating to? As noted in the introduction, only a small share of respondents report where they are donating. We group this into several categories summarized below, reporting for only those 429 respondents who indicated at least one category of donations. #TODO - HIGH: add better cause labels to this, visualise it in a way that conveys the aggregate shares of donations counts and amounts #created near the top of this file don_stats (#tab:don_stats)Donations by category (where indicated) Variable Number of Responses Number reporting donation to cause Share of reporters donating to cause Mean donation of reporters (including 0’s) Sd Median 90th pct Global health + development 429 266 0.62 3971.7 21405.3 153.9 6017.6 Animal welfare 429 117 0.27 1503.7 11025.4 0 964.5 EA meta and organization 429 74 0.17 771.4 7106.9 0 261.7 Long term &amp; AI 429 78 0.18 975.3 9963.9 0 345.6 Other 429 47 0.11 874.4 12863.9 0 25.3 As in previous years, ‘Global health and development’ is the largest category, both in terms of number of reported donations, and in terms of mean (and median, and 90th percentile) donations (we give the mean including zeroes, for those who reported any specific category of donation). Below, we depict the amounts and density of donations for each category, with the vertical axis on a logarithmic scale. The width of the violin plot depicts the smoothed density. In the box, the horizontal lines represent medians for each, lower and upper margins of the box 25th and 75th percentiles, “whisker” lines extends from the box to to the largest (smallest) value no further than 1.5 \\(\\times\\) the inter-quartile range, and large dots represent outlying points beyond the edge of the whiskers. ##TODO -- #sort by reverse frequency of donations to a cause #TODO: bottom code and change the scale on this, time permitted ( don_by_cause_viol &lt;- eas_20 %&gt;% filter(num_named_dons&gt;0) %&gt;% select(where_don_vars, action_gwwc_f) %&gt;% gather(cause, don, -action_gwwc_f) %&gt;% ggplot() + aes(cause, don) + geom_violin() + geom_boxplot() + ylab(&quot;Donation amount&quot;) + geom_point(size = 0.30, colour = &quot;#0c4c8a&quot;, position = position_jitter(seed = 42, width = 0.3, height = 0.01)) + scatter_theme + scale_y_log10(labels = scales::label_number_si(prefix = &quot;$&quot;), n.breaks = 10) + scale_x_discrete(labels = function(x) str_wrap(all_char_labels, width = 10)) + labs(title = &quot;Donation amounts by category: see description above&quot;) ) #Todo (Low to medium) ... @oska: if it&#39;s easy-ish, maybe gganimate this one across years? #@David: Kinda difficult to do this as the variables in where_don_vars don&#39;t seem to align with eas_all #@oska -- it is there, in variables like `donate_[charity]_year` but it would require considerable data cleaning work. Will ask/see if it&#39;s worth it. We can also check whether donations to each cause (incidence and amounts) vary by whether the person (ever) took a GWWC pledge. Below, we present scatterplots + violin + box plots for donation (USD amounts) to each category, split by GWWC pledge status. #TODO -- High Priority (@oska): clean up the below to be more readable, add the mean and a CI for the mean ( don_by_cause_viol_gwwc &lt;- eas_20 %&gt;% filter(num_named_dons&gt;0 &amp; !is.na(action_gwwc_f)) %&gt;% select(where_don_vars, action_gwwc_f) %&gt;% gather(cause, don, -action_gwwc_f) %&gt;% ggplot() + aes(cause, don, color=action_gwwc_f) + scale_color_discrete(name=&quot;GWWC pledge&quot;, labels=c(&quot;No&quot;, &quot;Yes&quot;)) + geom_violin() + geom_boxplot(notch=TRUE) + geom_point(size = 0.30, colour = &quot;#0c4c8a&quot;, position = position_jitter(seed = 42, width = 0.3, height = 0.01)) + scatter_theme + scale_y_log10() + scale_x_discrete(labels = function(x) str_wrap(all_char_labels, width = 10)) ) The details of these plots are similar to the previous plot (“Donation amounts by category…,” see description above). However, here the lower and upper margins of the (now ‘notched’) box present an estimate of 95% confidence interval for medians (for those reporting at least one category of donations and reporting GWWC status). We see that these mainly overlap, but perhaps less so for “EA meta and organization,” which GWWC pledgers seem to give more to. Below, we tabulate donations to each cause, for each of these groups. The final column in each table presents a statistical test for significant differences in means each donation category by GWWC status. (Note that ‘no significance stars’ implies a lack of statistical significance at the \\(p&lt;0.10\\) level in two-tailed tests). don_stats_by_gwwc Table 4.4: Donations by category (where indicated), by GWWC Variable N Responses Share positive Mean Median N Responses Share positive Mean Median Test GWWC Pledge No Yes Global health + development 241 0.59 2832.7 1144.1 187 0.66 5450.2 1854.9 F=1.573 Animal welfare 241 0.22 1480.4 867.1 187 0.34 1531 495.5 F=0.002 EA meta and organization 241 0.12 696.4 553.1 187 0.24 872.1 335.7 F=0.064 Long term &amp; AI 241 0.13 1144.7 830 187 0.25 762.1 274.8 F=0.155 Other 241 0.06 1289.5 1103.3 187 0.17 344.1 96.8 F=0.567 Next, as above, but for donation incidence (i.e., for ‘whether someone reports a donation in a particular cause category’): ddon_stats_by_gwwc Table 4.5: Binary: Indicated donating to category, by GWWC Variable N Responses Donated to… ? N Responses Donated to… ? Test GWWC Pledge No Yes Global health + development 241 187 X2=2.399 … No 100 41% 63 34% … Yes 141 59% 124 66% Animal welfare 241 187 X2=7.897*** … No 189 78% 123 66% … Yes 52 22% 64 34% EA meta and organization 241 187 X2=8.283*** … No 211 88% 143 76% … Yes 30 12% 44 24% Long term &amp; AI 241 187 X2=9.831*** … No 210 87% 140 75% … Yes 31 13% 47 25% Other 241 187 X2=11.681*** … No 226 94% 155 83% … Yes 15 6% 32 17% Here, the differences are substantial, and in some cases, statistically significant (three stars indicates statistical significance at the \\(p&lt;0.01\\)) level in a two-tailed test). # #TODO -- High Priority (@oska): -- the below is a mess... we want both the frequency table and test for each of these ... but how to do it. I feel like I&#39;ve done this before. maybe the function in rstuff `fisherme` would help? # TODO (high-medium): Once we get it to work, do similar plots and tests for different &#39;which cause&#39; comparisons ... fisher_cats &lt;- eas_20 %&gt;% filter(num_named_dons&gt;0) %&gt;% dplyr::select(all_of(where_don_vars)) %&gt;% lapply(janitor::fisher.test, y = eas_20$action_gwwc_f[eas_20$num_named_dons&gt;0], simulate.p.value=TRUE) As suggested in the first of the two tables above, among those who report a charity category, those who took the GWWC pledge tend to give as much or more on average to each category (other than perhaps Long Term &amp; AI), although none of these individual differences meet conventional statistical significance in simple F-tests (note that these tests are fairly low-powered due to small sample sizes). As the second table illustrates, GWWC pledgers are more likely to have donated to each of these categories, and this difference is statistically significant in standard chi-sq tests for all categories except ‘Global Health and Development.’ This can be seen seen in the \\(\\chi^2\\) tests in the “Donated to category” table, as well as in uncorrected Fisher’s exact tests: \\(p=\\) 0.1 for ‘Global Health and Development,’ \\(p&lt;0.01\\) for all other categories. 4.6 Donations: plans and aspirations versus actual (reported) donations #filtering and shaping functions f_don_plan_by_year &lt;- function(df=eas_all) { #adjusting for comparing planned and actual donation for same year in question (but not always for &#39;same individuals&#39;) {df} %&gt;% select(year, donation_usd, donation_plan_usd) %&gt;% gather(donation_type, value, -year) %&gt;% mutate(year = if_else(donation_type == &quot;donation_plan_usd&quot;, year, year-1)) %&gt;% mutate(year = fct_rev(as.factor(year)), donation_type = fct_recode(donation_type, &quot;Planned Donation&quot; = &quot;donation_plan_usd&quot;, &quot;Donation&quot; = &quot;donation_usd&quot;)) %&gt;% filter(year %in% c(2016, 2017, 2018, 2019, 2020)) } f_don_18_20 &lt;- function(df=eas_all) { #this is for comparing to &#39;planned donation&#39; (next year) df %&gt;% dplyr::filter(year %in% c(&quot;2018&quot;, &quot;2019&quot;,&quot;2020&quot;)) %&gt;% group_by(year) %&gt;% select(year, donation_usd, donation_plan_usd) %&gt;% gather(donation_type, value, -year) } f_next_d_don &lt;- function(df=eas_all) { #same as f_don_18_20, but instead of gather it constructs a differenced variable `next_d_don` df %&gt;% dplyr::filter(year %in% c(&quot;2018&quot;, &quot;2019&quot;,&quot;2020&quot;)) %&gt;% select(year, donation_usd, donation_plan_usd) %&gt;% transmute(next_d_don = donation_plan_usd - donation_usd) } #Construct key tibbles to use in comparing planned and actual for 2019 demographics &lt;- c(&#39;age&#39;, &#39;gender&#39;, &#39;country&#39;, &#39;employ_status&#39;) # Filtering for those present in both datasets planned_actual_2019 &lt;- eas_all %&gt;% filter(year %in% c(2019, 2020) &amp; !is.na(ea_id)) %&gt;% select(ea_id, donation_usd, donation_plan_usd, year) %&gt;% distinct() %&gt;% group_by(ea_id) %&gt;% filter(n() == 2) %&gt;% # Filter for those appearing in both years pivot_wider(names_from = &quot;year&quot;, values_from = c(&quot;donation_usd&quot;, &quot;donation_plan_usd&quot;)) %&gt;% # Remove unnecessary columns select(-donation_plan_usd_2020, -donation_usd_2019) %&gt;% # drop_na() %&gt;% # Ensure that each participant had planned donation from 2019 and actual donation from 2020 # TODO - fix, this is dropping everything rename(donation_2019 = donation_usd_2020, planned_donation_2019 = donation_plan_usd_2019) %&gt;% # Add demographic information left_join(., select(eas_20_cy, all_of(demographics), ea_id, action_gwwc, start_date, end_date, income_c), by = &quot;ea_id&quot;) #Convert to long format for ggplot planned_actual_2019_l &lt;- planned_actual_2019 %&gt;% group_by(ea_id) %&gt;% gather(donation_type, value, donation_2019, planned_donation_2019) ## helper functions f_19_hyp &lt;- function(df) { #2019 data for donation difference df %&gt;% filter(donation_2019&gt;0 &amp; planned_donation_2019&gt;0) %&gt;% #positive don in each year transmute(don_diff = donation_2019 - planned_donation_2019) #only the difference is used; this adds an &#39;attribute&#39; to this object } #test_rep_don_diff_mn_19 #point hypothesis of 0 mean (+attribute) #1000 replications of the relevant &#39;data&#39; #test_rep_don_diff_med_19: as above but for median #test_rep_next_d_don_mn_18_20 #for actual vs *next* year&#39;s plan (means) #test_rep_next_d_don_med_18_20 ... (medians) #### Linked tests: New Purr testing framework ##### # ...Alternate between testing mean and median = 0 #### mean_zero_hyp &lt;- list(null = &quot;point&quot;, mu = 0) med_zero_hyp &lt;- list(null = &quot;point&quot;, med = 0) hyps &lt;- list(mean_zero_hyp, med_zero_hyp) # ...Stats to calculate ##### stat_mean &lt;- list(list(stat = &quot;mean&quot;)) stat_median &lt;- list(list(stat = &quot;median&quot;)) bs_1000 &lt;- list(reps = 1000, type = &quot;bootstrap&quot;) #dataframes for testing &#39;current less next donation&#39; and &#39;actual less planned donation&#39; df_next_don &lt;- eas_all %&gt;% f_next_d_don df_don_diff &lt;- planned_actual_2019 %&gt;% f_19_hyp n &lt;- 4 # Total number of tests ... mean and median for each dataframe (better to softcode this?) responses &lt;- c( rep(&quot;don_diff&quot;, n/2), rep(&quot;next_d_don&quot;, n/2)) p_value_directions &lt;- rep(&quot;two_sided&quot;, n) # ... Functionalize #### dfs &lt;- list( rep(list(df_don_diff), n/2), rep(list(df_next_don), n/2)) linked_df_labels &lt;- c(rep(&quot;2019-20 linked responses&quot;, 2), rep(&quot;2018-2020 all responses&quot;, 2)) linked_test_var_type &lt;- c(rep(&quot;Actual vs Planned&quot;, 2), rep(&quot;&#39;Next year&#39; vs Current&quot;, 2)) linked_tests_df &lt;- tibble(df = do.call(c, dfs), # Dataframes (needs tidying) # Stats to calculate stat = rep(c(stat_mean, stat_median), n/2), # Hypotheses to test hypothesis = rep(hyps, n/2), # Samples to generate gen = rep(list(bs_1000), n), # Outcome variables response = responses, # Direction for p-value calculation p_val_dir = rep(&quot;two_sided&quot;, n)) # .... actually run tests and collect pvalues etc #### linked_tests_df &lt;- linked_tests_df %&gt;% mutate(results = pmap(., test_hypothesis)) #test_hypothesis was defined in `hypothesis_test.R`; it runs the steps in the Infer testing package with options selected based on the content of the arguments. linked_tests_results &lt;- extract_hyp_results(linked_tests_df) %&gt;% #extract and label key results for reporting and plotting mutate(data_label = linked_df_labels, data_type = linked_test_var_type) # ... make a tibble of the relevant dataframes and &#39;test formula elements&#39; #### unlinked_tests_df &lt;- tibble(df = do.call(c, unlinked_data), formula = rep(list(unlinked_formula), n), hypothesis = rep(hyp_unlinked, n), gen = rep(list(perm_200), n), stat = c(rep(d_order_diff_means, n-1), d_order_next_diff_means), p_val_dir = rep(&quot;two_sided&quot;, n)) # Column labels rename_test_results &lt;- c(&quot;Statistic&quot; = &quot;stat&quot;, &quot;Null type&quot; = &quot;null&quot;, &quot;Null value&quot; = &quot;null_value&quot;, &quot;Point estimate&quot; = &quot;point_estimate&quot;, &quot;CI Lower&quot; = &quot;lower_ci&quot;, &quot;CI Upper&quot; = &quot;upper_ci&quot;, &quot;P-value&quot; = &quot;p_value&quot;, &quot;Sample&quot; = &quot;data_label&quot;) # This can be used for plotting full_test_results &lt;- dplyr::bind_rows(linked_tests_results, unlinked_diff_in_means_results, unlinked_diff_in_medians_results) %&gt;% select(-c(order)) %&gt;% mutate(across(c(stat, null, p_val_dir), ~ snakecase::to_sentence_case(.x))) # This forms the basis for tables/displaying stats full_test_results_clean &lt;- full_test_results %&gt;% select(-c(reps, type, formula, p_val_dir, response)) %&gt;% rename(!!rename_test_results) %&gt;% mutate(Statistic = str_replace_all(Statistic, c(&quot;means&quot; = &quot;Mean&quot;, &quot;medians&quot; = &quot;Median&quot;, &quot;Diff&quot; = &quot;Difference&quot;))) #making tables #For linked tests: current_next_test_results_clean &lt;- full_test_results_clean %&gt;% filter(data_type == &quot;&#39;Next year&#39; vs Current&quot;) %&gt;% select(-c(data_type, null_dist)) planned_v_actual_test_results_clean &lt;- full_test_results_clean %&gt;% filter(data_type == &quot;Actual vs Planned&quot;) %&gt;% select(-c(data_type, null_dist)) planned_v_actual_test_table &lt;- planned_v_actual_test_results_clean %&gt;% select(-c(`Null value`, `Null type`, `Sample`)) %&gt;% kable(caption = &quot;Actual minus planned donations for 2019, linked participants (2019-20)&quot;, digits=c(0,0,0,3)) %&gt;% kable_styling() current_next_test_table &lt;- current_next_test_results_clean %&gt;% select(-c(`Null value`, `Null type`, `Sample`)) %&gt;% kable(digits=c(0,0,0,0,3), caption = &quot;Planned minus last year&#39;s donation, 2018-20, all participants who report donations&quot;) %&gt;% kable_styling() #making tables for UNLINKED tests: planned_actual_unlinked_results_table &lt;- full_test_results_clean %&gt;% arrange(match(Sample, c(&quot;Full sample (2018-19 donation years)&quot;, &quot;Involved before 2019 (2018-19 don)&quot;, &quot;GwwC only (2018-19 don)&quot;, &quot;&#39;Matched individuals&#39;&quot;))) %&gt;% filter(`Null type` == &quot;Independence&quot; &amp; data_type == &quot;Actual - Planned&quot; ) %&gt;% select(-c(data_type, null_dist, `Null value`, `Null type`)) %&gt;% select(Sample, Statistic, everything()) %&gt;% kable(caption = &quot;Actual versus Planned donation distributions: permutation tests&quot;, digits=c(0,0,0,0,0,3)) %&gt;% kable_styling() next_current_unlinked_results_table &lt;- full_test_results_clean %&gt;% filter(`Null type` == &quot;Independence&quot; &amp; data_type == &quot;&#39;Next year&#39; - &#39;this year&#39;&quot; ) %&gt;% select(-c(data_type, null_dist, `Null value`, `Null type`)) %&gt;% select(Sample, Statistic, everything()) %&gt;% kable(caption = &quot;&#39;Next year (plan)&#39; - &#39;this year&#39; donation distributions: permutation tests&quot;, digits=c(1,1,1,3)) %&gt;% kable_styling() Do people meet or exceed the amount they intended or planned to donate for the next year? What factors relate to this? Our surveys provide some evidence. In recent surveys, we have asked “In [current year] how much do you currently plan to donate?” We also ask “in [previous year], roughly how much money did you donate?” The EA surveys have been released at various points in the year: In 2017, the survey was released in April; thus the ‘plan’ was reported only about 1/3 of the way through the year (or slightly later, depending on response time). In 2018, the survey was released in May. In 2019, it was released in August, about 3/4 of the way throughout the year. Thus, for each of these years, the year-to-year comparison may tell us something about whether people lived up to their plans. This could be particularly relevant for the 2017 and 2018 surveys, but also relevant for 2019-20, particularly if donations tend to be clustered at years’ end (e.g., Christmas giving, Giving Tuesday in November).* * This clustering seems to hold true for giving in the USA overall. E.g., Charity Navigator (citing the ‘Digital giving index’) states that 31% of annual giving occurred in the month of December. In our 2019 post we wrote: We also asked respondents how much they planned to donate in 2019. … The median planned donation for 2019 was 1,074.98 USD among all EAs, and 3,000 USD among full-time employed non-student EAs. Below, we compare this 2019 report of planned-2019 donation to reports from the 2020 EAS of actual 2019 donations. We report this for several different groupings below, as well as for other pairings of surveys. 2019 Planned vs. actual: Individuals present in both surveys We first consider those 441 respondents who can be matched across the 2019 and 2020 surveys (through an anonymized email). The plots below cover only respondents who appear in both samples and provide planned and actual donation values. These individuals make up 22.9% of the total respondents that appear in the 2020 sample and 15% of the total respondents across 2019 and 2020.* * These EAs, who happened to respond to the survey in both years and give a matchable email, may not be typical EAs; we discuss this further below # Create plots for planned and actual donations matched across 2019 scales_point_density_min50 &lt;- list(limits = c(50, 500000), trans = scales::pseudo_log_trans(base=10), breaks = breaks, labels = scales::dollar_format()) planned_actual_2019_density &lt;- planned_actual_2019_l %&gt;% rowwise() %&gt;% mutate(value = max(value, 50)) %&gt;% ungroup() %&gt;% ggplot() + geom_density(aes(x = value, fill = donation_type), alpha = 0.5) + do.call(scale_x_continuous, scales_point_density_min50) + scale_y_continuous(breaks = density_breaks, expand = c(0,0)) + ggtitle(&quot;Actual vs Planned 2019 donations&quot;, subtitle = &quot;Donations bottom-coded at $50; subset: those who can be matched across surveys)&quot;) + theme(legend.position = &quot;bottom&quot;, legend.margin=margin(t = -0.6, unit=&#39;cm&#39;)) + # Shift legend position up xlab(&quot;&quot;) + ylab(&quot;Density&quot;) + scale_fill_discrete(name = &quot;&quot;, labels = to_title_case(unique(planned_actual_2019_l$donation_type))) # Define same parameters for x and y axis scales_point_density &lt;- list(limits = c(0, max_lim), trans = scales::pseudo_log_trans(base=10), breaks = breaks, labels = scales::dollar_format()) planned_actual_2019_pointdensity &lt;- planned_actual_2019 %&gt;% # ggplot(aes(y = donation_2019, x = planned_donation_2019)) + rowwise() %&gt;% mutate(planned_donation_2019 = max(planned_donation_2019, 50), donation_2019 = max(donation_2019, 50)) %&gt;% ungroup() %&gt;% ggplot(aes(y = donation_2019, x = planned_donation_2019)) + ggpointdensity::geom_pointdensity(adjust = 0.25) + geom_abline(slope = 1, intercept=0, linetype = &quot;dotted&quot;) + geom_smooth() + do.call(scale_x_continuous, scales_point_density_min50) + do.call(scale_y_continuous, scales_point_density_min50) + scale_color_viridis_c(&quot;Neighbours&quot;) + #scale_size_continuous(&quot;Income&quot;, labels = scales::label_number_si()) + ylab(&quot;Actual 2019 Donation (bottom-coded @ $50)&quot;) + xlab(&quot;Planned 2019 donation (bottom-coded @ $50)&quot;) + ggtitle(&quot;Planned &amp; actual donations 2019 (cross-survey matches)&quot;) #@oska I added a geom_smooth. If you can get it to work with the income-size and legends looking good, let&#39;s put that back (TODO) #We can also trim the right horizontal axis perhaps (maybe that can be set more generally above?) Below, we plot planned and actual 2019 donations for these respondents.* * As the distribution of values is highly negatively skewed, we present this on a logarithmic scale, with values from 0-50 USD ‘bottom-coded’ as 50 USD. planned_actual_2019_density Reassuringly, these distributions largely overlap. We separate the above graph by whether the individual made a GWWC pledge: ( planned_actual_gwwc &lt;- planned_actual_2019_l %&gt;% rowwise() %&gt;% mutate(value = max(value, 50)) %&gt;% ungroup() %&gt;% filter(!is.na(action_gwwc)) %&gt;% mutate(action_gwwc = as.factor( if_else(action_gwwc == 1, &quot;GWWC Pledge&quot;, &quot;No GWWC Pledge&quot;) ) )%&gt;% # mutate(value = value + 1) %&gt;% ggplot() + geom_density(aes(x = value, fill = donation_type), alpha = 0.5) + scale_x_log10(labels = scales::label_number_si(prefix = &quot;$&quot;)) + ggtitle(&quot;Actual vs Planned 2019 donations by &#39;made GWWC pledge&#39;&quot;, subtitle=&quot;Linked individuals, log scale&quot;) + xlab(&quot;Donation value, bottom-coded at $50&quot;) + ylab(&quot;Density&quot;) + facet_grid(action_gwwc ~ . ) + scale_fill_discrete(name = &quot;&quot;, labels = to_title_case(unique(planned_actual_2019_l$donation_type))) ) #TODO (\\@oska) -- maybe do this specifically for a year in which there is a large gap in timing -- perhaps 2018 is the best as it was &lt;ay (1/2 the year) and we think it&#39;s a reliable data year #TODO: Med-high -- test for difference in planned and actual (a &#39;shift&#39;) and ideally test for a difference in difference between GWWC and non-GWWC The above graphs do not suggest large differences in these distributions.* However, ‘visual inspection’ risks reading patterns into noise, and vice-versa; this speaks for formal statistical testing. In future modeling we may also wish to consider whether this could also reflect ‘regression to the mean’; those who report planning an unusually high (low) amount may tend to actually donate a more typical amount, i.e., a lower (higher) amount. We ran a series of simulation-based ‘permutation tests’ to consider compare the medians and means of the distributions of planned and actual donations for these linked individuals. Results are included in the table “Actual minus planned donations for 2019, linked participants (2019-20)” in the section Planned vs. actual: All respondents. These tests are inconclusive (not statistically significant, with wide confidence intervals), However, note that we are currently considering these distributions rather than the individual differences for linked individuals’; we present the latter in the next subsection. Donations versus plans (same individuals, linked) While the graphs and figures above help us understand whether the distribution of planned and actual gifts differ, it does not tell us whether any individual’s donation meets or exceeds his or her plan. As we are considering individuals present in both surveys, we can connect their donation responses across years. The graph below shows the distribution over the difference in planned and actual 2019 donations for those matched across the years. Here a negative value corresponds to an actual donation being lower than planned. #TODO [Medium-High] -- incorporate it in so it will work for split plots, for &#39;same year&#39;, etc. m_dd &lt;- planned_actual_2019 %&gt;% transmute(don_diff = donation_2019 - planned_donation_2019) %&gt;% ungroup() %&gt;% dplyr::summarize(mn_dd=mean(don_diff, na.rm=TRUE), med_dd = median(don_diff, na.rm=TRUE) ) ( actual_planned_2019 &lt;- planned_actual_2019 %&gt;% mutate(don_diff = donation_2019 - planned_donation_2019) %&gt;% ggplot(aes(x = don_diff)) + geom_density(alpha=0.5, fill=&quot;blue&quot;) + scale_x_continuous(trans = pseudo_log_trans(base=10), breaks = c((-1)*breaks*2, breaks*2), labels = label_number_si(prefix = &quot;$&quot;)) + geom_vline(xintercept=m_dd$mn_dd, size=1.5, color=&quot;green&quot;) + # this code is lame, we can improve it geom_vline(xintercept=m_dd$med_dd, size=1.5, color=&quot;red&quot;) + # this code is lame, we can improve it geom_vline(xintercept=0) + # coord_flip() + labs(title = &quot;2019 donations: actual minus planned&quot;, caption = &quot;Red line: Median, Green line: Mean&quot; ) + xlab(&quot;Actual - planned for same year&quot;) + ylab(&quot;&quot;) ) # TODO: keep improving this guy Planned and actual donations are highly correlated (\\(\\rho =\\) 0.948). While substantial shares report substantially less or more than their plan, this more or less balances out, with some tendency towards donating more than planned. In fact, the mean difference between donation and plan is 1,139 USD in excess of plan (the green line), while the median of the differences is 67.9 USD. Considering that the zeroes might have been quick and uncareful mis-responses, we repeat the same plot for those who report positive planned and actual donations in the consecutive years, and we also compare these for GWWC pledgers versus non-pledgers: ( actual_planned_2019 &lt;- planned_actual_2019 %&gt;% mutate(don_diff = donation_2019 - planned_donation_2019) %&gt;% ggplot(aes(x = don_diff)) + geom_density(alpha=0.5, fill=&quot;blue&quot;) + scale_x_continuous(trans = pseudo_log_trans(base=10), breaks = c((-1)*breaks*2, breaks*2), labels = label_number_si(prefix = &quot;$&quot;)) + geom_vline(xintercept=m_dd$mn_dd, size=1.5, color=&quot;green&quot;) + # this code is lame, we can improve it geom_vline(xintercept=m_dd$med_dd, size=1.5, color=&quot;red&quot;) + # this code is lame, we can improve it geom_vline(xintercept=0) + # coord_flip() + labs(title = &quot;2019 donations: actual minus planned&quot;, caption = &quot;Red line: Median, Green line: Mean&quot; ) + xlab(&quot;Actual - planned for same year&quot;) + ylab(&quot;&quot;) ) ( actual_planned_2019_no_0_bygwwc &lt;- planned_actual_2019 %&gt;% filter(!is.na(action_gwwc)) %&gt;% filter(donation_2019&gt;0 &amp; planned_donation_2019&gt;0) %&gt;% mutate(don_diff = donation_2019 - planned_donation_2019 ) %&gt;% ggplot(aes(x = don_diff, y = as.factor(action_gwwc), fill = factor(stat(quantile)))) + stat_density_ridges( geom = &quot;density_ridges_gradient&quot;, calc_ecdf = TRUE, quantiles = 4, quantile_lines = TRUE ) + scale_fill_viridis_d(name = &quot;Quartiles&quot;) + scale_x_continuous(trans = pseudo_log_trans(base=10), breaks = c((-1)*breaks*2, breaks*2), labels = label_number_si(prefix = &quot;$&quot;)) + geom_vline(xintercept=0) + ggtitle(&quot;2019 donations (no zeroes): actual minus planned, by GWWC-pledge&quot;) + xlab(&quot;&quot;) + ylab(&quot;&quot;) ) The results are similar – substantial shares outperformed their plans, and substantial shares underperformed, but the positives seem to outweigh the negatives. For both GWWC and non-GWWC pledgers the median donation exceeds the plan (by around 200 USD). We do not see striking differences between the GWWC pledgers and non-pledgers by this measure.* * Although the plot loosely suggests that the distribution for GWWC pledgers is shifted slightly to the right as for non-pledgers, the shift appears small. We do not pursue further testing here for several reasons. 1. There are many other differences between these groups. 2. The cross-survey tracked sample is a small share of the total sample. 3. As seen earlier, the base distribution of the levels of donations (planned or actual) differs between GWWC and non-GWWC; thus there is no single measure of ‘which group comes closer to their plan on average.’ We next present a scatterplot of planned versus actual donations for 2019, for those who can be matched across surveys. In the figure below, the brightness of a color indicates the density of respondents (number of ‘neighbors’) with a particular combination of planned and actual donations. planned_actual_2019_pointdensity Overall, the plot is more or less centered around the 45 degree line of ‘plans=actual.’ There are noticeable departures in each direction, but these seem to balance out. Thus, we might loosely conclude that ‘on average 441 individuals who can be matched across years tend to donate an amount close to what they planned.’ However, there may nonetheless be important differences, so we test further. Below, we plot donations for these linked individuals – actual donations are on the left, and planned donations are on the right. We overlay a ‘violin’ density plot (widths depicts the frequencies). Medians are depicted in red dots, and the boxes depict 25th and 75th percentiles. The lines show each individual’s donation (on the left) connected to her plan (on the right). The plot also reports on a Wilcoxon signed-rank test (for paired data). ( matched_dons_wilcoxon &lt;- planned_actual_2019_l %&gt;% mutate(donation_type = to_title_case(donation_type)) %&gt;% ggstatsplot::ggwithinstats( x = donation_type, y = value, type = &quot;nonparametric&quot;, paired = TRUE, point.path.args = list(alpha = 0.1, linetype = &quot;solid&quot;), ) + do.call(scale_y_continuous, scales) + xlab(&quot;&quot;) + ylab(&quot;&quot;) + scale_fill_discrete(name = &quot;&quot;) ) w_signed_test_planned_actual &lt;- wilcox.test(x = planned_actual_2019$donation_2019, y = planned_actual_2019$planned_donation_2019, alternative = c(&quot;greater&quot;), mu = 0, paired = TRUE, exact = NULL, correct = TRUE, conf.int = TRUE, conf.level = 0.95, tol.root = 1e-4, digits.rank = Inf) #a Wilcoxon signed rank test of the null that the distribution of ... x - y (in the paired two sample case) is symmetric about mu is performed. #Here the CI estimates &#39;the median of the difference between a sample from x and a sample from y.&#39; The nonparametric tests reported above find a statistically significant difference: actual donations tend to exceed planned donations in this sample, and this difference is unlikely to be due to chance. The ‘pseudo-median’ of this difference is estimated as 281 USD with 95% lower CI bound 162. The “matched-pairs rank-biserial correlation” is also bounded between about 0.17 and 0.41, suggesting that “actual donation exceeds planned donation” is more likely than “planned exceeds actual” (in the population that this is drawn from). The results are similar if we focus on the subset of these who report a donation in both years (see bookdown robustness appendix). planned_actual_2019_no_0 &lt;- planned_actual_2019 %&gt;% filter(donation_2019&gt;0 &amp; planned_donation_2019&gt;0) w_signed_test_planned_actual_no0s &lt;- wilcox.test(x = planned_actual_2019$donation_2019, y = planned_actual_2019$planned_donation_2019, alternative = c(&quot;greater&quot;), mu = 0, paired = TRUE, exact = NULL, correct = TRUE, conf.int = TRUE, conf.level = 0.95, tol.root = 1e-4, digits.rank = Inf) #a Wilcoxon signed rank test of the null that the distribution of ... x - y (in the paired two sample case) is symmetric about mu is performed. #Here the CI estimates &#39;the median of the difference between a sample from x and a sample from y.&#39; We also present simulation-based tests for whether the mean and median of the individual ‘actual minus planned’ donations exceeds or falls below zero. These are given in the table below. planned_v_actual_test_table Table 4.6: Actual minus planned donations for 2019, linked participants (2019-20) Statistic Point estimate CI Lower CI Upper P-value Mean 1587 -279 3453.648 0 Median 141 23 259.456 0 linked_ddmn &lt;- linked_tests_results %&gt;% filter(response==&quot;don_diff&quot; &amp; stat==&quot;mean&quot;) linked_ddmed &lt;- linked_tests_results %&gt;% filter(response==&quot;don_diff&quot; &amp; stat==&quot;median&quot;) The mean of ‘actual minus planned’ donations is 1,587 USD, with simulation-based (bootstrapped) confidence intervals [-279, 3,454], with corresponding p-value 0.138. For the median of this difference we have point estimate 141 USD, with simulation-based (bootstrapped) confidence intervals [22.5, 259], with corresponding p-value 0.102. Thus, the evidence points towards ‘actual donations exceeding planned donations for those EAs who can be linked across 2019-20.’ However, (unlike in the Wilcoxon signed-rank tests) the differences are not strongly statistically significant in these simulation-based tests. Planned vs. actual: All respondents (across relevant years) Those who responded to both 2019 and 2020 surveys (and left emails both times) might tend to be the more engaged EAs. In particular, having fulfilled one’s planned donation might make one more likely to want to complete the follow-up survey, and perhaps more keen to provide one’s donation data in particular. This suggest the above figures may be biased towards more ‘fulfilled plans.’ Thus, we next overlay the planned and actual donations for all respondents across both surveys. Here we compare the ‘amounts planned for the year of a survey’ to the ‘amounts reported for the previous year, in the following year’s survey.’ We do this separately for each available year. While this offers us a larger sample, and may be less vulnerable to the bias just-mentioned, it brings up other sample selection issues, and these comparisons should also be treated with some caution (see fold/footnote). Indeed, ‘2019 respondents who entered a planned donation amount’ (call these ‘2019-planners’) may not be precisely representative of the population of interest. Still, we might at least seek an ‘internally-valid’ measure of the ‘distribution of actual 2019 donations for the 2019-planners,’ and compare their actual to their planned 2019 donations. This will still be imperfect: the composition of the 2019 and 2020 respondents may differ, as discussed elsewhere. Thus, the distribution of ‘reported 2019 donations for those who completed the survey in 2020’ (call these ‘2020-reporters’) may be different from the distribution of the actual 2019 donations made by 2019-planners. The direction and nature of this bias is unclear; we might get some hints at this by comparing the reported donations in 2018 and 2019 respectively by 2019-reporters and 2020-reporters. If the distribution of donations changes little from year to year, we might worry less about this bias. We defer this for future work. Below, we also report these measures for those who joined EA only before 2019 (plausibly a more stable group). scales_set &lt;- list(scale_y_discrete(expand = c(0,0)), scale_x_continuous(limits = c(50, max_lim), trans = scales::pseudo_log_trans(base=10), breaks = breaks, expand = c(0,0), labels = scales::dollar_format()) ) ridge_bottom_opts &lt;- list( theme(legend.position = &quot;bottom&quot;, legend.margin=margin(t = -0.6, unit=&#39;cm&#39;)), ylab(&quot;&quot;), scale_fill_discrete(&quot;&quot;)) ( dons_planned_across_all &lt;- eas_all %&gt;% f_don_plan_by_year %&gt;% ggplot(aes(x = value, y = as.factor(year), fill = donation_type)) + geom_density_ridges(alpha=.6, color = &quot;black&quot;, quantile_fun = median, quantile_lines = TRUE, rel_min_height = 0.005) + # geom_vline_med(x) + scales_set + ridge_bottom_opts + xlab(&quot;&quot;) + guides(fill = guide_legend(override.aes = list(linetype = 0))) + labs(title= &quot;Density of planned and actual donations for each year&quot;, subtitle = &quot;Vertical lines: medians for the year and donation type&quot;, caption = &quot;Donations bottom-coded at $50&quot;) ) For 2019 (2020 survey ‘actual’ and 2019 survey ‘planned’) and 2018 (2019 survey ‘actual’ and 2018 survey ‘planned’), the histograms of planned and actual donations line up approximately (although planned donations tend to be a bit higher). However, for 2017 (2018 survey ‘actual’ and 2017 survey ‘planned’), the planned donation distribution appears far lower. This seems likely to result from a different response and a different composition between the 2017 and 2018 responses.* * There was an increase in the sample size and the response rate to the donation questions from 2017 to 2018 below. We report this in the bookdown ‘robustness’ appendix. Note that the number of EA survey respondents also declined in 2020, from 2,509 to 2,056. If the EA survey tends to select only the more engaged EAs, this would suggest that the extent 2019 donations under-performed plans may be even higher. (Thus we will not include 2017 in our “planned versus actual” comparisons.) As noted, for the remaining relevant donation years (2018 and 2019) the median donation is somewhat lower than the median planned donation, suggesting under-performance relative to plans. We investigate this further below. Over 2018-19, how does the distributions of planned versus actual donations differ?* In spite of the caveats above, we consider and test whether the distribution of planned donations for a year exceeds or falls short of actual donations, pooling the 2018-2019 and 2019-2020 data (to consider donations vs plans in 2018 and 2019). We do this separately both overall, and excluding those who joined EA only before 2019 (plausibly a more stable group). #TODO -- medium-high priority: some depiction of quantiles/cutoffs within each smoothed histogram (for all the ones below, even the faceted ones). See, e.g., https://stackoverflow.com/questions/57563692/combining-facet-wrap-and-95-area-of-density-plots-using-ggplot2/57566951#57566951 dons_plan_hist_opts &lt;- function(df) { df %&gt;% ggplot(aes(x = value, fill = donation_type)) + geom_density(alpha=.35) + scales_set + #geom_vline_med(x) + ridge_bottom_opts + xlab(&quot;&quot;) } #crappy workaround here: x &lt;- eas_all %&gt;% filter(year %in% c(2018, 2019, 2020)) %&gt;% f_don_plan_by_year xo &lt;- eas_all %&gt;% filter(year_involved&lt;2019) %&gt;% filter(year %in% c(2018, 2019, 2020)) %&gt;% f_don_plan_by_year x_med_don &lt;- median(x$value[x$donation_type== &quot;Donation&quot;], na.rm=TRUE) x_med_don_plan &lt;- median(x$value[x$donation_type== &quot;Planned Donation&quot;], na.rm=TRUE) xo_med_don &lt;- median(x$value[xo$donation_type== &quot;Donation&quot;], na.rm=TRUE) xo_med_don_plan &lt;- median(xo$value[x$donation_type== &quot;Planned Donation&quot;], na.rm=TRUE) dons_planned_18_20 &lt;- eas_all %&gt;% filter(year %in% c(2018, 2019, 2020)) %&gt;% f_don_plan_by_year %&gt;% rowwise() %&gt;% mutate(value = max(value, 50)) %&gt;% ungroup() %&gt;% dons_plan_hist_opts + geom_vline(xintercept=x_med_don, size=.5, color=&quot;green&quot;) + geom_vline(xintercept=x_med_don_plan, size=.75, color=&quot;pink&quot;) + ggtitle(&quot;2018-19&quot;) dons_planned_18_20_no_new &lt;- eas_all %&gt;% filter(year_involved&lt;2019) %&gt;% filter(year %in% c(2018, 2019, 2020)) %&gt;% f_don_plan_by_year %&gt;% dons_plan_hist_opts + geom_vline(xintercept=xo_med_don, size=.5, color=&quot;green&quot;) + geom_vline(xintercept=xo_med_don_plan, size=.75, color=&quot;pink&quot;) + ggtitle(&quot;2018-19&quot;) ( dons_planned_18_20_arr_new &lt;- ggarrange(dons_planned_18_20, dons_planned_18_20_no_new, ncol = 2, nrow=1, labels=c(&quot;All&quot;, &quot;Involved pre-2019&quot;), label.x=0.0, label.y=0.85, legend=&quot;bottom&quot;, common.legend=TRUE ) + labs(title= &quot;Density of planned and actual donations, split by year-invo&quot;, subtitle = &quot;Vertical lines: medians for the group and donation type&quot;, caption = &quot;Donations bottom-coded at $50&quot;) ) #todo (@oska) -- finish this; separate aligned plots for # - is it doing what I think? I think we want to use 2020 for the sums in &#39;actual&#39; but not in &#39;planned&#39; # - align the above, fix labels # - report some more stats within each as &#39;bars&#39; or shading (geom lines could also be good) # - stat tests for each Above, we give the density of planned and actual donations, split by year-involved. Vertical lines represent medians for the group and donation type (green=donation, pink=planned donations). Donations are bottom-coded at 50 USD. Again, for both groups (where the survey entries are linked) the planned donation distribution appears to be somewhat higher than the actual distribution, although the difference is not dramatic. We present the results of simulation-based permutation tests below. (Explanation in fold). We use permutation tests for testing whether the median (and mean) of planned donations exceeded/fell short of the mean for actual donations, but using the data from different years’ surveys (without connected individuals). The null hypothesis (for 2019 donations) is that: ‘there is no difference in the median donation, in our survey sample, between actual 2019 donations (reported in 2020) and planned 2019 donations (reported in 2019).’ Suppose we maintain the hypothesis that ‘individuals appeared in the 2019 survey versus the 2020 survey ‘as if randomly drawn’’, and we consider that under the null hypothesis “the distribution of planned and actual donations is identical” (this may be a stronger assumption than needed). The permutation procedure repeatedly simulates a distribution of planned and actual donations that is consistent with this null, by using our original donation amount data and randomly re-assigning each observation to either ‘planned’ or ‘actual.’ For each ‘simulated null distribution’ we can then compute the targeted statistic (difference between mean/median donation between the two groups). We can plot this ‘simulated nll distribution of differences’ and consider ‘how often do we observe a difference as extreme as the ’point estimate’ from our actual data’? This yields the p-values reported below. The confidence intervals for the differences come from simply using the 95% interval range from the simulated distribution, shifted to be centered around our point estimate. The figure below presents the simulated null distribution of differences in medians arising from this procedure, for the full sample (2018-19 donation years). The red line gives the point estimate of ‘differences in median between planned and actual’ from our data. The grey bins present the ‘(simulated) distribution of differences between planned and actual, under the null hypothesis that planned and actual are drawn from the same distribution.’ The ‘pink areas’ depict the area of the simulated null distribution that is ‘more extreme’ than our point estimate; this iis the area represented by the ‘p-value’ of a two-tailed hypothesis test. Finally the turquoise should represent a 95% CI for the actual median; essentially this comes from a simulated distribution under the hypothesis that the true difference between the medians is exactly equal to our point estimate. Note that this turquoise region just crosses the 0, again confirming that we ‘just barely cannot reject the null,’ but that a Bayesian analysis would probably put a lot of probability mass on fairly substantial differences. In the table below we summarize the results of this test for means and medians, and for four distinct subsamples. planned_actual_unlinked_results_table Table 4.7: Actual versus Planned donation distributions: permutation tests Sample Statistic Point estimate CI Lower CI Upper P-value Full sample (2018-19 donation years) Difference in Mean -2354 -7160 2451 0.376 Full sample (2018-19 donation years) Difference in Median -458 -609 -308 0.000 Involved before 2019 (2018-19 don) Difference in Mean -1293 -6724 4138 0.694 Involved before 2019 (2018-19 don) Difference in Median -157 -337 23 0.006 GwwC only (2018-19 don) Difference in Mean -235 -11168 10698 0.942 GwwC only (2018-19 don) Difference in Median -1027 -1477 -578 0.000 ‘Matched individuals’ Difference in Mean 1449 -2599 5496 0.504 ‘Matched individuals’ Difference in Median 94 -757 945 0.868 # report on #test_rep_mean_don_19_20 #test_rep_med_don_19_20 #test_rep_mean_don_19_20_gwwc #test_rep_med_don_19_20_gwwc #test_rep_mean_don_19_20_nonew #test_rep_med_don_19_20_nonew For the full sample, for the subset who have been in EA since before 2019, and for GWWC pledgers, both the mean and median donations fall short of the planned donations. Overall, the difference in medians is bounded between about 300 and 600 USD. Each of these differences (for the medians) are strongly statistically significant. Perhaps because of the large outliers, the differences in means are much more widely bounded, and thus this comparison is largely uninformative. This contrasts with our results for individuals that can be matched across 2019 and 2020 surveys, for whom actual donations tend to exceed the reported plans in the prior year.* As noted earlier, this contrast might be because people who have met or exceeded their donation plans are more likely to respond to surveys in subsequent years, and report donations in each. *As discussed earlier, for the ‘matched individuals’ (those who can be linked from 2019 and 2020 surveys) the mean and median of the distribution of actual donations exceeds that of planned, but these differences are not statistical significant in the permutation tests. However, for the matched individuals, these differences are positive and significant (or close to significant) in tests that take advantage of the linked nature of this data and look at the individual differences themselves. Given these contrasting findings, further work might be warranted. If donations do tend to underperform plans, we might look for patterns of underperformance that might suggest ways of improving this. 4.7 Donations versus next year’s plans As noted, we can only match a subset of individuals across years. However, in each of the years where it was asked, most respondents who answered the retrospective donation question also answered the ‘planned for this year’ question. We can see how these tend to relate; we may particularly consider whether 2020 donations are expected to be higher or lower than 2019, in light of the pandemic (cf the Giving Tuesday report suggesting growth in overall US charitable giving in 2020). Below we overlay the distribution of ‘last year’s donations’ and ‘planned current year’ donations for 2018-2020 surveys. next_don_lab &lt;- c(donation_usd = &quot;Don: Last year&quot;, donation_plan_usd = &quot;Don: This year (plan)&quot;) ( dons_v_next_18_20 &lt;- eas_all %&gt;% f_don_18_20 %&gt;% ggplot(aes(x = value, y = as.factor(year), fill = donation_type)) + geom_density_ridges(alpha=.6, color = &quot;black&quot;, quantile_fun = median, quantile_lines = TRUE) + # geom_vline_med(x) + scales_set + ridge_bottom_opts + guides(fill = guide_legend(override.aes = list(linetype = 0))) + labs(title= &quot;Density of last year vs current year planned donations&quot;, subtitle = &quot;Vertical lines: medians for the year and type of report&quot;) + scale_color_brewer(labels=next_don_lab) + scale_fill_brewer(labels=next_don_lab) + xlab(&quot;&quot;) + theme(legend.title=element_blank()) + guides(fill = guide_legend(reverse = TRUE)) ) #dons_plan_hist_opts + # facet_wrap(~factor(year, levels=c(&#39;2018&#39;,&#39;2019&#39;,&#39;2020&#39;)), nrow=3, ncol = 1) #) # Todo - medium: It&#39;s still not clear what is going on from year to year... maybe try animated? # Todo -- medium/high: get bars or color separation for quantiles (probability mass) within each histogram #p_load(&quot;&quot;) #devtools::install_github(&#39;thomasp85/gganimate&#39;) #devtools::install_github(&#39;thomasp85/transformr&#39;) #dons_v_next_18_20_anim &lt;- dons_v_next_18_20 + transition_states(year, state_length = 3) + ggtitle(&quot;Donations and plans: {closest_state}&quot;) In each year, the median of planned donations exceeds that of actual donations. The distribution of each of these appears fairly constant across years, with no obvious substantial drop for 2020. Next we plot this in two dimensions: for each individual we plot their planned current year’s donation against their reported donation for the year prior to the survey. current_planned_eas &lt;- eas_all %&gt;% select(ea_id, donation_usd, donation_plan_usd, year) %&gt;% # Add demographic information -- cut because it was crap #left_join(., select(eas_20_cy, all_of(demographics), ea_id, action_gwwc, start_date, end_date, income_c), by = &quot;ea_id&quot;) %&gt;% #remove likely duplicate entries (do that elsewhere too?) ; this also removes entries from years without any responses to these I guess distinct() ( current_planned_pointdensity &lt;- current_planned_eas %&gt;% # ggplot(aes(y = donation_2019, x = planned_donation_2019)) + filter(year&gt;=2018) %&gt;% rowwise() %&gt;% mutate(donation_usd = max(50, donation_usd), donation_plan_usd = max(50, donation_plan_usd)) %&gt;% ungroup() %&gt;% ggplot(aes(x = donation_usd, y = donation_plan_usd)) + ggpointdensity::geom_pointdensity(adjust = 0.25) + geom_smooth() + do.call(scale_x_continuous, scales_point_density_min50) + do.call(scale_y_continuous, scales_point_density_min50) + scale_color_viridis_c(&quot;Neighbours&quot;) + #scale_size_continuous(&quot;Income&quot;, labels = scales::label_number_si()) + ylab(&quot;Planned (next year&#39;s) Donation&quot;) + xlab(&quot;Actual (this year&#39;s) donation&quot;) + labs(title= &quot;Last year&#39;s donation vs this year&#39;s (planned) donation&quot;, subtitle = &quot;2018-2020; donations &#39;bottom-coded&#39; at 50 USD&quot;) ) #TODO: --medium importance -- facet or animate this across years&#39; The graph’s implications are not obvious. There is a large mass exactly along the 45 degree line, where the donation amount planned for the current year equals the amount reported for last year. There seems to be some substantial mass where planned donations exceed actual donations (above the 45 degree line), the smoothed curve is largely positioned at or below this line, perhaps because of the very small and zero entries for planned donations. We repeat the above plot but only for those who report positive values for both ‘the previous year’ and for ‘planned for this year’: ( current_planned_pointdensity_no0 &lt;- current_planned_eas %&gt;% # ggplot(aes(y = donation_2019, x = planned_donation_2019)) + filter(donation_usd &gt;0 &amp; donation_plan_usd&gt;0) %&gt;% filter(year&gt;=2018) %&gt;% rowwise() %&gt;% mutate(donation_usd = max(50, donation_usd), donation_plan_usd = max(50, donation_plan_usd)) %&gt;% ungroup() %&gt;% ggplot(aes(x = donation_usd, y = donation_plan_usd)) + ggpointdensity::geom_pointdensity(adjust = 0.25) + geom_smooth() + do.call(scale_x_continuous, scales_point_density_min50) + do.call(scale_y_continuous, scales_point_density_min50) + scale_color_viridis_c(&quot;Neighbours&quot;) + #scale_size_continuous(&quot;Income&quot;, labels = scales::label_number_si()) + ylab(&quot;Planned (next year&#39;s) Donation&quot;) + xlab(&quot;Actual (this year&#39;s) donation&quot;) + labs(title= &quot;Last year&#39;s vs this year&#39;s (planned) donation&quot;, subtitle = &quot;For EAs reporting a positive amount for each&quot;, caption=&quot;2018-20, donations &#39;bottom-coded&#39; at 50 USD&quot; ) ) #TODO: --medium importance -- facet or animate this across years&#39; As in previous sections, we conduct simulation-based tests. Here we can separately consider both (i) the (unpaired) differences in the medians and means of distributions and (ii) the medians and means of the differences themselves. First, considering the differences in these distributions: next_current_unlinked_results_table Table 4.7: ‘Next year (plan)’ - ‘this year’ donation distributions: permutation tests Sample Statistic Point estimate CI Lower CI Upper P-value 2018-2020, all responses Difference in Mean 1632.8 -2506.269 5771.8 0.5 2018-2020, all responses Difference in Median 437.7 306.781 568.6 0.0 The mean of the distribution of the current-years’ planned donations is higher than the mean for the previousc year’s, but we cannot reject equality (the p value is far above the conventional statistical threshold). However, the median is statistically significantly higher (by 438 USD point estimate). Next, considering the differences by individual: current_next_test_table Table 4.6: Planned minus last year’s donation, 2018-20, all participants who report donations Statistic Point estimate CI Lower CI Upper P-value Mean 1452 349 2555 0.016 Median 0 0 0 1.000 The median difference is clearly 0 – the great middle mass of participants report the same donation planned for the current year as for the previous one, and this is the case in all resampling simulations. However, the mean difference is strongly and significantly positive: if we consider the magnitude of the differences, people tend to report a greater planned donation for this year than they reported last year. However, this does not necessarily indicate over-optimism and underperformance: it is possible that the individuals responding to individual survey in this period in fact did and do increase their donations from year to year. 4.8 Model of EA donation behavior Modeling ‘questions’ and approaches: As discussed in other posts and linked material, we broadly imagine three categories of modeling: (See discussion in the fold/footnote.) Descriptive (‘what relates to donation behavior’), Predictive (‘what will people with particular characteristics donate in the future’), and Causal (‘what factors actually determine the amount donated’; so if we changed these factors, donations would change). Descriptive modeling: Essentially, offering a “dimension reduction” of the data, presenting ‘which features relate to donation behavior?’ Predictive modeling: Training a model to produce the best out-of-sample (or out-of-time) fit for current (or future) donations based on individual characteristics. This model should not include ‘leaks,’ i.e., it should excluding individual characteristics and outcomes that occur after the time we would be ‘doing the prediction.’ Causal: Consider identification of ‘causal paths,’ i.e., ‘what actually determines amounts donated.’ However causal inference requires strong assumptions and/or exogenous and random shifts in potential determinants of donation behavior. We don’t have any obvious candidates for this in the current setting. At best, we can interpret our descriptive and predictive models as suggestive of causal relationships. We may care about causality because we see potential to intervene and boost those variables that cause greater giving, and/or because a better understanding of what actually drives donation behavior may yield additional insights, helping us understand the world better. However, we see little potential for very credible and convincing causal inference here. We thus first focus on description (and less so, prediction), while informally considering ‘plausible causation.’ We discuss (and implement) this in the next section. (Discussion in bookdown/fold HERE).* * Consider factors of potential interest, including those we could influence as a movement (e.g., ‘recommended career paths’) and those of fundamental interest (perhaps income, age or initial cause prioritization). Simply looking at differences in donation by these measures will not tell us their actual impact on donation; nor will a ‘controlled regression’: each of these are likely to be related to, and influenced by (observable and) unobserved components which may also drive donations. E.g., suppose people who first went to an elite university tended to donate more. This would not this mean that attending an elite university causes greater donations. Individuals who attend elite university may have greater exposure to EA charitable appeals, or greater (unobserved wealth) or lifetime income, which may independently cause greater giving. Even age cannot be given an obvious causal interpretation, given our sample selection; e.g., in any sample we look at the older people will tend to have joined EA at a younger age, and people may have been driven to join at a younger age because they were more altruistic, or because they had a stronger EA peer network, etc. For these reasons, we general look for sources of experimental or quasi-experimental variation in the factors of interest to justify causal inference. However, these are not present in our data. As mentioned in the introduction, being able to predict donations could be useful for several reasons. Thus, we follow our descriptive models with “predictive models”, with different goals and approaches, including elements of machine learning (see further discussion below). 4.8.1 Descriptive (and causally-suggestive) models 2019 post: The results of a regression analysis are again suggestive … that those with higher incomes and GWWC members tend to donate more than those with lower incomes or who are students. … In this year’s post we begin with a set of pre-specified models aimed at describing and providing suggestive inference about causal factors driving donations. (Further discussion in the Bookdown at this point) . In our descriptive modeling we do not remove ‘insignificant’ features from the model (as in stepwise regression), nor do we shrink the coefficients towards zero (as in Ridge and Lasso models). Under the assumptions of the classical linear model and its simple extensions the coefficients we present here would be unbiased or consistent. (However, we admit that the strong assumptions of this model, particularly those embodying exogeneity, are likely to fail in important ways in the current non-experimental setting.) We retain those features of most direct interest (such as ‘how introduced to EA’) and/or theoretical importance (such as income),** ‘controls’ (especially time-in-EA and survey-year) that might allow us to better interpret the features of interest. ** Classical economic theory suggests that most goods are ‘normal,’ with the amount consumed increasing in income. Empirical evidence supports this for charitable giving; recent work suggests that share of income is relatively constant across the income distribution, implying that wealthier people give more in absolute terms. As discussed in other posts ‘how people were introduced to EA’ has changed over the years. We also expect those who have been involved in EA for a longer period of time to be more engaged, and perhaps donate more (possibly due to differential attrition). Thus, it seems reasonable that in tracking the association between donation and introducer, we might want to ‘control for’ (difference out or hold constant) the differences in ‘time-in-EA’ between these groups. Still, we admit that these specifications are not based on an explicit causal model or identification strategy. Choosing features and modeling targets We construct several ‘feature sets’: “Key demographics, student status, and geography,” used in all models “Career/Economics”: (Income, employment status, top-6 university)* “Pledges/commitments:” Whether ever taken a ‘Giving What We Can Pledge,’ whether ‘Earning to Give’ “Controls” for age, time-in-EA, and survey-year (used in all models)** * “Top-6 university” refers to whether the individual lists any of the six universities (Oxford, Stanford, Harvard, CalTech, MIT, Cambridge) appearing in the top-10 of all of USNWR, QS, and THE rankings. However, university was not asked in the 2018 survey; we will check whether this has an impact on the coefficient for year 2018. ** We refer to the latter as “controls” because they aid our interpretation of other features of interest, as noted above. However, these are also of independent interest. We focus on three key outcomes: Amount donated (converted to US dollars)*** ***Here we focus on the average of last-year’s and next year’s donation for each individual, where both are present, and otherwise we use whichever one is present. In the presence of recall and reporting error, we expect this will improve the reliability of our estimates. The plots and figures above also suggest that planned and actual donations are closely related. We report a set of related results for the simpler donation outcome in the robustness appendix. Donation as a share of income**** **** Where income is missing or where income was reported as 0 we impute it based on student status and country. Whether donated more than 1000 USD # Define vector for renaming terms in regression output #&quot;new_names&#39;&quot; moved to `build/labeling_eas.R&#39; #TODO - medium -- try to move all this to build side #We impute variables where missing and normalizing all variables to be mean-zero and to be on the same scale. diqr &lt;- function(x) { (x - mean(x, na.rm=TRUE))/IQR(x, na.rm=TRUE) } gtmed &lt;- function(x) { x*(x&gt;med(x)) } #TODO -- HIGH importance -- why 43 missing values for donation_usd? eas_all_s &lt;- eas_all %&gt;% filter(!is.na(don_av2_yr) &amp; year_f %in% c(&quot;2018&quot;, &quot;2019&quot;, &quot;2020&quot;)) %&gt;% mutate( #(re) code scaling and 2-part splits for the modeling sample (2018-20, reporting donations) age_d2sd = arm::rescale(age), #Todo (automate this with `mutate(across)` thing) age_if_older = gtmed(age), ln_age_if_older = gtmed(ln_age), ln_years_involved_post_med = gtmed(ln_years_involved), years_involved_d2sd = arm::rescale(year - as.numeric(year_involved)), years_inv_d2sd_post_med = gtmed(years_involved_d2sd), income_c_imp_diqr = diqr(income_c_imp_bc5k), age_d2sd_post_med = arm::rescale(age_if_older), income_c_imp_diqr_if_richer = gtmed(income_c_imp_diqr), ln_income_c_imp_if_richer= gtmed(ln_income_c_imp_bc5k) ) %&gt;% rowwise() %&gt;% mutate(don_share_inc_imp_bc5k = min(don_share_inc_imp_bc5k, 1)) %&gt;% #recode about 84 values so the range is between 0-1 for frac. logit to work ungroup() %&gt;% dplyr::select(all_of(c(num_out, bin_out, controls, key_demog, feat_income_employ, feat_gwwc_etg, robust_controls)), income_c, income_c_imp, income_c_imp_bc5k, income_c_imp_diqr, income_c_imp_diqr_if_richer, first_hear_ea_lump, years_involved, age, contains(&quot;d2sd&quot;), contains(&quot;iqr&quot;)) %&gt;% #I have added first_hear_ea_lump back even though we don&#39;t use it here because we want to use it in ML; I hope it doesn&#39;t mess anything up # years_involved included to put in sumstats labelled::set_variable_labels(.labels = as.list(key_eas_all_labels), .strict=FALSE) #eas_all_s_rl &lt;- eas_all_s %&gt;% #filter_all(any_vars(is.na(.), negate = TRUE)) %&gt;% #(Alt: drop all rows with any missings) #mutate( #re-leveling should now be done on build side only because it removes labels #Hopefully everything above preserves levels #where_live_cat = relevel(where_live_cat, ref=&quot;USA&quot;), #city_cat = relevel(city_cat, ref=&quot;Other&quot;), #year_f = relevel(as.factor(year_f), ref=&quot;2017&quot;), #student_cat = relevel(student_cat, ref=&quot;Non-student&quot;), #not_male_cat = relevel(not_male_cat, ref=&quot;Male&quot;) # race_cat = relevel(race_cat, ref=&quot;Just white&quot;) #) %&gt;% #gdata::drop.levels() #drops unused factor levels #Recode missing as 0 for all dummies, as a &#39;NA category&#39; for categoricals #also for normalized variables; i.e., set missings to the mean eas_all_s_rl &lt;- eas_all_s %&gt;% mutate(across(matches(&quot;d_|not_just_white&quot;), missing_to_zero)) eas_all_s_rl_imp &lt;- eas_all_s_rl %&gt;% mutate(across(matches(&quot;d2sd|diqr&quot;), missing_to_zero)) %&gt;% labelled::set_variable_labels(.labels = as.list(key_eas_all_labels), .strict=FALSE) #TODO: (future) -- check for sensitivity to this imputation vs dropping these obs # Write imp dataset to csv and RDS for ML/predictive modeling in donation_pred.R etc. saveRDS(eas_all_s_rl_imp, file = here(&quot;data&quot;,&quot;edited_data&quot;,&quot;eas_all_s_rl_imp.Rdata&quot;)) eas_all_s_rl_imp %&gt;% write_csv(here(&quot;data&quot;, &quot;edited_data/eas_all_s_rl_imp.csv&quot;)) count_uniq &lt;- eas_all_s_rl %&gt;% #counts of unique values for each feature in each year grp_uniq(year_f) recover_cols &lt;- count_uniq %&gt;% #any columns *without* unique features in each year? select_if(~ any(.==1))%&gt;% names() In the more extensive ‘bookdown’ version we report the summary statistics for the data used in the models. See HERE. We report summary statistics on a selection of these features and target outcomes below, limited to the subset who report a zero or positive previous or current-year donation (as in our modeling). #don_inc_career_tab ( don_inc_career_tab &lt;- eas_all_s_rl_imp %&gt;% filter(!is.na(don_av2_yr)) %&gt;% mutate(`Earn-to-give` = as.factor(d_career_etg), `GwwC` = as.factor(d_gwwc_ever_0)) %&gt;% ungroup() %&gt;% filter(year_f %in% c(&quot;2018&quot;, &quot;2019&quot;, &quot;2020&quot;)) %&gt;% dplyr::select(starts_with(&quot;don&quot;), starts_with(&quot;d_don&quot;), starts_with(&quot;inc&quot;), -income_c_imp_diqr, d_pt_employment, d_not_employed, `Earn-to-give`, `GwwC`) %&gt;% dplyr::select(-starts_with(&quot;l_&quot;), -d_don_10pct, -ends_with(&quot;d2sd&quot;), -matches(&quot;_if_|_post_&quot;)) %&gt;% .summ(title = &quot;Donations, income, career, 2018-2020, (subset: reporting 0+ donation)&quot;, digits = c(0,0,1,1,2,1), labels=TRUE, logical.labels = c(&quot;No&quot;, &quot;Yes&quot;), factor.counts = FALSE, out=&quot;kable&quot;) %&gt;% kable_styling() ) Table 4.8: Donations, income, career, 2018-2020, (subset: reporting 0+ donation) Variable N Responses N positive Mean Sd Median 90th pct Donation (USD) 5016 4157 8992.3 106108.5 660 10059.9 Don. ‘avg’ 5059 4528 9633.8 103967.3 1000 12000 Don./Income (imp, bc) 5016 4157 0.1 0.1 0.02 0.1 Don. plan (USD) 4870 4201 10625.1 107729.9 1097.69 13000 Don. &gt; 1k USD 5016 … FALSE 54% … TRUE 46% Income (not imp.) 4887 4518 83066.8 1314897.6 33956.11 130075.8 Income (imp.) 5059 5059 83338.8 1292295.8 35506.2 130000 Income (imp. bc) 5059 5059 83590.1 1292280.1 35506.2 130000 Employed PT 5059 474 0.1 0.3 0 0 Not Employed 5059 260 0.1 0.2 0 0 Earn-to-give 5059 … 0 70% … 1 30% GWWC (ever) 5059 … No/NA 66% … Yes 34% Above, we report donations, income, career, and GWWC pledge rates. Note that the ‘Don. avg.’ the average of the current year and planned donation, is close, but slightly above the ‘Donation’ variable, and has somewhat more positive values. Note also that income imputation (where missing or stated as below 5000 USD) recodes about 10% of these values, and leads to a fairly similar average income figure (compare ‘Income (not imp.)’ and ‘Income (imp. bc.),’ where the latter refers to the income imputation and bottom-coding at 5000 USD). Note that, perhaps unsurprisingly, the rates of self-reported ‘earning-to-give’ careers and ‘having ever made a Giving What We Can pledge’ is higher among those in this sample (those who report a donation) than in the overall EAS sample. #TODO for future posts/time permitting: split by &#39;whether reported donation&#39;, test for differences ( demog_etc_tab &lt;- eas_all_s_rl_imp %&gt;% ungroup() %&gt;% filter(year_f %in% c(&quot;2018&quot;, &quot;2019&quot;, &quot;2020&quot;)) %&gt;% droplevels() %&gt;% filter(!is.na(don_av2_yr)) %&gt;% dplyr::select(-contains(&quot;don&quot;), -starts_with(&quot;d_don&quot;), -starts_with(&quot;inc&quot;), -starts_with(&quot;ln_&quot;), -d_don_10pct, -ln_income_c_imp_bc5k, -matches(&quot;d2sd|_if_|_post_&quot;)) %&gt;% select(-d_pt_employment, -d_not_employed, -d_career_etg, -d_gwwc_ever_0, -first_hear_ea_lump, -year_f, -years_involved, -age) %&gt;% select(everything()) %&gt;% labelled::set_variable_labels(.labels = as.list(key_eas_all_labels), .strict=FALSE) %&gt;% sumtable( labels = TRUE, #uses assigned in Hmisc or sjlabelled simple.kable = TRUE, title = &quot;Demography etc., 2018-2020 (subset: reporting 0+ donation)&quot;, digits = 1, factor.counts = FALSE, out=&quot;kable&quot; ) %&gt;% kable_styling() ) Table 4.9: Demography etc., 2018-2020 (subset: reporting 0+ donation) Variable N Percent Gender 5059 … Male 69% … Not-male 28% … Gender: No response 3% Student 5059 … Non-student 67% … Student 33% … Student: No response 0% Race/ethnicity 5059 … Just white 80% … Not just white 18% … Race: No response 2% Where live 5059 … USA 40% … Can/Aus/NZ 13% … Country: No response 7% … EEA not Anglo 21% … Other 3% … UK/IR 16% City 5059 … Other 39% … City: No response 18% … Named big city 43% Top-6 Uni. 5059 … No 46% … NA 47% … Yes 7% ( year_etc_tab &lt;- eas_all_s_rl_imp %&gt;% ungroup() %&gt;% filter(year_f %in% c(&quot;2018&quot;, &quot;2019&quot;, &quot;2020&quot;)) %&gt;% droplevels() %&gt;% filter(!is.na(don_av2_yr)) %&gt;% dplyr::select(year_f, years_involved, age) %&gt;% labelled::set_variable_labels(.labels = as.list(key_eas_all_labels), .strict=FALSE) %&gt;% sumtable( labels = TRUE, #uses assigned in Hmisc or sjlabelled simple.kable = TRUE, title = &quot;Year, years-involved, age; 2018-2020 (subset: reporting 0+ donation)&quot;, digits = 1, factor.counts = FALSE, out=&quot;kable&quot;) %&gt;% kable_styling() ) Table 4.9: Year, years-involved, age; 2018-2020 (subset: reporting 0+ donation) Variable N Mean Std. Dev. Min Pctl. 25 Pctl. 75 Max Year of survey 5059 … 2018 38% … 2019 34% … 2020 28% Years in EA 4871 3.7 2.4 0.5 1.5 5.5 11.5 age 4209 30.1 9.8 4 24 33 102 As the table above suggests, we are modeling EA survey years 2018-2020 only, with roughly equal shares of each year (although somewhat fewer in each subsequent year). The largest (or plurality) demographic groups (as in the sample overall, see other posts) are male, non-students, of ‘white’ ethnicity, and from the US. At least 43% come from one of cities named in the EA survey (over 50% of those responding), and 13% (where we have data) have some education at a ‘top-6’ global university. Constructing models We focus on the following modeling specifications: * * We report log-linear models in the robustness appendix. Proportional-effects ‘Quasi-Poisson’ model for ‘amount donated’ outcomes (allowing the expected donation to be an exponential function of the features). ** **We focus on the ‘average of planned and actual, where present, otherwise the non-missing value.’ Although this outcome variable is continuous (and this cannot strictly follow a Poisson distribution, the quasi-poisson model is still able to obtain consistent parameter estimates, provided that the conditional mean is correctly specified (Silva and Tenreyro 2006). Fractional logit (Papke and Wooldridge (2008)) ‘donation as a share of income’ Logit regression for the binary ‘donated over 1000 USD’ outcome # Define models (For LINEAR models ... used only in appendix, but some of these are reused in other models) #----------------------------------------------------- feat_list = list( #better to make this a &#39;named list&#39;? (TODO -- @oska would that improve the code?) c(key_demog, feat_income_employ, controls), c(key_demog, feat_income_employ, controls, robust_controls), # c(key_demog, feat_income_employ, feat_fh, controls, robust_controls), #robust controls here because &#39;first heard&#39; is likely entangled with tenure and age c(key_demog, feat_income_employ, feat_gwwc_etg, controls) ) feat_list_n = list( #better to make this a &#39;named list&#39;? (TODO -- @oska would that improve the code?) c(key_demog_n, feat_income_employ_n, controls_n), c(key_demog_n, feat_income_employ_n, controls_n, robust_controls_n), c(key_demog_n, feat_income_employ_n, feat_gwwc_etg, controls_n) ) feat_names = c(&quot;Baseline&quot;, &quot;Robust controls&quot;, &quot;Base + EtG &amp; GWWC&quot;) rhs_vars_list &lt;- rep(feat_list, length(targets_short)) #rhs_vars_list_iqr &lt;- rep(feat_list_iqr, length(targets_short)) outcome_vars_list &lt;- rep(as.list(targets_short), each=length(feat_list)) dfs &lt;- rep(list(eas_all_s_rl_imp), length(outcome_vars_list)) ## Create dataframe for modeling linear_models &lt;- make_model_df(rhs_vars_list, outcome_vars_list, dfs) # Fit linear models linear_models &lt;- linear_models %&gt;% mutate( lm_fit = fit_models( linear_models, &quot;formulas&quot;, &quot;dfs&quot;, fun = fit_lm) ) #warning `using type = &quot;numeric&quot; with a factor response will be ignored‘-’ not meaningful for factor` # @DR: Why are these models being fit on binary outcomes? DR, @OM: It is fit on all the outcomes including the binary ones, no? However, we haven&#39;t reported it yet. Anyways, I think there is still a norm of considering &#39;linear probability models&#39; in Economics, and arguments on its behalf, at least as a robustness check. # Extract coefficients, fitted and residuals model_feat_names &lt;- rep(c(feat_names), times= length(targets_short)) model_oc_names &lt;- rep(c(targets_short_names), each= length(feat_names)) model_names &lt;- paste(model_oc_names, model_feat_names, sep = &quot;: &quot;) linear_models &lt;- linear_models %&gt;% mutate(lm_coefficients = map(lm_fit, extract_coefficients, replacement_names = new_names, robust_SE = TRUE), #TODO -fix -- Medium importance (as linear is just for robustness checks...) error/warning: `&#39;^’ not meaningful for factors` lm_resids = map(lm_fit, residuals), lm_fitted = map(lm_fit, fitted)) #note: in modeling_df, lm_fit and qp_fit are the &#39;model output&#39; objects # `lm_resids` are a list of vectors of residuals from each linear model # `lm_fitted` are a list of vectors of predicted outcomes from each linear model # Error: Problem with `mutate()` column `lm_coefficients`. ## ℹ `lm_coefficients = map(...)`. ## x only 0&#39;s may be mixed with negative subscripts #trying out some simple models just as a place to test what is going on test_qp &lt;- eas_all_s_rl_imp %&gt;% glm(don_av2_yr ~ ln_income_c_imp_bc5k + ln_age + not_male_cat + student_cat + race_cat + where_live_cat + city_cat + d_pt_employment + d_not_employed + d_top6_uni + ln_years_involved + year_f, family=quasipoisson, data =.) test_fl &lt;- eas_all_s_rl_imp %&gt;% glm(don_share_inc_imp ~ ln_income_c_imp_bc5k + ln_age + not_male_cat + student_cat + race_cat + where_live_cat + city_cat + d_pt_employment + d_not_employed + d_top6_uni + ln_years_involved + year_f, family = quasibinomial(&#39;logit&#39;), data = .) test_logit &lt;- eas_all_s_rl_imp %&gt;% glm(d_don_1k ~ age_d2sd + not_male_cat + student_cat + race_cat + where_live_cat + city_cat + income_c_imp_diqr + d_pt_employment + d_not_employed + d_top6_uni + years_involved_d2sd + year_f, family = binomial, data = .) qp_targets_short &lt;- c(&quot;don_av2_yr&quot;) qp_outcome_vars &lt;- rep(as.list(qp_targets_short), each=length(feat_list)) # List of outcome variables for quasi-poisson qp_rhs_vars &lt;- rep(feat_list, length(qp_targets_short)) # List of independent variables qp_dfs &lt;- rep(list(eas_all_s_rl_imp), length(qp_outcome_vars)) # List of dataframes to fit models to qp_models &lt;- make_model_df(qp_rhs_vars, qp_outcome_vars, qp_dfs) # Create dataframe for models # Add model names feat_group_names &lt;- c(&quot;1. Baseline&quot;, &quot;2. Robust controls&quot;, &quot;3. Base + ETG + GWWC&quot;) qp_model_names &lt;- feat_group_names qp_models &lt;- qp_models %&gt;% mutate(model_name = rep(qp_model_names, length(qp_targets_short))) # Fit quasi-poisson models qp_models &lt;- qp_models %&gt;% mutate( qp_fit = fit_models( qp_models, &quot;formulas&quot;, &quot;dfs&quot;, fun = fit_glm) ) # Extract coefficients ## Takes a little while, consider parallels package? qp_models_noexp &lt;- qp_models %&gt;% mutate(qp_coefficients = map(qp_fit, extract_coefficients, replacement_names = new_names, exponentiate = FALSE, robust_SE = TRUE), qp_resids = map(qp_fit, residuals), qp_fitted = map(qp_fit, fitted)) qp_models &lt;- qp_models %&gt;% mutate(qp_coefficients = map(qp_fit, extract_coefficients, replacement_names = new_names, exponentiate = TRUE, robust_SE = TRUE), qp_resids = map(qp_fit, residuals), qp_fitted = map(qp_fit, fitted)) #Note: redone/redoing - fractional logit instead of Quasi-poisson with offset #Discussion: fl_targets_short &lt;- c(&quot;don_share_inc_imp_bc5k&quot;) fl_outcome_vars &lt;- rep(as.list(fl_targets_short), each=length(feat_list)) # List of outcome variables for quasi-poisson fl_rhs_vars &lt;- rep(feat_list, length(fl_targets_short)) # List of independent variables fl_dfs &lt;- rep(list(eas_all_s_rl_imp), length(fl_outcome_vars)) # List of dataframes to fit models to #---------- # Function to remove a particular string from a list #remove_str_list (moved to rstuff functions) # Create dataframe for models fl_models &lt;- make_model_df(fl_rhs_vars, fl_outcome_vars, fl_dfs) fl_models &lt;- fl_models %&gt;% mutate(model_name = rep(feat_group_names, length(fl_targets_short))) # Fit fractional logit models fl_models &lt;- fl_models %&gt;% mutate( fl_fit = fit_models( fl_models, &quot;formulas&quot;, &quot;dfs&quot;, fun = fit_glm, family = quasibinomial(&#39;logit&#39;)) ) # Extract coefficients ## Takes a little while, consider parallels package? fl_models_noexp &lt;- fl_models %&gt;% mutate(fl_coefficients = map(fl_fit, extract_coefficients, replacement_names = new_names, exponentiate = FALSE, robust_SE = TRUE), fl_resids = map(fl_fit, residuals), fl_fitted = map(fl_fit, fitted)) fl_models_noexp_nonrobust &lt;- fl_models %&gt;% mutate(fl_coefficients = map(fl_fit, extract_coefficients, replacement_names = new_names, exponentiate = FALSE, robust_SE = FALSE), fl_resids = map(fl_fit, residuals), fl_fitted = map(fl_fit, fitted)) fl_models &lt;- fl_models %&gt;% mutate(fl_coefficients = map(fl_fit, extract_coefficients, replacement_names = new_names, exponentiate = TRUE, robust_SE = TRUE), fl_resids = map(fl_fit, residuals), fl_fitted = map(fl_fit, fitted)) Models (Tables and plots of results; years 2018-20 combined) We put together forest plots of (normalized) coefficients from the distinct set of models outlined above, where these can be compared on the same scales. Specifically, we consider, for each of the three key outcomes (‘amount donated (averaged),’ ‘donation as a share of income,’ ‘donated over 1000 USD’), models with three specific sets of features, yielding nine models in total (plus robustness checks in the appendix). The feature sets, which we will refer to in the forest plots below, are: lab_list_to_text &lt;- function(df) { df %&gt;% var_label %&gt;% unname %&gt;% unlist() %&gt;% paste(collapse = &#39;, &#39;) } 1. “Base” (baseline model) Demographics: Log age, Gender, Student, Race/ethnicity, Where live, City Career-related: Employed PT, Not Employed, Top-6 Uni. Controls: Years in EA (log), Year of survey Where “imp” denotes that income is imputed where missing, “log” notes that the natural log was taken (allowing a proportional ‘elasticity’ relationship). Note that for the Logit models we use standardizations instead of logged continuous variables.* * We divide age and tenure by two sample standard deviations for each, following Gelman (2008). This allows the coefficients of continuous features like income to be compared to those for binary features like “whether employed.” We divide income by the sample inter-quartile range (56,125 USD). As the distribution appears highly skewed, normalizing income by 2sd would yield extremely large and hard-to-interpret coefficients. 2. “Robust controls”: Including all of the features in Base as well as a second term for each of “Years in EA (log), Log age” that takes a positive value only where these exceed their respective sample medians, and is otherwise set to zero. These represent ‘adjustment terms’ allowing us to see whether and how time-in-EA, age, and income may have a different relationship with donations at higher values of each of these.* * This simple ‘two part’ specification is partially related to the DataColada discussion here. 3. “Base + ETG + GWWC”: Including all of the features in Base as well as the binary variables “GWWC (ever), EtG,” i.e., whether reported ever having taken the Giving What We Can Pledge, and whether they report their career as ‘earning-to-give.’ Note that we report models with each of the three feature sets in each of the forest plots below. However, each forest plot reports on a single outcome and a single ‘theme,’ e.g., focusing on reporting just the coefficients on demographics from across each of the above three model feature sets (with some repeated coefficients across plots). These themes are Demographics (including age and time-in-EA)* Employment/career, GWWC, EtG, Income** “Non-response” to particular questions (in the appendix)*** However, it is important to remember that the reported estimates in each forest plot come from models that ‘control for’ other features (as reported). Note that we exclude the ‘two-part’ coefficients (in the ‘Robust controls’ models) from the forest plots.* * In the ‘Robust controls’ model there are two coefficients for each of age, income and ‘time in EA’ for below-median values, and a second one representing the adjustment to this coefficient for above-median values of each of these. We leave these coefficients out of the forest plots to avoid confusion, reporting them in tables under “Age, time-in-EA, Income, year; possible nonlinearity” instead. We present the coefficients on ‘Age, Time in EA, Income, and nonlinear adjustments for each of these’ in a separate set of tables (web link).**, *** ::: {.marginnote} ** We use the natural log of income in our models of donation amounts and ‘donation/income’ outcome. Here the (untransformed) coefficients have an elasticity interpretation — percent increase in donations (or donation share) for a given percentage increase in income. As this scale is not comparable to our other coefficients, we do not report it in these forest plots. We report this in tables under “Age, time-in-EA, Income; possible nonlinearity” instead. ::: *** To avoid clutter we present the results for nonresponse feature set in a bookdown appendix table only. # Create variable groupings for displaying coefficients ## Can&#39;t think of a tidier way to do this... ### Check that this extracts all necessary demog_coefs &lt;- c(&quot;Age&quot;, &quot;Where live:&quot;, &quot;Student&quot;, &quot;city&quot;, &quot;Gender:&quot;, &quot;white&quot;, &quot;race&quot;) emp_gw_etg_coefs &lt;- c(&quot;top-6 uni&quot;, &quot;employ&quot;, &quot;etg&quot;, &quot;gwwc&quot;) #fh_coefs &lt;- c(&quot;hear&quot;) nr_coefs &lt;- c(&quot;response&quot;, &quot;NA&quot;) nonlin_coefs &lt;- c(&quot;income&quot;, &quot;age&quot;, &quot;year&quot;) #coefficients of interest not (always) reported elsewhere, allowing us to consider nonlinearity # Filter the coefficients returned from using broom::tidy ## Keep only those specified in character vector keep extract_coefs &lt;- function(df, keep, term_col = term, ignore.case = TRUE, exclude = NULL){ # Add assertion statements in/doc string if (ignore.case == TRUE){ keep &lt;- tolower(keep) } keep &lt;- paste(keep, collapse=&quot;|&quot;) coef_df &lt;- df %&gt;% filter(str_detect(tolower({{term_col}}), keep)) if (!is.null(exclude)){ exclude &lt;- paste(exclude, collapse=&quot;|&quot;) coef_df &lt;- coef_df %&gt;% filter(!str_detect(tolower({{term_col}}), exclude)) } return(coef_df) } # Extract coefficients for each feature set, for making forest plots (and tables) # forms &lt;- list(&quot;qp&quot;, &quot;fl&quot;, &quot;logit&quot;) #--&gt; pmap (todo @oska) qp_coefs &lt;- qp_models %&gt;% select(qp_coefficients, model_name, outcome) %&gt;% tidyr::unnest(., cols = c(qp_coefficients)) qp_coefs_noexp &lt;- qp_models_noexp %&gt;% select(qp_coefficients, model_name, outcome) %&gt;% tidyr::unnest(., cols = c(qp_coefficients)) fl_coefs &lt;- fl_models %&gt;% select(fl_coefficients, model_name, outcome) %&gt;% tidyr::unnest(., cols = c(fl_coefficients)) fl_coefs_noexp &lt;- fl_models_noexp %&gt;% select(fl_coefficients, model_name, outcome) %&gt;% tidyr::unnest(., cols = c(fl_coefficients)) fl_coefs_noexp_nonrobust &lt;- fl_models_noexp_nonrobust %&gt;% select(fl_coefficients, model_name, outcome) %&gt;% tidyr::unnest(., cols = c(fl_coefficients)) logit_coefs &lt;- logit_models %&gt;% select(logit_coefficients, model_name, outcome) %&gt;% tidyr::unnest(., cols = c(logit_coefficients)) # feature_sets &lt;- list(&quot;demog&quot;, &quot;inc_emp_gw_etg&quot;, &quot;fh&quot;, &quot;nr&quot;) #--&gt; pmap2 feature_sets, forms (todo @oska) .. or maybe map across forms but not feature sets here, as we need bespoke exclusions exclude_demog_coefs &lt;- c(&quot;response&quot;,&quot;older&quot;, &quot;post_med&quot;, &quot;ln_&quot; ) exclude_inc_coefs &lt;- c(&quot;response&quot;, &quot;if above&quot;, &quot;older&quot;, &quot;na&quot;) #exclude_fh_coefs &lt;- c(&quot;response&quot;, &quot;if above&quot;, &quot;older&quot;) #will prob need to add coefs for all the small fh categories if we put these all in demog_coefs_qp &lt;- extract_coefs(qp_coefs, demog_coefs, exclude = c(exclude_demog_coefs)) emp_gw_etg_coefs_qp &lt;- extract_coefs(qp_coefs, emp_gw_etg_coefs, exclude = exclude_inc_coefs) nr_coefs_qp &lt;- extract_coefs(qp_coefs, nr_coefs) nonlin_coefs_qp &lt;- extract_coefs(qp_coefs, nonlin_coefs) nonlin_coefs_qp_noexp &lt;- extract_coefs(qp_coefs_noexp, nonlin_coefs) nonlin_coefs_qp_combo &lt;- bind_rows(nonlin_coefs_qp_noexp %&gt;% filter(str_detect(term, &quot;Year of&quot;)==FALSE), nonlin_coefs_qp %&gt;% filter(str_detect(term, &quot;Year of&quot;)==TRUE)) demog_coefs_fl &lt;- extract_coefs(fl_coefs, demog_coefs, exclude = exclude_demog_coefs) emp_gw_etg_coefs_fl &lt;- extract_coefs(fl_coefs, emp_gw_etg_coefs, exclude = exclude_inc_coefs) #TODO: doublecheck the income coefficients: nr_coefs_fl &lt;- extract_coefs(fl_coefs, nr_coefs) nonlin_coefs_fl &lt;- extract_coefs(fl_coefs, nonlin_coefs) nonlin_coefs_fl_noexp &lt;- extract_coefs(fl_coefs_noexp, nonlin_coefs) nonlin_coefs_fl_noexp_nonrobust &lt;- extract_coefs(fl_coefs_noexp_nonrobust, nonlin_coefs) nonlin_coefs_fl_combo &lt;- bind_rows(nonlin_coefs_fl_noexp %&gt;% filter(str_detect(term, &quot;Year of&quot;)==FALSE), nonlin_coefs_fl %&gt;% filter(str_detect(term, &quot;Year of&quot;)==TRUE)) demog_coefs_logit &lt;- extract_coefs(logit_coefs, demog_coefs, exclude = exclude_demog_coefs) emp_gw_etg_coefs_logit &lt;- extract_coefs(logit_coefs, c(&quot;income&quot;, emp_gw_etg_coefs), exclude = exclude_inc_coefs) nr_coefs_logit &lt;- extract_coefs(logit_coefs, nr_coefs) nonlin_coefs_logit &lt;- extract_coefs(logit_coefs, nonlin_coefs) group_fp_do &lt;- function(df, groups=model_name, xlims=c(NA,NA), vl=1){ df %&gt;% grouped_forest_plot(., groups = {{groups}}, vline = {{vl}}) + coord_cartesian(xlim = {{xlims}}) + scale_colour_discrete(name = &quot;&quot;, labels = function(x) str_wrap(x, width = 15)) + theme_bw() + theme(legend.position = &quot;bottom&quot;) + guides(fill=guide_legend(nrow=2,byrow=TRUE)) } #TODO: Add to caption at bottom, automate, specify the exact models (or at least explain the control variables) # Legend on top or bottom? # Todo -- gray line in background # add more grid lines fp_qp_subtitle &lt;- &quot;Quasi-poisson: relative rates, 95% CIs (Robust SEs); colors = models&quot; fp_logit_subtitle &lt;- &quot;Logit model, proportional effects, 95% CIs; colors = models&quot; fp_fl_subtitle &lt;- &quot;Frac. Logit model, prop. effects, 95% CIs; colors = models&quot; fp_caption = str_wrap(&quot;Results come from three distinct models, each with different sets of features. These models and their features are fully described in the main text. All confidence intervals are heteroskedasticity-robust (White, 1980).&quot;, 120) #todo (@oska) purr::map these too fp_demog_coefs_qp &lt;- demog_coefs_qp %&gt;% group_fp_do(vl=1) + labs(title= &quot;&#39;Donation amount&#39;, demog. coefficients&quot;, subtitle = fp_logit_subtitle, caption = fp_caption ) + theme(plot.caption = element_text(size = 8, hjust = 0)) fp_demog_coefs_fl &lt;- demog_coefs_fl %&gt;% group_fp_do(vl=1) + labs(title= &quot;&#39;Donation/income&#39;, demog. coefficients, 2018-20&quot;, subtitle = fp_fl_subtitle, caption = fp_caption) #TODO -- get me my ticks for 0.25, 0.5 etc fp_demog_coefs_logit &lt;- demog_coefs_logit %&gt;% group_fp_do(vl=1) + labs(title= &quot;&#39;Donated $1000+&#39;, demog. coef., 2018-20&quot;, subtitle = fp_logit_subtitle, caption = fp_caption) #todo (@oska) purr::map these too fp_emp_gw_etg_coefs_qp &lt;- emp_gw_etg_coefs_qp %&gt;% filter(!(str_detect(model_name, &quot;Robust&quot;) &amp; str_detect(term, &quot;Income&quot;))) %&gt;% #Don&#39;t show income in models with nonlinear income terms group_fp_do(vl=1) + labs(title= &quot;&#39;Donation amount&#39;, career-related coefs, 2018-20&quot;, subtitle = fp_qp_subtitle, caption = fp_caption) #TODO -- NA STILL HERE! fp_emp_gw_etg_coefs_fl &lt;- emp_gw_etg_coefs_fl %&gt;% filter(!(str_detect(model_name, &quot;Robust&quot;) &amp; str_detect(term, &quot;Income&quot;))) %&gt;% group_fp_do(vl=1) + labs(title= &quot;&#39;Donation as share of income&#39;, proportional model, career-related coefs&quot;, subtitle = fp_qp_subtitle, caption = fp_caption) fp_emp_gw_etg_coefs_logit &lt;- emp_gw_etg_coefs_logit %&gt;% filter(!(str_detect(model_name, &quot;Robust&quot;) &amp; str_detect(term, &quot;Income&quot;))) %&gt;% filter(!(str_detect(term, &quot;NA&quot;))) %&gt;% group_fp_do(vl=1, xlims=c(0,NA)) + labs(title= &quot;&#39;Donated $1000+&#39;, Logit model, career-related coefs&quot;, subtitle = fp_logit_subtitle, caption = c(fp_caption) ) ### ##TODO -- get NA out of here! Model theme: Demographics Below, we plot the estimates and (heteroskedasticity-robust) 95% confidence intervals for key demographic coefficients for each of the three models. Again, we want to emphasize that each these are from models which also ‘control’ for a wide set of characteristics (e.g., income, age, and time-in-EA), as cataloged above. We first present the results from our Quasi-Poisson model of donation amount (expressed as the average of current and planned donation in a year, or whichever is noted). This model allows effects to be “proportional,” as described and interpreted below.* * The exponentiated coefficients presented here can be interpreted as ‘in considering average donations for each group, by what amount should we multiply this if we look at an individual with the variable ’switched on’ versus switched off’, all else equal’? For continuous variables, it expresses ’how much do we multiply this if we increase our the variable by one (normalized) measure? fp_demog_coefs_qp In the figure above, the vertical bar at “1” represents the coefficient of “no difference in donation between these groups, all else equal.” As all of the 95% confidence intervals cross this line (for City, just barely), we cannot rule out ‘no difference’ by conventional frequentist null-hypothesis testing. Still, the evidence suggests that (all else equal), individuals from big cities named in the EA survey donate substantially more.** ** We did not run a Bayesian analysis here. However, in our experience such approaches, under a flat prior belief, put most of the posterior probability mass within similar ranges as do the frequentist confidence intervals. This would suggest we could be fairly confident that (e.g.) those from big EA cities tend to donate more, all else equal. However, further, explicit Bayesian analysis might be merited. Point estimates imply they donate about 18-19% more on average (considering our baseline model and our model with robust controls), or about 25% more on average, when we also adjust for earning-to-give and GWWC status.** *** However, GWWC and EtG can be seen as very closely related to the outcome we are looking for; thus, even in a descriptive sense, this coefficient is hard to interpret in model 3. Ethnicity seems to have very little relationship to donation here, or at least we have little evidence to suggest a relationship. The coefficients on “Not just white” are close to zero, with wide 95% confidence intervals. The gender coefficients weakly suggest that women and nonbinary people donate somewhat less, all else equal. Students seem to donate substantially less, perhaps only 70-80% as much as nonstudents. Still, in a conventional sense (95% confidence interval), we cannot rule out that any of these differences observed in our sample are due to chance, and that in fact, the differences in the relevant population are zero, or in the opposite direction. (Also, see caveats in other post about potential non-representativeness, recall bias and measurement error, etc.) fp_demog_coefs_fl Above we plot the estimates, for the same features, for our (Fractional Logit) models of the ‘share of income donated’ (where income is imputed where 0 or below 5000, as explained above).* * Here, we topcode the (relatively few) responses that report donations in excess of income to have a value of 1 (donated 100% of income.) As in all of these plots, these are from models containing the three broad sets of features outlined above, including (the log of) reported income; thus we do not impose an exact proportional relationship between income and donations. We find generally similar results as in the models of donation amounts, with perhaps a slightly more important role for gender (non-males donating a lower share all else equal), and a slightly less important role for student status. However, none of these coefficients are statistically significant in a conventional sense. rpct &lt;- function(x){ (round(x, 3) -1)*100} EAs living in named cities donate a substantially higher share of their income, all else equal – a roughly 6.8% greater share in our baseline model.* * Note – this doesn’t mean they donate 20 more percentage points of their income; the share of the income they donate, on average, is 20% larger. E.g., if a group of non-big-EA-city-people donated 10% of their income on average, we might expect a comparable big-EA-city group of people to donate 12% of their income on average. Again, we have little evidence that ethnicity is related to this outcome. Non-males seem to be donating a somewhat lower share of income, 89.2% as high a share in our baseline model. Students also seem to donate lower shares, 94.4% as high in our baseline model. fp_demog_coefs_logit The final outcome variable is ‘whether an individual donated $1000 or more.’ Here we also present the normalized age coefficient.* * Recall, for the models of other outcomes we present age in a later table, in elasticity terms) Age has a strong relationship with this outcome: a two standard deviation increase in age (about 19.6 years older) is associated with a near-doubling of the probability of donating 1000 USD or more in our model. (1.78 times as high in our baseline model.) Again, in our baseline model… EAs living in named big cities are more likely – roughly 18.4% more likely, Non-males are about 80.9% as likely as males, ‘Not-just-white’ people about 82.3% as likely as white people, and students 62.9% as likely as nonstudents… …to donate at least 1000 dollars, all else equal. The graph suggests that each of these results are similar across the three models. Most of these coefficients are statistically significant in a conventional sense Model theme: Employment/career, GwwC, EtG, (income) Next we consider employment and career-related features.* * We consider the relationship between income and donations and donations as a share of income in the next section. For these models we express income in natural logs, so the interpretation of the ‘raw coefficients’ are approximately income elasticities; these are not on the same scale as the standardized coefficients below. fp_emp_gw_etg_coefs_qp Unsurprisingly, those who report ever having taken the GWWC pledge, and those who report being in an Earning-to-Give career also report donating substantially more, all else equal. However, the magnitudes are strikingly large: they donate nearly twice as much, and over 50% more, respectively. Those who attended global top-6 universities (defined above) also donate substantially more, about 34.8% more in our baseline model point estimate. Those part-time-employed seem to donate somewhat more, all else equal, although confidence intervals are very wide. Those who are not employed tend to donate less. fp_emp_gw_etg_coefs_fl Similarly to above, those who report ever having taken the GWWC pledge, and those who report being in an Earning-to-Give career tend to donate a much larger share of income than the rest, all else equal. Specifically, over twice as large a share for GWWC, and over 50% more for EtG. We see similar patterns as above for top-6 university and for those who are not employed. However the results for part-time employer contrast to the previous plot. While the part-time employed tend to donate somewhat more overall, they tend to donate a lower share of their income than the base group (the full-time employed), all else equal. (Again, recall that this already controls for income and other factors.) fp_emp_gw_etg_coefs_logit We see similar patterns for our logit models of “whether donated at least 1000 USD,” with some notable exceptions. Similarly, GWWC pledgers are much more likely to donate at least this amount. EtG people show a less dramatic difference, only being about 31.5% more likely than the base group, all else equal. Here (for models without the two-part controls) we also present the relationship to income. Unsurprisingly, income has a strong positive association with the probability of donating 1k or more: An income that is 56125 USD greater (the 25-75 ‘interquartile range’) is associated with a 2.82 times greater probability of this. Those from top-6 universities and the part-time employed appear slightly (but not ‘significantly’) more likely to donate 1k or more, all else equal. The not-employed are substantially less likely to donate 1k or more. Age, time-in-EA, Income, Year; possible nonlinearity #Making table of *raw coefficients* for logged income variables here, as these have elasticity interpretations nonlin_tables &lt;- bind_rows(nonlin_coefs_qp_combo, nonlin_coefs_fl_combo, nonlin_coefs_logit) %&gt;% select(outcome, term, model_name, estimate, std.error, p.value, conf.low, conf.high) %&gt;% mutate( term = str_replace_all(term, c(&quot;ln_&quot; = &quot;log &quot;, &quot;EApost_med&quot; = &quot;EA (post median)&quot;)), term = str_replace_all(term, key_eas_all_labels), term = str_replace_all(term, c(&quot;Involved&quot; = &quot;in&quot;)), term = str_replace_all(term, c(&quot;_bc5k&quot; = &quot;&quot;)), term = str_replace_all(term, c(&quot;imp.&quot; = &quot;imp., bc&quot;)), term = str_replace_all(term, c(&quot;years_inv_d2spost_med&quot; = &quot;Years in EA (2sd norm) post-median&quot;)) ) %&gt;% filter(!str_detect(model_name, &quot;GWWC&quot;)) %&gt;% mutate( outcome = str_replace_all(outcome, key_eas_all_labels ) ) %&gt;% arrange(term) %&gt;% group_by(outcome) %&gt;% group_split nonlin_don_avg_tab &lt;- nonlin_tables[[1]] %&gt;% select(-outcome) %&gt;% .kable(caption = nonlin_tables[[1]][[1,&quot;outcome&quot;]], col.names = NA, digits=3) %&gt;% .kable_styling(&quot;striped&quot;) nonlin_don_gt1k_tab &lt;- nonlin_tables[[2]] %&gt;% select(-outcome) %&gt;% .kable(caption = nonlin_tables[[2]][[1,&quot;outcome&quot;]], col.names = NA, digits=3) %&gt;% .kable_styling(&quot;striped&quot;) nonlin_donshare_tab &lt;- nonlin_tables[[3]] %&gt;% select(-outcome) %&gt;% .kable(caption = nonlin_tables[[3]][[1,&quot;outcome&quot;]], col.names = NA, digits=3) %&gt;% .kable_styling(&quot;striped&quot;) We next present the estimates, from six of the nine models (excluding models involving GWWC and earning-to-give), for the continuous-valued features (age, income, and years-in-EA) as well for the survey-year categorical feature. We present these for both the baseline and the ‘Robust control’ models; the latter allow us to consider distinct patterns where values are above-median. We present these in tables rather than forest plots, as the interpretation is subtle. We first consider the models of amount donated, using the proportional (Quasi-Poisson) specification. Below, the coefficients are reported in a way that allows them to be considered as elasticities (discussed below). The coefficient on the survey year dummies are presented in a way that allows the ‘proportional change’ interpretation, as presented in previous plots.* * Technical note: this intepretation is possible because we exponentiate these coefficients (i.e., raise the exponential constant to the power of the coefficients) for the survey year dummies, but report the remaining coefficients in their raw form. nonlin_don_avg_tab Table 4.10: Don. ‘avg’ term model_name estimate std.error p.value conf.low conf.high log age Baseline 0.538 0.334 0.107 -0.116 1.193 log age Robust controls 0.386 0.399 0.333 -0.395 1.168 log Age (if age &gt; med.) Robust controls 0.037 0.049 0.451 -0.060 0.134 Log income (imp., bc) Baseline 0.948 0.095 0.000 0.761 1.135 Log income (imp., bc) Robust controls 0.929 0.113 0.000 0.707 1.152 Log Income (imp., bc) (if above med.) Robust controls 0.012 0.020 0.571 -0.028 0.052 log Years in EA Baseline 0.628 0.100 0.000 0.431 0.825 log Years in EA Robust controls 0.533 0.143 0.000 0.253 0.813 log Years in EA (post median) Robust controls 0.070 0.117 0.550 -0.159 0.298 Year of survey: 2019 Baseline 1.218 0.362 0.586 0.599 2.476 Year of survey: 2019 Robust controls 1.194 0.356 0.618 0.594 2.399 Year of survey: 2020 Baseline 1.220 0.387 0.607 0.571 2.606 Year of survey: 2020 Robust controls 1.187 0.385 0.656 0.558 2.526 In the Baseline model, we see that, unsurprisingly, donations clearly and strongly increase in income, all else equal; in the parlance of Economics, donation seems to be a ‘Normal good.’ The estimated income elasticity is 0.948, suggesting that, all else equal, on average, as income increases in our data by some share ‘X,’ donations increase by slightly less than this share. I.e. donations increase slightly less than proportionally with income, suggesting that donation are not a ‘luxury good’ in the strict Econ-1 sense. However, the upper confidence interval is still somewhat above 1 (and the usual caveats about sample selection, unobservable factors, and causality apply). In model 2 we include an adjustment coefficient to allow nonlinearity, allowing the elasticity of donations in income to be distinct for income levels above the median. This coefficient is positive (very loosely suggesting that, for above-average levels of income, greater income leads to proportionally greater donations) but it is very small, and we cannot rule out zero difference. Arguably, the fact that even the upper confidence interval for this adjustment is rather small speaks against a very strong nonlinearity, and in favor of a ‘proportional donations’ model as a starting point. Age has a positive relationship to donation; the baseline coefficient suggests that as age doubles, contributions increase by of 53.8% on average, all else equal. Model 2 suggests that this ‘age relationship’ is approximately proportional in this way, with only a small (and statistically insignificant) positive adjustment for ages above the median (age 28). Time-in-EA is strongly related to donations, even ‘controlling for age, etc.’ (and vice versa). A doubling of years in EA is associated with a 62.8% greater donation. The nonlinear adjustment term is again fairly small and statistically insignificant. Each of the ‘survey year difference’ estimates (for 2019 and 2020, with 2018 as the base year) are fairly close to 1 (representing ‘no difference’). However, 95% confidence intervals are rather wide, suggesting a lack of statistical power to discern a difference.* * This suggests that we may have little power to discern whether (all else equal) there are strong differences between donations among respondents to each survey, all else equal. Still, our best guess might be something close to a zero difference, and we might reasonably put substantial probability that any differences are not extremely large. (Strictly speaking, we would need to estimate Bayesian credible intervals to make statements like this; we use the standard frequentist confidence intervals somewhat imprecisely.) We next present the corresponding coefficients for our fractional logit models of ‘donations as a share of income.’ nonlin_donshare_tab Table 4.10: Don./Income (imp, bc) term model_name estimate std.error p.value conf.low conf.high log age Baseline 0.853 0.150 0.000 0.559 1.147 log age Robust controls 0.928 0.197 0.000 0.540 1.315 log Age (if age &gt; med.) Robust controls -0.016 0.026 0.530 -0.066 0.034 Log income (imp., bc) Baseline 0.043 0.044 0.331 -0.043 0.128 Log income (imp., bc) Robust controls 0.025 0.059 0.674 -0.091 0.140 Log Income (imp., bc) (if above med.) Robust controls 0.006 0.010 0.554 -0.013 0.024 log Years in EA Baseline 0.614 0.050 0.000 0.517 0.711 log Years in EA Robust controls 0.673 0.085 0.000 0.506 0.840 log Years in EA (post median) Robust controls -0.046 0.058 0.424 -0.159 0.067 Year of survey: 2019 Baseline 0.690 0.131 0.005 0.534 0.893 Year of survey: 2019 Robust controls 0.696 0.132 0.006 0.537 0.901 Year of survey: 2020 Baseline 0.674 0.141 0.005 0.511 0.889 Year of survey: 2020 Robust controls 0.682 0.141 0.007 0.517 0.900 The baseline models suggest that donation as a share of income is roughly constant, or slightly increasing in income. For every doubling of income, the share of income donated is seen to increase by 4.26%. While the 95% confidence intervals include small decreases or increases in this share as income doubles (from about -5% to +13%), the evidence suggests approximate proportionality. Model 2 suggests this pattern continues at larger incomes, with little apparent nonlinearity above median income (and fairly tight bounds on this). Age is very strongly positively associated with ‘donation as a share of income,’ with a doubling of age approximately relating to a 85.3% increase in share of income donated (i.e., more than a doubling of this share, on average, all other observables held constant).* * We want to emphasize each of these coefficients ‘hold other observable things constant.’ E.g., age has the mentioned very strong relationship to share of income donated—even holding time-in-EA constant and vice versa. Years-in-EA also shows a very strong association to share of income donated, with a doubling of this ‘tenure’ approximately relating to a 61.4% increase in share of income donated. The adjustment coefficients for each of these are small and fairly-tightly bounded, suggesting perhaps only small differences in the above relationships for values of age and tenure above the medians. In these models we do find some statistically significant associations between survey year and share-of-income donated, all else equal, with 2019 and 2020 generally having lower values than 2018. However, we do not want to read too much into this, given possible differences in survey response composition, as discussed in other posts. Finally, we consider the models of ‘donated 1k or more’: nonlin_don_gt1k_tab Table 4.10: Don. &gt; 1k USD term model_name estimate std.error p.value conf.low conf.high Age (2sd norm.) Baseline 1.776 0.089 0.000 1.493 2.113 Age (2sd norm.) Robust controls 1.816 0.157 0.000 1.334 2.473 Age if older (norm.) Robust controls 0.971 0.158 0.853 0.712 1.324 Income (imp., bc, IQR norm) Baseline 2.823 0.129 0.000 2.193 3.634 Income (imp., bc, IQR norm) Robust controls 4.575 0.074 0.000 3.956 5.290 Income (imp., bc, IQR norm)_if_richer Robust controls 0.363 0.121 0.000 0.287 0.460 Year of survey: 2019 Baseline 0.721 0.138 0.017 0.551 0.944 Year of survey: 2019 Robust controls 0.720 0.142 0.020 0.546 0.950 Year of survey: 2020 Baseline 0.611 0.144 0.001 0.461 0.810 Year of survey: 2020 Robust controls 0.627 0.149 0.002 0.468 0.839 Years in EA (2 sd norm.) Baseline 2.447 0.077 0.000 2.105 2.846 Years in EA (2 sd norm.) Robust controls 8.011 0.184 0.000 5.587 11.486 Years in EA (2sd norm) post-median Robust controls 0.156 0.266 0.000 0.092 0.262 Here we present exponentiated coefficients, representing relative proportional rates of this outcome for the distinct groups. Age is strongly positively associated with this outcome (as for the other donation outcomes), with a 2 sd difference in age (about 20.1) years associated with a near doubling of the probability of making a 1k donation. Unsurprisingly, income is also strongly associated with donating 1k or more. The coefficients for the 2019 and (especially) 2020 EA survey year dummies are substantially below 1, suggesting donating 1k or more is becoming less prevalent among otherwise-similar individuals. However, as noted above, we are cautious about these ‘year coefficients’ because of potential changes in EA survey promotion and response that may not reflect actual changes in the EA population. The ‘years in EA’ coefficients are also extremely strong. These suggest that a 2 sd increase in tenure in EA (4.89 years) is associated with a 2.45 times greater relative chance of donating 1k or more relative to the base group), all else equal. 4.8.2 Predictive models We use elastic-net and random-forest modeling approaches with validation (these are standard in the modern ‘machine learning’ tooklit), to derive a model that ‘predicts well.’* We discuss what these models may or may not be useful for in the bookdown (see margin note and fold HERE). * In previous-years’ posts we used a backwards-selection procedure. The approaches we are using in the current post are more common in modern applied statistics and data science (at least according to Andrew Gelman). The elastic net models ‘penalize’ the magnitude of (the square or level) coefficients in a way that improves out-of-sample prediction. The penalization parameters are ‘tuned’ on ‘cross-fold’ data, and these models are trained and tested on separate partitions of the data. We focus on predicting the individual’s donation in a year, focusing on the same set of outcomes used in the previous section. For this model to be useful for an actual prediction problem going forward, it would need to rely on ‘ex-ante’ characteristic that were already observable at the time of a career/EtG/pledge decision.* *An alternate project might try to predict future total EA donations in total in subsequent years and decades. This could embody both a prediction problem for individuals and uncertainties at the aggregate level. This is even further from what we are doing here, but seems worthwhile for future work, combining the EA survey with other measures and assessments. These might include immutable demographics, career plans, and pledges previously taken, and consider year and trend effects. Although we have these models in mind, this is not what we are doing here. We are not posing a specific ‘prediction problem’ per se. Instead we are using machine learning tools built for prediction problems to generate ‘data-driven insights’ about factors related to EA donation behavior. Here, we do not than directly specifying all of the included components of the model (features, interaction terms, etc.). Instead we provide a large set of possible ‘inputs’ and use ML techniques to train models that should predict well outside of the data they are trained on. These models should do a good job of accomplishing the task: ‘if you gave me a set of features of an EA, I should have a fairly accurate guess at what they will donate.’ The insights from these models should also be treated with caution. Again, they may not be deriving causal relationships. Furthermore, the parameters derived from model-fitting ML procedures are not in general unbiased or consistent, and it is difficult to derive proper confidence intervals for these parameters. Still, the benefit of this exercise may be considered ‘the derivation of robust and predictive relationships in the data that are mainly driven by the data itself, rather than our preconcieved ideas.’ These models may also be useful building blocks towards future predictive work. Note: The content in the present note will be part of the ‘Bookdown’ version only and not in the EA forum post. In the post we will note: “In the more extensive hosted version of this report we explain our use and choices of machine-learning approaches in more detail. See link [HERE].” … In brief, the elastic net models involve linear models (log-linear in our case), i.e., ‘regressions,’ that carefully ‘penalize’ the (squared) magnitude of coefficients, in effect shrinking these towards zero. The penalties are specifically ‘tuned’ and ‘validated’ to maximize the predictive power of the model. As these are essentially regression approaches, we can report the sign and magnitude of the coefficients used in the ‘optimally tuned’ predictive model. (However, we should be careful about interpreting these parameters, and statistical inference is challenging. See e.g., Mullainathan and Spiess (2017a) for a detailed discussion.) Decision tree models (which we do not report on here) take a different approach, attempting to discern optimal ways to split the data into conditional groups (e.g., ‘income over 20k’) and subgroups (e.g., ‘students versus nonstudents with income below 20k’), and finally making a prediction for each subgroup at the ‘bottom of the tree.’ The random forest approach extends the above to allow a sort of averaging across an ensemble of trees that are derived independently, each selecting a random subset of the features. We fit these models/approaches, starting with a wide set of potential features, to explain each of the three main outcomes considered above. The features include (nearly) all of those considered above, as well as ‘where first heard of EA’ responses.* Below, we plot the seven most ‘important’ features (aka variables) for predicting the log of donation amount (average of planned and actual, where available) according to the random forest and elastic net (‘regression’) models.* * ‘Giving What we Can’ pledge was not included here, because this seems to be too close to the outcome of interest (i.e., it seems to be a very strong collider). We do not include the decision-tree model in this plot: while such models are useful for interpretation, they are relatively unstable. # Need to see each of these variables for all models tuning_folder &lt;- here(&quot;analysis&quot;, &quot;intermed_results&quot;, &quot;donation_prediction&quot;, &quot;tuning_results&quot;) final_models &lt;- here(&quot;analysis&quot;, &quot;intermed_results&quot;, &quot;donation_prediction&quot;, &quot;final_models&quot;) l_don_av_2yr_best_params &lt;- readRDS(here(final_models, &quot;l_don_av_2yr.Rdata&quot;)) %&gt;% filter(!grepl(&quot;decision&quot;, model, ignore.case = TRUE)) don_share_inc_imp_best_params &lt;- readRDS(here(final_models, &quot;don_share_inc_imp.Rdata&quot;)) %&gt;% filter(!grepl(&quot;decision&quot;, model, ignore.case = TRUE)) d_don_1k_best_params &lt;- readRDS(here(final_models, &quot;d_don_1k.Rdata&quot;)) %&gt;% filter(!grepl(&quot;decision&quot;, model, ignore.case = TRUE)) l_don_av_2yr_best_params_filter &lt;- readRDS(here(final_models, &quot;l_don_av_2yr_filter.Rdata&quot;)) %&gt;% filter(!grepl(&quot;decision&quot;, model, ignore.case = TRUE)) # don_share_inc_imp_best_params_filter &lt;- readRDS(here(final_models, &quot;don_share_inc_imp_filter.Rdata&quot;)) # d_don_1k_best_params_filter &lt;- readRDS(here(final_models, &quot;d_don_1k_filter.Rdata&quot;)) l_don_av_2yr_best_params &lt;- l_don_av_2yr_best_params %&gt;% bind_rows(l_don_av_2yr_best_params_filter) #don_share_inc_imp_best_params &lt;- don_share_inc_imp_best_params %&gt;% bind_rows(don_share_inc_imp_best_params_filter) #d_don_1k_best_params &lt;- d_don_1k_best_params %&gt;% bind_rows(d_don_1k_best_params_filter) recode_params &lt;- function(df){ # Shortcut function to tidy up variable names in parameter df df &lt;- df %&gt;% dplyr::select(model, vi) %&gt;% tidyr::unnest(vi) %&gt;% mutate(model = str_replace_all(model, c(&quot;preprocess_&quot; = &quot;&quot;, &quot;_&quot; = &quot; &quot;)), Variable = str_replace_all(Variable, key_eas_all_labels), Variable = str_replace_all(Variable, c(&quot;_&quot; = &quot; &quot;, &quot;_Student&quot; =&quot;&quot;, &quot;ln&quot; = &quot;log&quot;)), Sign = if_else(is.na(Sign), &quot;NA&quot;, Sign)) } norm_vi &lt;- function(df, slice_top = 7){ # Shortcut function for calculating normalized variable importance # Not reproducible... df %&gt;% group_by(model) %&gt;% mutate(Norm = scale_var(Importance)) %&gt;% group_by(Variable) %&gt;% mutate(Total_Norm = sum(Norm)) %&gt;% group_by(model) %&gt;% slice_max(Total_Norm, n = slice_top) %&gt;% mutate(Variable = fct_reorder(Variable, Norm)) } plot_vi &lt;- function(df, shapes = shape_colours){ # Shortcut function for plotting normalized variable importance (output of norm_vi) df %&gt;% ggplot(aes(y = Variable, x = Norm, colour = model, shape = Sign)) + scale_shape_manual(values = shapes) + geom_point(size = 4, stroke = 5) + xlab(&quot;Normalised feature importance&quot;) + ylab(&quot;&quot;) } #specific changing of variable and signs for the below. mutate_labels_sign_snip &lt;- function(df) { df %&gt;% mutate( Variable = str_replace_all(Variable, c(&quot;First-heard EA&quot;=&quot;Heard EA:&quot;, &quot;response&quot; = &quot;resp.&quot;, &quot;Gender Gender&quot; = &quot;Gender&quot;, &quot;unknown&quot; = &quot;No resp.&quot;, &quot;Student Student&quot; = &quot;Student&quot;, &quot;X80000&quot; = &quot;80000&quot;)), Sign = if_else(is.na(Sign), &quot;NA&quot;, Sign) ) } # Set colors for shapes as a named vector shape_colours &lt;- c(&quot;NA&quot; = 120, &quot;NEG&quot; = 95, &quot;POS&quot; = 43) # Tidy up parameters l_don_av_2yr_best_params_recode &lt;- l_don_av_2yr_best_params %&gt;% filter(is.na(filter_name)) %&gt;% recode_params l_don_av_2yr_best_params_recode_filter &lt;- l_don_av_2yr_best_params %&gt;% filter(!is.na(filter_name)) %&gt;% recode_params don_share_inc_imp_best_params_recode &lt;- don_share_inc_imp_best_params %&gt;% recode_params d_don_1k_best_params_recode &lt;- d_don_1k_best_params %&gt;% recode_params #NOT RUN # Starting to plot decision trees (early stages) l_don_av_2yr_tree &lt;- l_don_av_2yr_best_params %&gt;% mutate( model = str_replace_all( model, c(&quot;preprocess_&quot; = &quot;&quot;, &quot;_&quot; = &quot; &quot;)) ) %&gt;% filter(!grepl(&quot;decision&quot;, model, ignore.case = TRUE)) ) %$% workflowsets::extract_fit_parsnip(fit[[1]]) # l_don_av_2yr_treeX &lt;- l_don_av_2yr_best_params %&gt;% # mutate( # model = str_replace_all( # model, c(&quot;preprocess_&quot; = &quot;&quot;, &quot;_&quot; = &quot; &quot;)) # ) %&gt;% # filter(str_det(model, &quot;decision tree&quot;)) %$% # workflowsets::extract_fit_parsnip(fit[[1]]) #, fig.dim = c(10, 10) ( iplot_l_don_av_2yr_best_params &lt;- l_don_av_2yr_best_params_recode %&gt;% filter(!grepl(&quot;tree&quot;, model, ignore.case = TRUE)) %&gt;% norm_vi(slice_top = 10) %&gt;% mutate_labels_sign_snip %&gt;% slice_max(Total_Norm, n = 10) %&gt;% mutate(Variable = fct_reorder(Variable, Norm)) %&gt;% ggplot(aes(y = Variable, x = Norm, colour = model, shape = Sign)) + scale_shape_manual(values = c(120, 95, 43)) + geom_point( position = position_jitter(seed = 42, width = 0.1, height = 0.1), size = 4, stroke = 5) + xlab(&quot;Normalised feature importance&quot;) + ylab(element_blank()) + ggtitle(&quot;Normalized importance scores: predicting log(don.)&quot;) ) Above, we report the ‘importance scores’ for the ten most important features (‘variables’) for two distinct approaches to predicting log (average) donation.* * Note that (as is common in machine learning modeling) all features have been normalized to be on the same scale; for continuous features such as age and income we take the natural log of each, and divide each by two standard deviations of the logged feature, following Gelman (2008). These importance scores are technically defined here. For the elastic net (“linear reg”) approach, we depict the coefficients’ signs with a “+” or “-”; for tree/forest-based modeling this is less straightforward. Income (normalized, bottom-coded at 5000 USD, and logged) is the most important predictor in for each model, by a wide margin. After this, the relative importances vary. E.g., the random forest model deems age and student status to be particularly important, while linear model does not; in turn the linear model puts substantial importance on non-response to the student status question, but the random forest modeling does not. Both put substantial importance on years involved and ‘not employed’ statuses. Considering ‘where one first-heard of EA,’ the linear model finds nonresponse and (to a lesser extent) GiveWell to be positively related and important, and 80000 hours to be negatively related to the predicted donation. It also finds Earning to Give to be somewhat important (and positively related), but perhaps to a lesser extent than we might have expected. As they are difficult to interpret, and probably not useful for future predictions, we will basically not discuss the non-response features further.* * We might expect non-response to be associated with lower engagement, and perhaps lower donation rates. However, we are considering non-responses to particular questions among those who did report a donation amount. We could speculate about why non-response to the ‘where heard of EA’ question seems to be associated with donating more. E.g., perhaps people who donate more tend to come from a group that don’t feel as connected to any of the EA organizations/sources listed, but didn’t want to put “other/don’t remember” so skip the question. Or perhaps this nonresponse is picking up something about the value of time or income that was not fully captured in the income question (which not everyone answers) We hope to investigate this in future work. However, we don’t expect that this nonresponse will be useful in models aimed at predicting future donations, as the nonresponse here is basically occurring contemporaneously with donations. Note also that statisticians and economists caution against drawing inferences from machine-learning predictive models (Mullainathan and Spiess (2017b)). As our data exhibited some large donation amount outliers, (which is naturally tied to high income), we re-trained models on a subset of the data with only respondents who earned less than $500,000, with importance scores reported below. ( iplot_l_don_av_2yr_best_params_filter &lt;- l_don_av_2yr_best_params_recode_filter %&gt;% filter(!grepl(&quot;tree&quot;, model, ignore.case = TRUE)) %&gt;% norm_vi(slice_top = 10) %&gt;% mutate_labels_sign_snip %&gt;% slice_max(Total_Norm, n = 10) %&gt;% mutate(Variable = fct_reorder(Variable, Norm)) %&gt;% ggplot(aes(y = Variable, x = Norm, colour = model, shape = Sign)) + scale_shape_manual(values = c(120, 95, 43)) + geom_point( position = position_jitter(seed = 42, width = 0.1, height = 0.1), size = 4, stroke = 5) + xlab(&quot;Normalised feature importance&quot;) + ggtitle(&quot;Importance: predict log(don.) (filter: income &lt; 500k)&quot;) ) The results are very similar. Again income is still the most important predictor for both models. The ranking of variables, and the importance scores are generally similar to the ‘unfiltered’ model above.* * Earning to give is no longer one of the ‘top 10 most important’ features, while having heard of EA through LessWrong shows up as fairly important and negative in the linear model. However, this may tell us more about the variance and sensitivity of the importance scores in these prediction model approaches than about any real differences in the correlates of donations. In the more extensive hosted ‘bookdown’ version we present further details and results from the elastic-net regression-based models (for this and other feature sets). See HERE. We next focus specifically on the elastic-net regression-based model. # TODO -- important -- what are the base groups here, especially for &#39;first-heard&#39;? I thought in previous work we made &quot;don&#39;t remember&quot; the base group! This is important for interpreting the coefficient signs! # Plot all coefficients for elastic net model #TODO (DR @ OF -- plot the coefficients rather than the importance weights? (the latter are absolute value t-values anyways)) #TODO/check DR @ OF -- why is &#39;year of survey 2015&#39; (and 2017) in here? those years should have been removed from the dataset; I think they have been, but still it somehow reports an importance score? -- OK I am removing &#39;0&#39; importance scores for now ( enet_coefs_ldon &lt;- l_don_av_2yr_best_params_recode %&gt;% filter( grepl(&quot;regression&quot;, model, ignore.case = TRUE) &amp; Importance!=0) %&gt;% mutate_labels_sign_snip %&gt;% #mutate(Norm = scale_var(Importance)) %&gt;% mutate(Variable = fct_reorder(Variable, Importance)) %&gt;% ggplot(aes(y = Variable, x = Importance, shape = Sign)) + scale_shape_manual(values = c(95, 43)) + geom_point(size = 2, stroke = 4) + xlab(&quot;Feature importance&quot;) + ggtitle(&quot;Importance scores: predicting log(don.)&quot;) ) The graph above presents the overall ranking of importance scores within the elastic-net linear regression model, with symbols depicting whether these features take on a positive or negative sign. In addition to those mentioned above, substantial importance is assigned to other ‘first heard’ sources, e.g., GWWC and several related sources, as well as Ted Talks positively predict log donation, while 80000 Hours, Facebook, and Educational course negatively predict log donation. Predictive model: Shares of income donated Next we consider the shares of income donated, with income imputed and bottom-coded as mentioned in previous sections. ( iplot_don_share_inc_imp_best_params &lt;- don_share_inc_imp_best_params_recode %&gt;% filter(!grepl(&quot;tree&quot;, model, ignore.case = TRUE)) %&gt;% mutate_labels_sign_snip %&gt;% norm_vi(slice_top = 10) %&gt;% plot_vi() + ggtitle(&quot;Importance scores: predicting share of income donated &quot;) ) (Log) Income is deemed highly important as a predictor of share of income donated, in the random forest models but not in the regression models.* * We speculate that this might be due to mechanical differences in the models: while a linear model allows predicted donations shares to ‘continuously scale with income,’ the random forest modeling needs to use discrete ‘branches.’ Also note that we explored the relationship between donations and income and income shares in more detail above, particularly in the final section of our descriptive modeling. Both types of models assign some importance to age and years involved; but this is much stronger in the random forest (in the linear models these have positive signs but only middling importance). On the other hand, while both also assign importance to reporting that one ‘could not remember or determine where they first heard of EA’; this is much stronger in the linear model (where it is deemed the most important feature, and it has a positive sign). Overall, the importance scores are rather divergent. The linear models assign some importance (and positive sign) to people indicating that they first heard of EA through ‘Raising for Effective Giving, EA Funds, the Foundational Research Institute or the “Swiss group”,’ through GWWC and related ‘pledge/charity orgs,’ and, to a much lesser extent, through GiveWell or through a Ted Talk.* * We recognize that these ‘first-heard’ groupings are somewhat ad-hoc and only moderately homogeneous. This may merit future work. Note also that the random forest models also put some importance on the nonlinear ‘years involved term.’ Further details and figures can be found in the ‘Bookdown’ version about HERE. We present the remaining signed non-zero importance scores from the linear model in the figure below. ( plot_enet_coefs_don_share &lt;- don_share_inc_imp_best_params_recode %&gt;% filter( grepl(&quot;regression&quot;, model, ignore.case = TRUE) &amp; Importance!=0) %&gt;% mutate_labels_sign_snip %&gt;% #mutate(Norm = scale_var(Importance)) %&gt;% mutate(Variable = fct_reorder(Variable, Importance)) %&gt;% ggplot(aes(y = Variable, x = Importance, shape = Sign)) + scale_shape_manual(values = c(95, 43)) + geom_point(size = 2, stroke = 4) + xlab(&quot;Feature importance&quot;) + ggtitle(&quot;Importance scores: predicting log(don.)&quot;) ) Predictive model: Donated 1k USD or more ( iplot_don_1k_best_params &lt;- d_don_1k_best_params_recode %&gt;% filter(!grepl(&quot;tree&quot;, model, ignore.case = TRUE)) %&gt;% mutate_labels_sign_snip %&gt;% norm_vi(slice_top = 10) %&gt;% plot_vi() + ggtitle(&quot;Importance scores: predicting donation &gt; 1k USD &quot;) ) Both approaches deem (logged, imputed, bottom-coded) income to be the most important predictor of donating 1k USD or more. Both also consider (log) years involved and age to be substantially important. The logistic regression elastic-net model assigns importance to several sources of ‘learning about EA,’ with ‘Ted Talks,’ ‘GWWC and related,’ and (less so) Givewell (as well as nonresponse) deemed particularly important, with positive signs . The random forest (but not the linear model) also deems student status to be a somewhat important associated feature. Further details and figures can be found in the ‘Bookdown’ version about HERE. Next, we plot the (nonzero) importance scores for all of the coefficients in the elastic-net logistic model of donating 1k or more. ( plot_enet_coefs_don_1k &lt;- d_don_1k_best_params_recode %&gt;% filter( grepl(&quot;logistic&quot;, model, ignore.case = TRUE) &amp; Importance!=0) %&gt;% mutate_labels_sign_snip %&gt;% #mutate(Norm = scale_var(Importance)) %&gt;% mutate(Variable = fct_reorder(Variable, Importance)) %&gt;% ggplot(aes(y = Variable, x = Importance, shape = Sign)) + scale_shape_manual(values = c(95, 43)) + geom_point(size = 2, stroke = 4) + xlab(&quot;Feature importance&quot;) + ggtitle(&quot;Importance scores: predicting donation &gt; 1000k USD&quot;) ) 4.8.2.1 Model Performance Note: In the hosted ‘bookdown’ we further discuss ‘how well these models predict’ (see final subsection of linked section). Overall, these models offer some predictive power. E.g., note that about 46% of the relevant sample reports over 1k in donations. Our logistic regression model can correctly predict 75% of these outcomes with a false-positive rate of around 25%.* * In comparison, a predictor that did not condition on observables could only correctly ‘catch’ 75% of these outcomes if it (randomly) predicted this outcome over 75% of the time, leading to a false-positive rate over 75%. We may want to consider ‘how successful’ our predictive models are at making practically useful predictions. In other words, ‘how far off’ are the predictions and classifications on average, from the actual outcomes. This procedure considers the fit on randomly-drawn set-aside ‘testing data,’ data that has not been used in ‘training’ (or ‘fitting’) the model. Below, we consider some commonly-used metrics. Regression Model Performance Reminder: this section (discussing performance) is only very briefly summarized/linked in the EA Forum post. In order to assess the usefulness of each predictive regression model we consider both root-mean-square-error (RMSE) and mean-absolute-error (MAE). RMSE (aka RMSD) can be interpreted as the average ‘Euclidean distance’ between the actual values and the model’s prediction. For each observation (in the set-aside ‘testing sample’), to construct RMSE we: Measure the differences between the actual and predicted outcome (e.g., donation) Square these differences Take the average of these squared differences across all observations Take the square root of this To construct mean-absolute-error (MAE) we simply Measure the absolute-value differences between the actual and predicted outcome (e.g., donation) for each observation Take the average of these across all observations MAE has a much more straightforward interpretation: it simply asks ‘how far off are we, on average?’ While the RMSE is used in the model fitting for various reasons, it is arguably less-interpretable and less-relevant than MAE in judging the model’s fit in cases like this one. RMSE error negatively assesses the model fit based on squared deviations, and is thus very sensitive to ‘large mistakes.’ This may be relevant where ‘large errors are much much worse than small ones’ – here, this is not so clearly the case. In the presence of data with large outlying observations, prediction will tend to be poor by this measure. To address this we: Present both RMSE and MAE Re-run the models of (log average) donations for the subset of individuals with incomes at or below 500,000 USD. For this subset, there are fewer influential donation outliers. The latter also allows us to consider how sensitive the model fit is to outliers. Note that when considering models where the outcome is transformed (e.g., log(donations)) we construct the RMSE and MAE by exponentiating to generate predictions for the level outcomes, and then measure the deviations on the level scale.* * When considering predicted outcomes on the logarithmic scale, both RMSE and MAE indicate roughly ‘how many exponential orders of magnitude our predictions for the non-logged outcomes are off. E.g., a MSE of 1.5 for ’log donation’ suggests an we are off by about \\(exp(1.5) =\\) 4.48 times in terms of donations, getting them off by a factor of about 5. This conversion avoid such complications. l_don_av_2yr_best_params &lt;- l_don_av_2yr_best_params %&gt;% mutate(dv = &quot;Donation amount*&quot;) don_share_inc_imp_best_params &lt;- don_share_inc_imp_best_params %&gt;% mutate(dv = &quot;Donation as a share of income&quot;) ( reg_model_performance &lt;- purrr::map(list(l_don_av_2yr_best_params, don_share_inc_imp_best_params), ~.x %&gt;% dplyr::select(dv, rmse, mae, model, matches(&quot;filter_name&quot;)) ) %&gt;% bind_rows() %&gt;% mutate(filter_name = if_else(is.na(filter_name), &quot;None&quot;, filter_name)) %&gt;% rename(&quot;Dependent variable&quot; = dv, &quot;RMSE&quot; = rmse, &quot;MAE&quot; = mae, &quot;Model&quot; = model, &quot;Filter&quot; = filter_name) %&gt;% kable(caption = &quot;Regression model performance&quot;, digits = 2) %&gt;% kable_styling() %&gt;% add_footnote(&quot;Note: While the model was trained using logs of the dependent variable, RMSE and MAE were calculated in levels&quot;, notation = &quot;symbol&quot;) ) Table 4.11: Regression model performance Dependent variable RMSE MAE Model Filter Donation amount* 66980.31 7259.41 Random Forest None Donation amount* 65011.02 7287.65 Linear Regression (glmnet) None Donation amount* 25944.63 4706.42 Random Forest Income (imp.)_bc5k &lt; 500000 Donation amount* 26010.45 4757.24 Linear Regression (glmnet) Income (imp.)_bc5k &lt; 500000 Donation as a share of income 0.10 0.06 Random Forest None Donation as a share of income 0.11 0.06 Linear Regression (glmnet) None * Note: While the model was trained using logs of the dependent variable, RMSE and MAE were calculated in levels p_load(ie2misc) mad_naive &lt;- ie2misc::madstat(eas_all_s_rl_imp$donation_usd, na.rm=TRUE) sd_naive &lt;- round((sd(eas_all_s_rl_imp$donation_usd, na.rm=TRUE)), 0) How does this compare to a ‘naive model’ in which we predict the average donation for everyone? Note that for the comparable unfiltered data, the mean absolute deviation is 13305.9303138871 and the standard deviation is 106109. The predictive model reduces this uncertainty substantially. 4.8.2.1.1 Classification Model Performance Reminder: this section (discussing performance) will be only very briefly summarized/linked in the EA Forum post. In evaluating classification model performance there are a variety of metrics which can be used. Firstly we show a ROC curve to consider the differences in the predictive power of the various models. We can also compare it to an uninformed classifier, which would simply predict a positive outcome with some random probability \\(p\\) (this maps out the 45 degree line). # Add column for ROC curve roc_curve &lt;- yardstick::roc_curve unnest &lt;- tidyr::unnest pr_curve &lt;- yardstick::pr_curve # Calculate ROC curve d_don_1k_best_params$roc_curve &lt;- d_don_1k_best_params %&gt;% select(true_y, preds, pred_prob, model) %&gt;% unnest(cols = everything()) %&gt;% group_by(model) %&gt;% group_map(~ roc_curve(., true_y, .pred_FALSE)) # Calculate AUC d_don_1k_best_params$auc &lt;- d_don_1k_best_params %&gt;% select(true_y, preds, pred_prob, model) %&gt;% unnest(cols = everything()) %&gt;% group_by(model) %&gt;% group_map(~ yardstick::roc_auc(., truth = true_y, estimate = .pred_FALSE)) # Extract AUC d_don_1k_best_params &lt;- d_don_1k_best_params %&gt;% unnest_wider(., col = auc) %&gt;% select(-c(.metric, .estimator)) %&gt;% rename(auc = .estimate) # Plot ROC curve (roc_curve_d_don_1k &lt;- d_don_1k_best_params %&gt;% select(roc_curve, model) %&gt;% unnest(cols = everything()) %&gt;% rename_with(snakecase::to_title_case) %&gt;% ggplot(aes(x = 1-Specificity, y = Sensitivity, colour = Model)) + geom_line() + geom_abline(slope=1, intercept = 0, linetype = &quot;dotted&quot;) + theme_bw() ) An ROC curve plots the true positive rate (sensitivity) as a function of the false positive rate (1-specificity). Here the true positive rate gives the rate at which our model correctly predicts a respondent to donate over $1000, with the false positive rate giving the rate at which these predictions are incorrect. Better classifiers will have an ROC curve that is further North-West, with the perfect classifier being an L-shaped curve passing through \\((0,0) \\rightarrow(0,1) \\rightarrow(1,1)\\). Where classifiers ROC curves do not cross, it is clear that one will be performing better than another. That is not the case here. Both models seem to be performing relatively similarly, with the ROC curves overlapping somewhat. It is difficult to discern which model is performing the best, and this will depend on our criterion. However, both models yield curves substantially above the 45 degree line, thus substantially outperforming an uninformed classifier. For example, if we are willing to accept about a 25% rate of false positives (falsely predicting a 1k+ donation), the logistic regression model correctly predicts about 75% of true positives (and the random forest model about 73%). We can use the area under the curve (AUC) measure to compare classifiers for all costs of misclassification. This measure quantifies how close the ROC curve is to the optimal L-shaped curve. calculate_metrics &lt;- function(df, metrics, preds = preds, true_y = true_y){ df %&gt;% mutate(purrr::map2_dfr({{true_y}}, {{preds}}, ~ purrr::map_dfc(metrics, do.call, list(.x, .y)))) } class_metrics &lt;- list(accuracy = yardstick::accuracy_vec, recall = yardstick::recall_vec, precision = yardstick::precision_vec, f1_score = yardstick::f_meas_vec) # Adding a no skill classifier to d_don_1k ## Messy code truth &lt;- d_don_1k_best_params$true_y[[1]] majority &lt;- tail(names(sort(table(truth))), 1) pred_majority &lt;- as.logical(rep(majority, length(truth))) .pred_FALSE &lt;- 1 - pred_majority .pred_TRUE &lt;- 1 - .pred_FALSE pred_prob &lt;- tibble(.pred_FALSE, .pred_TRUE, truth) no_skill &lt;- tibble(model = &quot;No Skill&quot;, true_y = list(truth), pred_prob = list(pred_prob), preds = list(factor(pred_majority, levels = levels(truth)))) %&gt;% calculate_metrics(class_metrics) no_skill$auc &lt;- yardstick::roc_auc_vec(truth, .pred_TRUE) purrr::map_df(list(no_skill, d_don_1k_best_params), ~.x %&gt;% select(model, auc, accuracy)) %&gt;% rename_with(snakecase::to_title_case) %&gt;% rename(AUC = Auc) %&gt;% kable(digits = 3) %&gt;% kable_styling() Model AUC Accuracy No Skill 0.500 0.537 Random Forest 0.817 0.739 Logistic Regression (glmnet) 0.824 0.735 Here we see that the random forest performs best in terms of AUC. All models perform much better than a no-skill classifier which simply predicts the majority class. This would suggest that there is predictive power in the explanatory variables included in these models. # Calculate precision recall curve # d_don_1k_best_params$pr_curve &lt;- d_don_1k_best_params %&gt;% select(true_y, preds, pred_prob, model) %&gt;% # unnest(cols = everything()) %&gt;% # group_by(model) %&gt;% # group_map(~ pr_curve(., true_y, .pred_FALSE)) # # d_don_1k_best_params %&gt;% select(pr_curve, model) %&gt;% # unnest(cols = everything()) %&gt;% # ggplot(aes(x = recall, y = precision, colour = model)) + # geom_path() + # coord_equal() + # theme_bw() + # geom_hline(aes(yintercept = 0.46)) best_d_don_1k_preds &lt;- d_don_1k_best_params %&gt;% filter(f1_score == max(f1_score)) %$% preds[[1]] d_don_1k_true &lt;- d_don_1k_best_params %&gt;% filter(f1_score == max(f1_score)) %$% true_y[[1]] #DR: @Oska, I&#39;m just guessing this is what you wanted d_don_1k_preds_df &lt;- tibble(preds = best_d_don_1k_preds, truth = d_don_1k_true) cm &lt;- yardstick::conf_mat(d_don_1k_preds_df, truth, preds) autoplot(cm, type = &quot;heatmap&quot;) + scale_fill_gradient(low=&quot;#D6EAF8&quot;,high = &quot;#2E86C1&quot;) + ggtitle(&quot;Predicting Donations over $1k&quot;) 4.8.3 Summary of modeling results – see the introduction At the end of the introduction ‘summary’ section we give an overall characterization of our modeling results in bullet points; we do not repeat it here. 4.9 Appendix: Extra analysis and robustness checks See bookdown appendix for further analysis and robustness checks. This appendix contains further and analysis and robustness checks, as mentioned or alluded to in the above ‘main text.’ This section will be part of the ‘Bookdown’ version only and not in the EA forum post. We will link this in the post. (With a section header and then a link). Donations by engagement level don_share_income_by_engage_sp Donations and income by student/employment status Below, we tabulate income and donations, split by student and employment status. #this is an annoying workaround for the EA markdown ... but it shouldn&#39;t matter because this appendix is cut if(Sys.info()[[4]]==&quot;Yosemites-iMac.local&quot;) { don_inc_by_student } html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #swirghxfwt .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #swirghxfwt .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #swirghxfwt .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #swirghxfwt .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #swirghxfwt .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #swirghxfwt .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #swirghxfwt .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #swirghxfwt .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #swirghxfwt .gt_column_spanner_outer:first-child { padding-left: 0; } #swirghxfwt .gt_column_spanner_outer:last-child { padding-right: 0; } #swirghxfwt .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #swirghxfwt .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #swirghxfwt .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #swirghxfwt .gt_from_md > :first-child { margin-top: 0; } #swirghxfwt .gt_from_md > :last-child { margin-bottom: 0; } #swirghxfwt .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #swirghxfwt .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #swirghxfwt .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #swirghxfwt .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #swirghxfwt .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #swirghxfwt .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #swirghxfwt .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #swirghxfwt .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #swirghxfwt .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #swirghxfwt .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #swirghxfwt .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #swirghxfwt .gt_sourcenote { font-size: 90%; padding: 4px; } #swirghxfwt .gt_left { text-align: left; } #swirghxfwt .gt_center { text-align: center; } #swirghxfwt .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #swirghxfwt .gt_font_normal { font-weight: normal; } #swirghxfwt .gt_font_bold { font-weight: bold; } #swirghxfwt .gt_font_italic { font-style: italic; } #swirghxfwt .gt_super { font-size: 65%; } #swirghxfwt .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } Characteristic N Overall, N = 1,6361 employed_ft, N = 707 employed_pt, N = 70 not_employed_looking, N = 57 Other, N = 120 self_employed, N = 127 student_doctoral, N = 119 student_masters, N = 155 student_undergrad, N = 281 Income in $1000 USD 1,400 Median 33 60 33 15 24 42 26 12 4 10%-90% 1-130 14-182 6-70 1-92 0-107 10-126 6-55 0-56 0-17 Mean [se] (SD) 61 [4] (138) 93 [6] (144) 43 [6] (48) 37 [8] (54) 52 [17] (160) 87 [28] (290) 28 [2] (18) 22 [3] (34) 8 [1] (9) 2019 donation (in USD) 1,413 Median 528 1,420 679 284 500 1,247 548 178 110 10%-90% 0-9,822 0-17,048 0-5,975 0-4,200 0-9,000 0-15,249 0-3,793 0-2,367 0-1,000 Mean [se] (SD) 7,516 [1,944] (73,062) 10,048 [1,769] (44,507) 2,779 [743] (5,944) 3,541 [2,072] (14,503) 4,085 [1,158] (11,048) 28,589 [22,709] (238,179) 1,505 [209] (2,165) 953 [199] (2,329) 450 [77] (1,141) 2020 planned donation 1,393 Median 1,000 3,052 1,319 349 578 1,751 1,500 327 200 10%-90% 0-12,039 0-21,500 0-7,167 0-5,114 0-8,085 0-12,534 0-5,678 0-2,869 0-2,000 Mean [se] (SD) 10,002 [1,993] (74,389) 14,473 [2,895] (72,421) 3,352 [789] (6,314) 5,990 [4,166] (28,864) 10,903 [5,619] (52,712) 26,841 [19,090] (196,545) 2,655 [480] (4,919) 990 [163] (1,906) 691 [93] (1,372) 1 c(&quot;Median&quot;, &quot;10%-90%&quot;, &quot;Mean [se] (SD)&quot;) if(Sys.info()[[4]]!=&quot;Yosemites-iMac.local&quot;) { don_inc_by_student %&gt;% as_image(width = 8) } Donation as share of income by tenure, ‘faceted’ by referrer to survey* ( don_share_by_tenure_facet_referrer &lt;- eas_20 %&gt;% filter(!is.na(age_approx_ranges)) %&gt;% ggplot() + aes(x = tenure, y = don_share_inc_19_imp) + geom_point(size = 0.15, colour = &quot;#0c4c8a&quot;, position = position_jitter(seed = 42, width = 0.1, height = 0.001)) + geom_smooth(span = 0.75) + scatter_theme + facet_grid(vars(), vars(referrer_cat2), scales = &quot;free&quot;) + labs(title = &quot;2019 donation as share of (imputed) income by time in EA faceted by referrer category&quot;) + labs(x = get_label(eas_20$referrer_cat2)) + ylim(0, 0.3) ) %&gt;% ggplotly For several major groups of referrers, we (again) see a strong positive association between time-in-EA and donations as a share of income. Additional: Donations and income by whether a Longtermist cause is top priority We were asked to compare the donations of those who prioritize longtermist causes to the remainder of EAs. Below, we tabulate this by whether a respondent gives some longtermist cause as high a priority rating as any other cause. #eas_20 %&gt;% tabyl(lt_above_mn_priority) #lt_4plus_priority = case_when( don_income_by_priority &lt;- eas_20 %&gt;% dplyr::select(income_k_c, donation_2019_c, donation_2020_c, don_share_inc_19_imp, lt_top_priority) %&gt;% tbl_summary( by = lt_top_priority, type = c(all_continuous()) ~ &quot;continuous2&quot;, statistic = list(all_continuous() ~ sumstatvec), label = list(income_k_c ~ &quot;Income in $1000 USD&quot;, donation_2019_c ~ &quot;2019 donation (in USD)&quot;, donation_2020_c ~ &quot;2020 planned donation&quot;, don_share_inc_19_imp ~ &quot;2019 donation as share of (imputed) income&quot; ), missing = c(&quot;no&quot;) ) %&gt;% bold_labels() %&gt;% add_n() %&gt;% add_overall() if(Sys.info()[[4]]==&quot;Yosemites-iMac.local&quot;) { don_income_by_priority } html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #agrbfqbnoo .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #agrbfqbnoo .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #agrbfqbnoo .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #agrbfqbnoo .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #agrbfqbnoo .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #agrbfqbnoo .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #agrbfqbnoo .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #agrbfqbnoo .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #agrbfqbnoo .gt_column_spanner_outer:first-child { padding-left: 0; } #agrbfqbnoo .gt_column_spanner_outer:last-child { padding-right: 0; } #agrbfqbnoo .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #agrbfqbnoo .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #agrbfqbnoo .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #agrbfqbnoo .gt_from_md > :first-child { margin-top: 0; } #agrbfqbnoo .gt_from_md > :last-child { margin-bottom: 0; } #agrbfqbnoo .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #agrbfqbnoo .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #agrbfqbnoo .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #agrbfqbnoo .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #agrbfqbnoo .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #agrbfqbnoo .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #agrbfqbnoo .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #agrbfqbnoo .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #agrbfqbnoo .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #agrbfqbnoo .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #agrbfqbnoo .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #agrbfqbnoo .gt_sourcenote { font-size: 90%; padding: 4px; } #agrbfqbnoo .gt_left { text-align: left; } #agrbfqbnoo .gt_center { text-align: center; } #agrbfqbnoo .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #agrbfqbnoo .gt_font_normal { font-weight: normal; } #agrbfqbnoo .gt_font_bold { font-weight: bold; } #agrbfqbnoo .gt_font_italic { font-style: italic; } #agrbfqbnoo .gt_super { font-size: 65%; } #agrbfqbnoo .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } Characteristic N Overall, N = 1,6161 FALSE, N = 796 TRUE, N = 820 Income in $1000 USD 1,361 Median 34 38 29 10%-90% 1-130 2-129 0-130 Mean [se] (SD) 61 [4] (138) 59 [4] (111) 62 [6] (161) 2019 donation (in USD) 1,374 Median 559 700 500 10%-90% 0-10,000 0-10,000 0-10,000 Mean [se] (SD) 7,688 [1,998] (74,077) 6,212 [1,289] (33,823) 9,172 [3,794] (99,297) 2020 planned donation 1,354 Median 1,053 1,320 939 10%-90% 0-12,759 0-12,049 0-12,796 Mean [se] (SD) 10,186 [2,050] (75,431) 9,446 [2,188] (57,095) 10,935 [3,481] (90,311) 2019 donation as share of (imputed) income 1,373 Median 0.02 0.03 0.02 10%-90% 0.00-0.15 0.00-0.15 0.00-0.14 Mean [se] (SD) 0.13 [0.05] (1.82) 0.09 [0.01] (0.33) 0.16 [0.10] (2.55) 1 c(&quot;Median&quot;, &quot;10%-90%&quot;, &quot;Mean [se] (SD)&quot;) if(Sys.info()[[4]]!=&quot;Yosemites-iMac.local&quot;) { don_income_by_priority %&gt;% as_image(width = 8) } # Todo (medium): fix labeling and titles above # Todo (High): add standard error and perhaps tests, perhaps Bayes factors # Todo (Medium-high): visualization of donations by top-priority category (poverty, animals, LT, meta/other) don_inc_priority_plot &lt;- eas_20 %&gt;% grp_sum(income_c_imp_bc5k, donation_2019_c, XXX) %&gt;% plot_grp(country_big) + xlab(&quot;Mean income in USD (imputed if &lt;5k/missing&quot;) + ylab(&quot;Mean donations, CIs&quot;) The above presentation is meant to be broadly descriptive. Overall, it appears that those who prioritize long-term causes tend to donate a bit less at median but more at mean, and there is a lot of overlap between the two groups. 4.9.1 Planned donation by year, comparison tests We report the amount people say they expect to donate in the current (survey) year below. Note the high share of missing values for 2017, and the substantially-larger sample in 2018. As noted above, this suggests that comparing the planned donations for 2018 (in EA survey 2018) to actual donations for 2018 (reported in 2019 EA survey) may not be informative. ( plan_don_per_year &lt;- eas_all %&gt;% filter(year&gt;=2017) %&gt;% group_by(year) %&gt;% summarise(&quot;Number reported&quot; = sum(!is.na(donation_plan_usd)), N = n(), &quot;Number missing&quot; = sum(is.na(donation_plan_usd)), &quot;Proportion missing (%)&quot; = sum(is.na(donation_plan_usd))/n()*100, &quot;Mean planned donation&quot; = mean(donation_plan_usd, na.rm=TRUE), &quot;Median planned donation&quot; = median(donation_plan_usd, na.rm=TRUE)) %&gt;% kable(caption = &quot;Planned donation per year&quot;) %&gt;% kable_styling() ) (#tab:plan_don_per_year)Planned donation per year year Number reported N Number missing Proportion missing (%) Mean planned donation Median planned donation 2017 831 1845 1014 54.95935 1806.744 10.00 2018 1790 2599 809 31.12736 11045.812 1156.22 2019 1678 2509 831 33.12077 10704.457 1088.80 2020 1402 2056 654 31.80934 9992.946 1000.00 Below, the results of the signed rank test for plan versus actual donation, excluding 0 donations. w_signed_test_planned_actual_no0s ## ## Wilcoxon signed rank test with continuity correction ## ## data: planned_actual_2019$donation_2019 and planned_actual_2019$planned_donation_2019 ## V = 30124, p-value = 0.000009109 ## alternative hypothesis: true location shift is greater than 0 ## 95 percent confidence interval: ## 162.205 Inf ## sample estimates: ## (pseudo)median ## 281 4.9.2 Donations by income ‘earning-to-give’ career status ( don_income_etg &lt;- eas_all %&gt;% filter(year_n&gt;=2018) %&gt;% ggplot(aes(x = income_c_imp_bc_k, y = donation_2019, color = d_career_etg)) + geom_point(size = 1, alpha = 0.7) + # draw the points geom_smooth(aes(method = &#39;loess&#39;, fill = d_career_etg)) + # @Oska -- note I am using local smoothing here. scale_x_log10(name = &quot;Income in $1K USD (imputed if &lt;5k/missing)&quot;, n.breaks = 5, limits = c(5, 5000)) + scale_y_log10( name = &quot;Donation amount&quot;, # labels = scales::dollar, labels = scales::label_number_si(prefix = &quot;$&quot;), n.breaks = 10 ) + scale_color_discrete(name = &quot;Earning to give&quot;) + scale_fill_discrete(guide = &quot;none&quot;) + theme(axis.text.x = element_text( angle = 90, vjust = 0.5, hjust = 1 ), legend.position = c(.87,.15), legend.background = element_rect(fill=alpha(&#39;blue&#39;, 0.01))) ) #don_income_etg + facet_wrap(~d_gwwc_ever) 4.9.3 Donation shares by income (by US-residence, 2019) By request, we consider median and mean shares of income donated, separately tallying for US residents and others. This allows us to compare donation rates to those reported for the US overall. In particular, Meer and Priday (2020) reports a roughly 1.6-2.1% percent share of income donated throughout all of the US income quantiles (except or the lowest 5%). The statistics below suggest that EAs who fill out the donation questions in the survey to donate a greater share of their income, perhaps at least twice as much. Recall that the mean share of total (imputed) income donated (for 2019) was 9.44% (imputing income where below 5k or missing). If we focus on US-resident nonstudents across all years, the mean share is 7.94%. mean_don_sharenonstud_usa_w20 &lt;- eas_all %&gt;% filter(d_live_usa==1 &amp; d_student==0) %&gt;% rowwise() %&gt;% mutate(don_share_inc_imp_bc5k = min(don_share_inc_imp_bc5k, 0.2)) %&gt;% ungroup() %&gt;% summarize(mean_share_nonstud_usa_w20 = mean(don_share_inc_imp_bc5k, na.rm=TRUE) ) We could also ‘average the individual shares donated’; as this is highly sensitive to outliers (e.g., people with the lowest incomes reporting donating many times this share), we ‘Winsorise,’ capping each individual’s ‘share of income donate’ at some percent. Following this procedure and capping at 20%, the mean share of income donated, across all years, for US-resident non-students in the EA survey, is 5.67%. We plot donation shares on a log scale, for US and non-US residents separately (across all years). Below, the blue dash gives us the median for USA (vs non-USA), and the smoothed curve tries to best fit the mean. The left graph is ‘Winsorised’ at 20%, and right one at 40% don_share_income_by_usa &lt;- eas_all %&gt;% filter(!is.na(d_live_usa)) %&gt;% rowwise() %&gt;% mutate(don_share_inc_imp_bc5k = min(don_share_inc_imp_bc5k, 0.4)) %&gt;% ungroup() %&gt;% group_by(d_live_usa) %&gt;% mutate(med_usa = median(don_share_inc_imp_bc5k, na.rm=TRUE)) %&gt;% ungroup() %&gt;% ggplot(aes(x = income_c_imp_bc_k, y = don_share_inc_imp_bc5k)) + ggpointdensity::geom_pointdensity(adjust = 0.25) + geom_smooth(method = &quot;loess&quot;) + geom_hline(aes(yintercept=med_usa), linetype=&quot;dashed&quot;, size=0.5, color = &quot;blue&quot;) + geom_hline(yintercept=0.1, linetype=&quot;dashed&quot;, size=0.5, color = &quot;red&quot;) + scale_y_continuous(labels = scales::label_percent(accuracy = 1L)) + scale_x_log10(breaks = scales::log_breaks(n=7)) + scale_color_viridis_c(&quot;Neighbours&quot;) + xlab(&quot;Income in $1K USD (imputed if missing, bottom-code at 5k)&quot;) + theme(axis.title.x = element_text(size = 10)) + ylim(NA,.21) + ylab(&quot;Donations/Income (top-code at 40%)&quot;) + facet_wrap(~d_live_usa) + labs(title=&quot;By US residence: 2019 &#39;Don. share of income&#39; by income (w/ imputing)&quot;) don_share_income_by_usa_w20 &lt;- eas_all %&gt;% filter(!is.na(d_live_usa)) %&gt;% rowwise() %&gt;% mutate(don_share_inc_imp_bc5k = min(don_share_inc_imp_bc5k, 0.2)) %&gt;% ungroup() %&gt;% group_by(d_live_usa) %&gt;% mutate(med_usa = median(don_share_inc_imp_bc5k, na.rm=TRUE)) %&gt;% ungroup() %&gt;% ggplot(aes(x = income_c_imp_bc_k, y = don_share_inc_imp_bc5k)) + ggpointdensity::geom_pointdensity(adjust = 0.25) + geom_smooth(method = &quot;loess&quot;) + geom_hline(aes(yintercept=med_usa), linetype=&quot;dashed&quot;, size=0.5, color = &quot;blue&quot;) + geom_hline(yintercept=0.1, linetype=&quot;dashed&quot;, size=0.5, color = &quot;red&quot;) + scale_y_continuous(labels = scales::label_percent(accuracy = 1L)) + scale_x_log10(breaks = scales::log_breaks(n=7)) + scale_color_viridis_c(&quot;Neighbours&quot;) + xlab(&quot;Income in $1K USD (imputed if missing, bottom-code at 5k)&quot;) + theme(axis.title.x = element_text(size = 10)) + ylab(&quot;Donations/Income (&#39;Windsorised&#39; (top-coded) at 40%)&quot;) + ylim(NA,.21) + facet_wrap(~d_live_usa) + labs(title=&quot;By US residence: 2019 &#39;Don. share of income&#39; by income (w/ imputing)&quot;) mean_don_share_income_usa_nonstudent_w20 &lt;- eas_all %&gt;% filter(d_live_usa==1 &amp; d_student==0) %&gt;% rowwise() %&gt;% mutate(don_share_inc_imp_bc5k = min(don_share_inc_imp_bc5k, 0.2)) %&gt;% ungroup() %&gt;% dplyr::summarise(mean_don_share= mean(don_share_inc_imp_bc5k, na.rm=TRUE) ) #don_income_etg + facet_wrap(~d_gwwc_ever) 4.9.4 Models: nonresponse coefficients Below we report the ‘no response’ coefficients for all of the models presented above (recall that these are ‘controls’ included in each specification). These are exponentiated, as in the presentations above. We report these only here because we suspect they are of less direct interest. # make nice table (and/or forest plot?) of nonreseponses ( nr_coefs_table &lt;- bind_rows(nr_coefs_qp, nr_coefs_fl,nr_coefs_logit) %&gt;% select(outcome, term, model_name, estimate, std.error, p.value, conf.low, conf.high) %&gt;% filter(!str_detect(model_name, &quot;GWWC&quot;)) %&gt;% filter(str_detect(term, &quot;response|na|NA&quot;)) %&gt;% mutate( outcome = str_replace_all(outcome, key_eas_all_labels) ) %&gt;% arrange(term) %&gt;% .kable(digits=3) %&gt;% .kable_styling() ) outcome term model_name estimate std.error p.value conf.low conf.high Don. ‘avg’ City: No response Baseline 0.661 0.198 0.037 0.449 0.975 Don. ‘avg’ City: No response Robust controls 0.651 0.197 0.029 0.442 0.957 Don./Income (imp, bc) City: No response Baseline 0.877 0.210 0.532 0.581 1.324 Don./Income (imp, bc) City: No response Robust controls 0.873 0.211 0.520 0.577 1.320 Don. &gt; 1k USD City: No response Baseline 1.132 0.116 0.283 0.903 1.420 Don. &gt; 1k USD City: No response Robust controls 1.124 0.121 0.332 0.887 1.425 Don. ‘avg’ Gender: No response Baseline 0.786 0.236 0.308 0.494 1.249 Don. ‘avg’ Gender: No response Robust controls 0.803 0.240 0.361 0.502 1.285 Don./Income (imp, bc) Gender: No response Baseline 0.945 0.238 0.811 0.593 1.505 Don./Income (imp, bc) Gender: No response Robust controls 0.942 0.238 0.802 0.591 1.502 Don. &gt; 1k USD Gender: No response Baseline 0.985 0.236 0.949 0.621 1.563 Don. &gt; 1k USD Gender: No response Robust controls 1.068 0.243 0.787 0.663 1.719 Don. ‘avg’ Live: Country: No response Baseline 1.347 0.340 0.381 0.692 2.624 Don. ‘avg’ Live: Country: No response Robust controls 1.353 0.346 0.382 0.687 2.664 Don./Income (imp, bc) Live: Country: No response Baseline 1.630 0.339 0.150 0.838 3.168 Don./Income (imp, bc) Live: Country: No response Robust controls 1.634 0.340 0.149 0.839 3.181 Don. &gt; 1k USD Live: Country: No response Baseline 0.795 0.156 0.142 0.585 1.080 Don. &gt; 1k USD Live: Country: No response Robust controls 0.874 0.161 0.405 0.637 1.200 Don. ‘avg’ Race: No response Baseline 0.567 0.308 0.066 0.310 1.037 Don. ‘avg’ Race: No response Robust controls 0.562 0.308 0.061 0.308 1.028 Don./Income (imp, bc) Race: No response Baseline 0.938 0.262 0.808 0.562 1.567 Don./Income (imp, bc) Race: No response Robust controls 0.941 0.261 0.817 0.565 1.570 Don. &gt; 1k USD Race: No response Baseline 0.697 0.296 0.222 0.390 1.245 Don. &gt; 1k USD Race: No response Robust controls 0.666 0.299 0.174 0.370 1.197 Don. ‘avg’ Student: No response Baseline 1.607 1.895 0.802 0.039 65.955 Don. ‘avg’ Student: No response Robust controls 1.610 2.231 0.831 0.020 127.555 Don./Income (imp, bc) Student: No response Baseline 1.134 1.009 0.901 0.157 8.193 Don./Income (imp, bc) Student: No response Robust controls 1.144 1.008 0.894 0.159 8.251 Don. &gt; 1k USD Student: No response Baseline 1.759 0.727 0.437 0.423 7.306 Don. &gt; 1k USD Student: No response Robust controls 1.826 0.733 0.411 0.434 7.678 Don. ‘avg’ Top-6 Uni: NA Baseline 1.098 0.337 0.782 0.567 2.125 Don. ‘avg’ Top-6 Uni: NA Robust controls 1.092 0.336 0.794 0.565 2.110 Don./Income (imp, bc) Top-6 Uni: NA Baseline 0.770 0.121 0.031 0.607 0.976 Don./Income (imp, bc) Top-6 Uni: NA Robust controls 0.773 0.121 0.034 0.609 0.981 Don. &gt; 1k USD Top-6 Uni: NA Baseline 0.782 0.126 0.052 0.611 1.002 Don. &gt; 1k USD Top-6 Uni: NA Robust controls 0.813 0.130 0.112 0.630 1.050 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
